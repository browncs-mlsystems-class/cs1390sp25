<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>hw1</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
<hr />
<h1 id="csci-1390-spring-2025-written-hw-1">CSCI 1390, Spring 2025:
Written HW 1</h1>
<p>Due Date: Thursday, February 27, 6 PM. You CANNOT use late hours on
the written homework.</p>
<p>Read the following paper excerpts, and answer the questions below.
Submit your answers as a single PDF on gradescope <a
href="https://www.gradescope.com/courses/987745">here</a>. TAs won’t be
answering questions about the writeup in office hours; you should be
able to answer the questions below merely with reading
comprehension.</p>
<hr style="border: none; border-top: 1px solid lightgrey; margin: 20px 0;">
<h2 id="reading">Reading</h2>
<ul>
<li><p><a
href="https://deepakn94.github.io/assets/papers/pipedream-sosp19.pdf">PipeDream</a>
– All Sections.</p></li>
<li><p><a href="https://arxiv.org/pdf/1909.08053">Megatron-LM</a> – All
Sections.</p></li>
<li><p><a href="https://arxiv.org/pdf/2104.04473">Efficient Large-Scale
Language Model Training on GPU Clusters Using Megatron-LM</a> – Sections
1, 3, Skim Evaluation.</p></li>
</ul>
<h2 id="questions">Questions</h2>
<p>The total length of your response should be about 600-700 words, with
approximate breakdowns specified below. Please adhere to the breakdowns;
you will be penalized, for example, if your summarization is too long,
and the other answers are too short. Additionally, we expect you to cite
specific examples and evidence from the papers when answering the
questions.</p>
<h3 id="summarization-300-400-words-total">Summarization (300-400 words
total)</h3>
<ol type="1">
<li>What were the key challenges that the PipeDream paper solved to get
pipeline parallelism working well in practice (150 words)?</li>
<li>What are the advantages of tensor model parallelism over pipeline
model parallelism; why was it chosen to train transformers (150
words)?</li>
<li>Answer for both the pipedream and megatron-LM papers (100 words) :
What are key weaknesses and strengths in either paper? You can discuss
weaknesses and strengths of how they framed the problem, or of the
solution and the solution’s applicability.</li>
</ol>
<h3 id="comprehension-200-words">Comprehension (200 words)</h3>
<ol start="3" type="1">
<li>Why does the third paper explore combining parallelism strategies?
What in this setting is different making it such that no one strategy
alone is sufficient? Why is their method effective over any single
parallelism strategy?</li>
</ol>
<h3 id="synthesis-100-200-words">Synthesis (100-200 words)</h3>
<ol start="4" type="1">
<li>Consider the workload of inference rather than training. Most
transformer model weights will not fit on a single GPU. What parallelism
strategy would you deploy and why?</li>
</ol>
</body>
</html>
