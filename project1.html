<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="mobile-web-app-capable" content="yes">
    <title>
        Assignment 1: Parallelism Techniques - HackMD
    </title>
    <link rel="icon" type="image/png" href="https://hackmd.io/favicon.png">
    <link rel="apple-touch-icon" href="https://hackmd.io/apple-touch-icon.png">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ionicons/2.0.1/css/ionicons.min.css" integrity="sha256-3iu9jgsy9TpTwXKb7bNQzqWekRX7pPK+2OLj3R922fo=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/3.5.0/octicons.min.css" integrity="sha256-QiWfLIsCT02Sdwkogf6YMiQlj4NE84MKkzEMkZnMGdg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.1/themes/prism.min.css" integrity="sha256-vtR0hSWRc3Tb26iuN2oZHt3KRUomwTufNIf5/4oeCyg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/css/basic/emojify.min.css" integrity="sha256-UOrvMOsSDSrW6szVLe8ZDZezBxh5IoIfgTwdNDgTjiU=" crossorigin="anonymous" />
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i|Source+Code+Pro:300,400,500|Source+Sans+Pro:300,300i,400,400i,600,600i|Source+Serif+Pro&subset=latin-ext);
/*!
  Theme: GitHub
  Description: Light theme as seen on github.com
  Author: github.com
  Maintainer: @Hirse
  Updated: 2021-05-15

  Outdated base version: https://github.com/primer/github-syntax-light
  Current colors taken from GitHub's CSS
*/:root[theme=light] :not([theme])>*>.markdown-body .hljs-doctag,:root[theme=light] :not([theme])>*>.markdown-body .hljs-keyword,:root[theme=light] :not([theme])>*>.markdown-body .hljs-meta .hljs-keyword,:root[theme=light] :not([theme])>*>.markdown-body .hljs-template-tag,:root[theme=light] :not([theme])>*>.markdown-body .hljs-template-variable,:root[theme=light] :not([theme])>*>.markdown-body .hljs-type,:root[theme=light] :not([theme])>*>.markdown-body .hljs-variable.language_,:root[theme] [theme=light] .markdown-body .hljs-doctag,:root[theme] [theme=light] .markdown-body .hljs-keyword,:root[theme] [theme=light] .markdown-body .hljs-meta .hljs-keyword,:root[theme] [theme=light] .markdown-body .hljs-template-tag,:root[theme] [theme=light] .markdown-body .hljs-template-variable,:root[theme] [theme=light] .markdown-body .hljs-type,:root[theme] [theme=light] .markdown-body .hljs-variable.language_{color:#d73a49}:root[theme=light] :not([theme])>*>.markdown-body .hljs-title,:root[theme=light] :not([theme])>*>.markdown-body .hljs-title.class_,:root[theme=light] :not([theme])>*>.markdown-body .hljs-title.class_.inherited__,:root[theme=light] :not([theme])>*>.markdown-body .hljs-title.function_,:root[theme] [theme=light] .markdown-body .hljs-title,:root[theme] [theme=light] .markdown-body .hljs-title.class_,:root[theme] [theme=light] .markdown-body .hljs-title.class_.inherited__,:root[theme] [theme=light] .markdown-body .hljs-title.function_{color:#6f42c1}:root[theme=light] :not([theme])>*>.markdown-body .hljs-attr,:root[theme=light] :not([theme])>*>.markdown-body .hljs-attribute,:root[theme=light] :not([theme])>*>.markdown-body .hljs-literal,:root[theme=light] :not([theme])>*>.markdown-body .hljs-meta,:root[theme=light] :not([theme])>*>.markdown-body .hljs-number,:root[theme=light] :not([theme])>*>.markdown-body .hljs-operator,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-attr,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-class,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-id,:root[theme=light] :not([theme])>*>.markdown-body .hljs-variable,:root[theme] [theme=light] .markdown-body .hljs-attr,:root[theme] [theme=light] .markdown-body .hljs-attribute,:root[theme] [theme=light] .markdown-body .hljs-literal,:root[theme] [theme=light] .markdown-body .hljs-meta,:root[theme] [theme=light] .markdown-body .hljs-number,:root[theme] [theme=light] .markdown-body .hljs-operator,:root[theme] [theme=light] .markdown-body .hljs-selector-attr,:root[theme] [theme=light] .markdown-body .hljs-selector-class,:root[theme] [theme=light] .markdown-body .hljs-selector-id,:root[theme] [theme=light] .markdown-body .hljs-variable{color:#005cc5}:root[theme=light] :not([theme])>*>.markdown-body .hljs-meta .hljs-string,:root[theme=light] :not([theme])>*>.markdown-body .hljs-regexp,:root[theme=light] :not([theme])>*>.markdown-body .hljs-string,:root[theme] [theme=light] .markdown-body .hljs-meta .hljs-string,:root[theme] [theme=light] .markdown-body .hljs-regexp,:root[theme] [theme=light] .markdown-body .hljs-string{color:#032f62}:root[theme=light] :not([theme])>*>.markdown-body .hljs-built_in,:root[theme=light] :not([theme])>*>.markdown-body .hljs-symbol,:root[theme] [theme=light] .markdown-body .hljs-built_in,:root[theme] [theme=light] .markdown-body .hljs-symbol{color:#e36209}:root[theme=light] :not([theme])>*>.markdown-body .hljs-code,:root[theme=light] :not([theme])>*>.markdown-body .hljs-comment,:root[theme=light] :not([theme])>*>.markdown-body .hljs-formula,:root[theme] [theme=light] .markdown-body .hljs-code,:root[theme] [theme=light] .markdown-body .hljs-comment,:root[theme] [theme=light] .markdown-body .hljs-formula{color:#6a737d}:root[theme=light] :not([theme])>*>.markdown-body .hljs-name,:root[theme=light] :not([theme])>*>.markdown-body .hljs-quote,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-pseudo,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-tag,:root[theme] [theme=light] .markdown-body .hljs-name,:root[theme] [theme=light] .markdown-body .hljs-quote,:root[theme] [theme=light] .markdown-body .hljs-selector-pseudo,:root[theme] [theme=light] .markdown-body .hljs-selector-tag{color:#22863a}:root[theme=light] :not([theme])>*>.markdown-body .hljs-subst,:root[theme] [theme=light] .markdown-body .hljs-subst{color:#24292e}:root[theme=light] :not([theme])>*>.markdown-body .hljs-section,:root[theme] [theme=light] .markdown-body .hljs-section{color:#005cc5;font-weight:700}:root[theme=light] :not([theme])>*>.markdown-body .hljs-bullet,:root[theme] [theme=light] .markdown-body .hljs-bullet{color:#735c0f}:root[theme=light] :not([theme])>*>.markdown-body .hljs-emphasis,:root[theme] [theme=light] .markdown-body .hljs-emphasis{color:#24292e;font-style:italic}:root[theme=light] :not([theme])>*>.markdown-body .hljs-strong,:root[theme] [theme=light] .markdown-body .hljs-strong{color:#24292e;font-weight:700}:root[theme=light] :not([theme])>*>.markdown-body .hljs-addition,:root[theme] [theme=light] .markdown-body .hljs-addition{background-color:#f0fff4;color:#22863a}:root[theme=light] :not([theme])>*>.markdown-body .hljs-deletion,:root[theme] [theme=light] .markdown-body .hljs-deletion{background-color:#ffeef0;color:#b31d28}

/*!
  Theme: GitHub Dark Dimmed
  Description: Dark dimmed theme as seen on github.com
  Author: github.com
  Maintainer: @Hirse
  Updated: 2021-05-15

  Colors taken from GitHub's CSS
*/:root[theme=dark] :not([theme])>*>.markdown-body .hljs-doctag,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-keyword,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-meta .hljs-keyword,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-template-tag,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-template-variable,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-type,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-variable.language_,:root[theme] [theme=dark] .markdown-body .hljs-doctag,:root[theme] [theme=dark] .markdown-body .hljs-keyword,:root[theme] [theme=dark] .markdown-body .hljs-meta .hljs-keyword,:root[theme] [theme=dark] .markdown-body .hljs-template-tag,:root[theme] [theme=dark] .markdown-body .hljs-template-variable,:root[theme] [theme=dark] .markdown-body .hljs-type,:root[theme] [theme=dark] .markdown-body .hljs-variable.language_{color:#f47067}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-title,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-title.class_,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-title.class_.inherited__,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-title.function_,:root[theme] [theme=dark] .markdown-body .hljs-title,:root[theme] [theme=dark] .markdown-body .hljs-title.class_,:root[theme] [theme=dark] .markdown-body .hljs-title.class_.inherited__,:root[theme] [theme=dark] .markdown-body .hljs-title.function_{color:#dcbdfb}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-attr,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-attribute,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-literal,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-meta,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-number,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-operator,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-attr,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-class,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-id,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-variable,:root[theme] [theme=dark] .markdown-body .hljs-attr,:root[theme] [theme=dark] .markdown-body .hljs-attribute,:root[theme] [theme=dark] .markdown-body .hljs-literal,:root[theme] [theme=dark] .markdown-body .hljs-meta,:root[theme] [theme=dark] .markdown-body .hljs-number,:root[theme] [theme=dark] .markdown-body .hljs-operator,:root[theme] [theme=dark] .markdown-body .hljs-selector-attr,:root[theme] [theme=dark] .markdown-body .hljs-selector-class,:root[theme] [theme=dark] .markdown-body .hljs-selector-id,:root[theme] [theme=dark] .markdown-body .hljs-variable{color:#6cb6ff}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-meta .hljs-string,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-regexp,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-string,:root[theme] [theme=dark] .markdown-body .hljs-meta .hljs-string,:root[theme] [theme=dark] .markdown-body .hljs-regexp,:root[theme] [theme=dark] .markdown-body .hljs-string{color:#96d0ff}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-built_in,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-symbol,:root[theme] [theme=dark] .markdown-body .hljs-built_in,:root[theme] [theme=dark] .markdown-body .hljs-symbol{color:#f69d50}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-code,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-comment,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-formula,:root[theme] [theme=dark] .markdown-body .hljs-code,:root[theme] [theme=dark] .markdown-body .hljs-comment,:root[theme] [theme=dark] .markdown-body .hljs-formula{color:#768390}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-name,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-quote,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-pseudo,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-tag,:root[theme] [theme=dark] .markdown-body .hljs-name,:root[theme] [theme=dark] .markdown-body .hljs-quote,:root[theme] [theme=dark] .markdown-body .hljs-selector-pseudo,:root[theme] [theme=dark] .markdown-body .hljs-selector-tag{color:#8ddb8c}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-subst,:root[theme] [theme=dark] .markdown-body .hljs-subst{color:#adbac7}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-section,:root[theme] [theme=dark] .markdown-body .hljs-section{color:#316dca;font-weight:700}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-bullet,:root[theme] [theme=dark] .markdown-body .hljs-bullet{color:#eac55f}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-emphasis,:root[theme] [theme=dark] .markdown-body .hljs-emphasis{color:#adbac7;font-style:italic}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-strong,:root[theme] [theme=dark] .markdown-body .hljs-strong{color:#adbac7;font-weight:700}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-addition,:root[theme] [theme=dark] .markdown-body .hljs-addition{background-color:#1b4721;color:#b4f1b4}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-deletion,:root[theme] [theme=dark] .markdown-body .hljs-deletion{background-color:#78191b;color:#ffd8d3}:root[theme=dark] :not([theme])>*>.markdown-body code[class*=language-],:root[theme=dark] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=dark] .markdown-body code[class*=language-],:root[theme] [theme=dark] .markdown-body pre[class*=language-]{word-wrap:normal;background:none;color:#ccc;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;white-space:pre;word-break:normal;word-spacing:normal}:root[theme=dark] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=dark] .markdown-body pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:root[theme=dark] :not([theme])>*>.markdown-body :not(pre)>code[class*=language-],:root[theme=dark] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=dark] .markdown-body :not(pre)>code[class*=language-],:root[theme] [theme=dark] .markdown-body pre[class*=language-]{background:#2d2d2d}:root[theme=dark] :not([theme])>*>.markdown-body :not(pre)>code[class*=language-],:root[theme] [theme=dark] .markdown-body :not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}:root[theme=dark] :not([theme])>*>.markdown-body .token.block-comment,:root[theme=dark] :not([theme])>*>.markdown-body .token.cdata,:root[theme=dark] :not([theme])>*>.markdown-body .token.comment,:root[theme=dark] :not([theme])>*>.markdown-body .token.doctype,:root[theme=dark] :not([theme])>*>.markdown-body .token.prolog,:root[theme] [theme=dark] .markdown-body .token.block-comment,:root[theme] [theme=dark] .markdown-body .token.cdata,:root[theme] [theme=dark] .markdown-body .token.comment,:root[theme] [theme=dark] .markdown-body .token.doctype,:root[theme] [theme=dark] .markdown-body .token.prolog{color:#999}:root[theme=dark] :not([theme])>*>.markdown-body .token.punctuation,:root[theme] [theme=dark] .markdown-body .token.punctuation{color:#ccc}:root[theme=dark] :not([theme])>*>.markdown-body .token.attr-name,:root[theme=dark] :not([theme])>*>.markdown-body .token.deleted,:root[theme=dark] :not([theme])>*>.markdown-body .token.namespace,:root[theme=dark] :not([theme])>*>.markdown-body .token.tag,:root[theme] [theme=dark] .markdown-body .token.attr-name,:root[theme] [theme=dark] .markdown-body .token.deleted,:root[theme] [theme=dark] .markdown-body .token.namespace,:root[theme] [theme=dark] .markdown-body .token.tag{color:#e2777a}:root[theme=dark] :not([theme])>*>.markdown-body .token.function-name,:root[theme] [theme=dark] .markdown-body .token.function-name{color:#6196cc}:root[theme=dark] :not([theme])>*>.markdown-body .token.boolean,:root[theme=dark] :not([theme])>*>.markdown-body .token.function,:root[theme=dark] :not([theme])>*>.markdown-body .token.number,:root[theme] [theme=dark] .markdown-body .token.boolean,:root[theme] [theme=dark] .markdown-body .token.function,:root[theme] [theme=dark] .markdown-body .token.number{color:#f08d49}:root[theme=dark] :not([theme])>*>.markdown-body .token.class-name,:root[theme=dark] :not([theme])>*>.markdown-body .token.constant,:root[theme=dark] :not([theme])>*>.markdown-body .token.property,:root[theme=dark] :not([theme])>*>.markdown-body .token.symbol,:root[theme] [theme=dark] .markdown-body .token.class-name,:root[theme] [theme=dark] .markdown-body .token.constant,:root[theme] [theme=dark] .markdown-body .token.property,:root[theme] [theme=dark] .markdown-body .token.symbol{color:#f8c555}:root[theme=dark] :not([theme])>*>.markdown-body .token.atrule,:root[theme=dark] :not([theme])>*>.markdown-body .token.builtin,:root[theme=dark] :not([theme])>*>.markdown-body .token.important,:root[theme=dark] :not([theme])>*>.markdown-body .token.keyword,:root[theme=dark] :not([theme])>*>.markdown-body .token.selector,:root[theme] [theme=dark] .markdown-body .token.atrule,:root[theme] [theme=dark] .markdown-body .token.builtin,:root[theme] [theme=dark] .markdown-body .token.important,:root[theme] [theme=dark] .markdown-body .token.keyword,:root[theme] [theme=dark] .markdown-body .token.selector{color:#cc99cd}:root[theme=dark] :not([theme])>*>.markdown-body .token.attr-value,:root[theme=dark] :not([theme])>*>.markdown-body .token.char,:root[theme=dark] :not([theme])>*>.markdown-body .token.regex,:root[theme=dark] :not([theme])>*>.markdown-body .token.string,:root[theme=dark] :not([theme])>*>.markdown-body .token.variable,:root[theme] [theme=dark] .markdown-body .token.attr-value,:root[theme] [theme=dark] .markdown-body .token.char,:root[theme] [theme=dark] .markdown-body .token.regex,:root[theme] [theme=dark] .markdown-body .token.string,:root[theme] [theme=dark] .markdown-body .token.variable{color:#7ec699}:root[theme=dark] :not([theme])>*>.markdown-body .token.entity,:root[theme=dark] :not([theme])>*>.markdown-body .token.operator,:root[theme=dark] :not([theme])>*>.markdown-body .token.url,:root[theme] [theme=dark] .markdown-body .token.entity,:root[theme] [theme=dark] .markdown-body .token.operator,:root[theme] [theme=dark] .markdown-body .token.url{color:#67cdcc}:root[theme=dark] :not([theme])>*>.markdown-body .token.bold,:root[theme=dark] :not([theme])>*>.markdown-body .token.important,:root[theme] [theme=dark] .markdown-body .token.bold,:root[theme] [theme=dark] .markdown-body .token.important{font-weight:700}:root[theme=dark] :not([theme])>*>.markdown-body .token.italic,:root[theme] [theme=dark] .markdown-body .token.italic{font-style:italic}:root[theme=dark] :not([theme])>*>.markdown-body .token.entity,:root[theme] [theme=dark] .markdown-body .token.entity{cursor:help}:root[theme=dark] :not([theme])>*>.markdown-body .token.inserted,:root[theme] [theme=dark] .markdown-body .token.inserted{color:green}:root[theme=light] :not([theme])>*>.markdown-body code[class*=language-],:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=light] .markdown-body code[class*=language-],:root[theme] [theme=light] .markdown-body pre[class*=language-]{word-wrap:normal;background:none;color:#000;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;text-shadow:0 1px #fff;white-space:pre;word-break:normal;word-spacing:normal}:root[theme=light] :not([theme])>*>.markdown-body code[class*=language-] ::selection,:root[theme=light] :not([theme])>*>.markdown-body code[class*=language-]::selection,:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-] ::selection,:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-]::selection,:root[theme] [theme=light] .markdown-body code[class*=language-] ::selection,:root[theme] [theme=light] .markdown-body code[class*=language-]::selection,:root[theme] [theme=light] .markdown-body pre[class*=language-] ::selection,:root[theme] [theme=light] .markdown-body pre[class*=language-]::selection{background:#b3d4fc;text-shadow:none}:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=light] .markdown-body pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:root[theme=light] :not([theme])>*>.markdown-body :not(pre)>code[class*=language-],:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=light] .markdown-body :not(pre)>code[class*=language-],:root[theme] [theme=light] .markdown-body pre[class*=language-]{background:#f5f2f0}:root[theme=light] :not([theme])>*>.markdown-body :not(pre)>code[class*=language-],:root[theme] [theme=light] .markdown-body :not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}:root[theme=light] :not([theme])>*>.markdown-body .token.cdata,:root[theme=light] :not([theme])>*>.markdown-body .token.comment,:root[theme=light] :not([theme])>*>.markdown-body .token.doctype,:root[theme=light] :not([theme])>*>.markdown-body .token.prolog,:root[theme] [theme=light] .markdown-body .token.cdata,:root[theme] [theme=light] .markdown-body .token.comment,:root[theme] [theme=light] .markdown-body .token.doctype,:root[theme] [theme=light] .markdown-body .token.prolog{color:#708090}:root[theme=light] :not([theme])>*>.markdown-body .token.punctuation,:root[theme] [theme=light] .markdown-body .token.punctuation{color:#999}:root[theme=light] :not([theme])>*>.markdown-body .token.namespace,:root[theme] [theme=light] .markdown-body .token.namespace{opacity:.7}:root[theme=light] :not([theme])>*>.markdown-body .token.boolean,:root[theme=light] :not([theme])>*>.markdown-body .token.constant,:root[theme=light] :not([theme])>*>.markdown-body .token.deleted,:root[theme=light] :not([theme])>*>.markdown-body .token.number,:root[theme=light] :not([theme])>*>.markdown-body .token.property,:root[theme=light] :not([theme])>*>.markdown-body .token.symbol,:root[theme=light] :not([theme])>*>.markdown-body .token.tag,:root[theme] [theme=light] .markdown-body .token.boolean,:root[theme] [theme=light] .markdown-body .token.constant,:root[theme] [theme=light] .markdown-body .token.deleted,:root[theme] [theme=light] .markdown-body .token.number,:root[theme] [theme=light] .markdown-body .token.property,:root[theme] [theme=light] .markdown-body .token.symbol,:root[theme] [theme=light] .markdown-body .token.tag{color:#905}:root[theme=light] :not([theme])>*>.markdown-body .token.attr-name,:root[theme=light] :not([theme])>*>.markdown-body .token.builtin,:root[theme=light] :not([theme])>*>.markdown-body .token.char,:root[theme=light] :not([theme])>*>.markdown-body .token.inserted,:root[theme=light] :not([theme])>*>.markdown-body .token.selector,:root[theme=light] :not([theme])>*>.markdown-body .token.string,:root[theme] [theme=light] .markdown-body .token.attr-name,:root[theme] [theme=light] .markdown-body .token.builtin,:root[theme] [theme=light] .markdown-body .token.char,:root[theme] [theme=light] .markdown-body .token.inserted,:root[theme] [theme=light] .markdown-body .token.selector,:root[theme] [theme=light] .markdown-body .token.string{color:#690}:root[theme=light] :not([theme])>*>.markdown-body .language-css .token.string,:root[theme=light] :not([theme])>*>.markdown-body .style .token.string,:root[theme=light] :not([theme])>*>.markdown-body .token.entity,:root[theme=light] :not([theme])>*>.markdown-body .token.operator,:root[theme=light] :not([theme])>*>.markdown-body .token.url,:root[theme] [theme=light] .markdown-body .language-css .token.string,:root[theme] [theme=light] .markdown-body .style .token.string,:root[theme] [theme=light] .markdown-body .token.entity,:root[theme] [theme=light] .markdown-body .token.operator,:root[theme] [theme=light] .markdown-body .token.url{background:#ffffff80;color:#9a6e3a}:root[theme=light] :not([theme])>*>.markdown-body .token.atrule,:root[theme=light] :not([theme])>*>.markdown-body .token.attr-value,:root[theme=light] :not([theme])>*>.markdown-body .token.keyword,:root[theme] [theme=light] .markdown-body .token.atrule,:root[theme] [theme=light] .markdown-body .token.attr-value,:root[theme] [theme=light] .markdown-body .token.keyword{color:#07a}:root[theme=light] :not([theme])>*>.markdown-body .token.class-name,:root[theme=light] :not([theme])>*>.markdown-body .token.function,:root[theme] [theme=light] .markdown-body .token.class-name,:root[theme] [theme=light] .markdown-body .token.function{color:#dd4a68}:root[theme=light] :not([theme])>*>.markdown-body .token.important,:root[theme=light] :not([theme])>*>.markdown-body .token.regex,:root[theme=light] :not([theme])>*>.markdown-body .token.variable,:root[theme] [theme=light] .markdown-body .token.important,:root[theme] [theme=light] .markdown-body .token.regex,:root[theme] [theme=light] .markdown-body .token.variable{color:#e90}:root[theme=light] :not([theme])>*>.markdown-body .token.bold,:root[theme=light] :not([theme])>*>.markdown-body .token.important,:root[theme] [theme=light] .markdown-body .token.bold,:root[theme] [theme=light] .markdown-body .token.important{font-weight:700}:root[theme=light] :not([theme])>*>.markdown-body .token.italic,:root[theme] [theme=light] .markdown-body .token.italic{font-style:italic}:root[theme=light] :not([theme])>*>.markdown-body .token.entity,:root[theme] [theme=light] .markdown-body .token.entity{cursor:help}@media print{:root[theme=light] :not([theme])>*>.markdown-body code[class*=language-],:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=light] .markdown-body code[class*=language-],:root[theme] [theme=light] .markdown-body pre[class*=language-]{text-shadow:none}}.markdown-body{word-wrap:break-word;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;font-size:16px;line-height:1.5}.markdown-body:after,.markdown-body:before{content:"";display:table}.markdown-body:after{clear:both}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:#c00}.markdown-body .anchor{float:left;line-height:1;margin-left:-20px;padding-right:4px}.markdown-body .anchor:focus{outline:none}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-bottom:16px;margin-top:0}.markdown-body hr{background-color:#e7e7e7;border:0;height:.25em;margin:24px 0;padding:0}.markdown-body blockquote{border-left:.25em solid #ddd;color:#777;font-size:16px;padding:0 1em}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body kbd,.popover kbd{background-color:#fcfcfc;border:1px solid;border-color:#ccc #ccc #bbb;border-radius:3px;box-shadow:inset 0 -1px 0 #bbb;color:#555;display:inline-block;font-size:11px;line-height:10px;padding:3px 5px;vertical-align:middle}.markdown-body .loweralpha{list-style-type:lower-alpha}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{font-weight:600;line-height:1.25;margin-bottom:16px;margin-top:24px}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#000;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 code,.markdown-body h1 tt,.markdown-body h2 code,.markdown-body h2 tt,.markdown-body h3 code,.markdown-body h3 tt,.markdown-body h4 code,.markdown-body h4 tt,.markdown-body h5 code,.markdown-body h5 tt,.markdown-body h6 code,.markdown-body h6 tt{font-size:inherit}.markdown-body h1{font-size:2em}.markdown-body h1,.markdown-body h2{border-bottom:1px solid #eee;padding-bottom:.3em}.markdown-body h2{font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{color:#777;font-size:.85em}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol.no-list,.markdown-body ul.no-list{list-style-type:none;padding:0}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-bottom:0;margin-top:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{padding-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{font-size:1em;font-style:italic;font-weight:700;margin-top:16px;padding:0}.markdown-body dl dd{margin-bottom:16px;padding:0 16px}.markdown-body table{display:block;overflow:auto;width:100%;word-break:normal;word-break:keep-all}.markdown-body table th{font-weight:700}.markdown-body table td,.markdown-body table th{border:1px solid #ddd}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{background-color:#fff;box-sizing:initial;max-width:100%}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{background-color:initial;max-width:none;vertical-align:text-top}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{border:1px solid #ddd;display:block;float:left;margin:13px 0 0;overflow:hidden;padding:7px;width:auto}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{clear:both;color:#333;display:block;padding:5px 0 0}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center>span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right>span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right>span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{background-color:#0000000a;border-radius:3px;font-size:85%;margin:0;padding:.2em 0}.markdown-body code:after,.markdown-body code:before,.markdown-body tt:after,.markdown-body tt:before{content:"\00a0";letter-spacing:-.2em}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{text-decoration:inherit}.markdown-body pre{word-wrap:normal}.markdown-body pre>code{background:#0000;border:0;font-size:100%;margin:0;padding:0;white-space:pre;word-break:normal}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{border-radius:3px;font-size:85%;line-height:1.45;overflow:auto}.markdown-body:not(.next-editor) pre{padding:16px}.markdown-body pre code,.markdown-body pre tt{word-wrap:normal;background-color:initial;border:0;display:inline;line-height:inherit;margin:0;max-width:auto;overflow:visible;padding:0}.markdown-body pre code:after,.markdown-body pre code:before,.markdown-body pre tt:after,.markdown-body pre tt:before{content:normal}.markdown-body .csv-data td,.markdown-body .csv-data th{font-size:12px;line-height:1;overflow:hidden;padding:5px;text-align:left;white-space:nowrap}.markdown-body .csv-data .blob-line-num{background:#fff;border:0;padding:10px 8px 9px;text-align:right}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{background:#f8f8f8;border-top:0;font-weight:700}.news .alert .markdown-body blockquote{border:0;padding:0 0 0 40px}.activity-tab .news .alert .commits,.activity-tab .news .markdown-body blockquote{padding-left:0}.task-list-item{list-style-type:none}.task-list-item label{font-weight:400}.task-list-item.enabled label{cursor:pointer}.task-list-item+.task-list-item{margin-top:3px}.task-list-item-checkbox{cursor:default!important;float:left;margin:.31em 0 .2em -1.3em!important;vertical-align:middle}.markdown-alert{border-left-style:solid;border-left-width:4px;color:inherit;margin-bottom:16px;padding:8px 16px}.markdown-alert .markdown-alert-title{align-items:center;display:flex;font-weight:500;line-height:1;white-space:break-spaces}.markdown-body .markdown-alert>*{margin-bottom:0;margin-top:16px}.markdown-body .markdown-alert .selection-popover,.markdown-body .markdown-alert>:first-child{margin-top:0}.markdown-alert.markdown-alert-note{border-left-color:var(--hmd-tw-state-info-default)}.markdown-alert.markdown-alert-note .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-state-info-text)}.markdown-alert.markdown-alert-tip{border-left-color:var(--hmd-tw-state-success-default)}.markdown-alert.markdown-alert-tip .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-state-success-text)}.markdown-alert.markdown-alert-important{border-left-color:var(--hmd-tw-border-primary-default)}.markdown-alert.markdown-alert-important .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-text-primary)}.markdown-alert.markdown-alert-warning{border-left-color:var(--hmd-tw-state-warning-default)}.markdown-alert.markdown-alert-warning .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-state-warning-text)}.markdown-alert.markdown-alert-caution{border-left-color:var(--hmd-tw-state-danger-default)}.markdown-alert.markdown-alert-caution .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-state-danger-text)}:root[theme=dark] :not([theme])>*>.markdown-body,:root[theme] [theme=dark] .markdown-body{color:#d4d4d8}:root[theme=dark] :not([theme])>*>.markdown-body h1,:root[theme=dark] :not([theme])>*>.markdown-body h2,:root[theme] [theme=dark] .markdown-body h1,:root[theme] [theme=dark] .markdown-body h2{border-bottom-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body h6,:root[theme] [theme=dark] .markdown-body h6{color:#a1a1aa}:root[theme=dark] :not([theme])>*>.markdown-body details,:root[theme] [theme=dark] .markdown-body details{background-color:#303036;color:#d4d4d8}:root[theme=dark] :not([theme])>*>.markdown-body details summary::marker:first-child,:root[theme] [theme=dark] .markdown-body details summary::marker:first-child{color:#d4d4d8}:root[theme=dark] :not([theme])>*>.markdown-body details:hover,:root[theme] [theme=dark] .markdown-body details:hover{background:#303036}:root[theme=dark] :not([theme])>*>.markdown-body details code,:root[theme=dark] :not([theme])>*>.markdown-body details[open]:hover,:root[theme] [theme=dark] .markdown-body details code,:root[theme] [theme=dark] .markdown-body details[open]:hover{background-color:#303036}:root[theme=dark] :not([theme])>*>.markdown-body hr,:root[theme] [theme=dark] .markdown-body hr{background-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body blockquote,:root[theme] [theme=dark] .markdown-body blockquote{border-left-color:#71717a;color:#a1a1aa}:root[theme=dark] :not([theme])>*>.markdown-body blockquote a span,:root[theme] [theme=dark] .markdown-body blockquote a span{color:#9894f9}:root[theme=dark] :not([theme])>*>.markdown-body a.mention-anchor.user-card-popover,:root[theme] [theme=dark] .markdown-body a.mention-anchor.user-card-popover{background-color:#453aff26;color:#9894f9}:root[theme=dark] :not([theme])>*>.markdown-body ::selection,:root[theme] [theme=dark] .markdown-body ::selection{background-color:#453aff99}:root[theme=dark] :not([theme])>*>.markdown-body .alert.alert-info,:root[theme] [theme=dark] .markdown-body .alert.alert-info{background-color:#38bdf81a;border-left-color:#0ea5e9;color:#38bdf8}:root[theme=dark] :not([theme])>*>.markdown-body .alert.alert-warning,:root[theme] [theme=dark] .markdown-body .alert.alert-warning{background-color:#fbbf241a;border-left-color:#f59e0b;color:#f59e0b}:root[theme=dark] :not([theme])>*>.markdown-body .alert.alert-success,:root[theme] [theme=dark] .markdown-body .alert.alert-success{background-color:#6db19d26;border-left-color:#55b685;color:#6db19d}:root[theme=dark] :not([theme])>*>.markdown-body .alert.alert-danger,:root[theme] [theme=dark] .markdown-body .alert.alert-danger{background-color:#ef444433;border-left-color:#ef4444;color:#f87171}:root[theme=dark] :not([theme])>*>.markdown-body .mark,:root[theme=dark] :not([theme])>*>.markdown-body mark,:root[theme] [theme=dark] .markdown-body .mark,:root[theme] [theme=dark] .markdown-body mark{background-color:#fbbf241a;color:#f59e0b}:root[theme=dark] :not([theme])>*>.markdown-body .mark span,:root[theme=dark] :not([theme])>*>.markdown-body mark span,:root[theme] [theme=dark] .markdown-body .mark span,:root[theme] [theme=dark] .markdown-body mark span{color:#fbbf24}:root[theme=dark] :not([theme])>*>.markdown-body .highlight pre,:root[theme=dark] :not([theme])>*>.markdown-body pre,:root[theme] [theme=dark] .markdown-body .highlight pre,:root[theme] [theme=dark] .markdown-body pre{background-color:#303036;color:#a1a1aa}:root[theme=dark] :not([theme])>*>.markdown-body .style .token.string,:root[theme=dark] :not([theme])>*>.markdown-body .token.entity,:root[theme=dark] :not([theme])>*>.markdown-body .token.operator,:root[theme=dark] :not([theme])>*>.markdown-body .token.url,:root[theme=dark] :not([theme])>*>.markdown-body.language-css,:root[theme=dark] :not([theme])>*>.markdown-body.token.string,:root[theme] [theme=dark] .markdown-body .style .token.string,:root[theme] [theme=dark] .markdown-body .token.entity,:root[theme] [theme=dark] .markdown-body .token.operator,:root[theme] [theme=dark] .markdown-body .token.url,:root[theme] [theme=dark] .markdown-body.language-css,:root[theme] [theme=dark] .markdown-body.token.string{background:none}:root[theme=dark] :not([theme])>*>.markdown-body :not(pre)>code,:root[theme] [theme=dark] .markdown-body :not(pre)>code{background-color:#3f3f46}:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-tag,:root[theme] [theme=dark] .markdown-body code .hljs-tag{color:#d4d4d8}:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-keyword,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-selector-tag,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-type,:root[theme=dark] :not([theme])>*>.markdown-body code .token.boolean,:root[theme=dark] :not([theme])>*>.markdown-body code .token.constant,:root[theme=dark] :not([theme])>*>.markdown-body code .token.deleted,:root[theme=dark] :not([theme])>*>.markdown-body code .token.number,:root[theme=dark] :not([theme])>*>.markdown-body code .token.property,:root[theme=dark] :not([theme])>*>.markdown-body code .token.symbol,:root[theme=dark] :not([theme])>*>.markdown-body code .token.tag,:root[theme] [theme=dark] .markdown-body code .hljs-keyword,:root[theme] [theme=dark] .markdown-body code .hljs-selector-tag,:root[theme] [theme=dark] .markdown-body code .hljs-type,:root[theme] [theme=dark] .markdown-body code .token.boolean,:root[theme] [theme=dark] .markdown-body code .token.constant,:root[theme] [theme=dark] .markdown-body code .token.deleted,:root[theme] [theme=dark] .markdown-body code .token.number,:root[theme] [theme=dark] .markdown-body code .token.property,:root[theme] [theme=dark] .markdown-body code .token.symbol,:root[theme] [theme=dark] .markdown-body code .token.tag{color:#ff70b4}:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-attribute,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-bullet,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-literal,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-number,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-symbol,:root[theme=dark] :not([theme])>*>.markdown-body code .token.atrule,:root[theme=dark] :not([theme])>*>.markdown-body code .token.attr-value,:root[theme=dark] :not([theme])>*>.markdown-body code .token.keyword,:root[theme] [theme=dark] .markdown-body code .hljs-attribute,:root[theme] [theme=dark] .markdown-body code .hljs-bullet,:root[theme] [theme=dark] .markdown-body code .hljs-literal,:root[theme] [theme=dark] .markdown-body code .hljs-number,:root[theme] [theme=dark] .markdown-body code .hljs-symbol,:root[theme] [theme=dark] .markdown-body code .token.atrule,:root[theme] [theme=dark] .markdown-body code .token.attr-value,:root[theme] [theme=dark] .markdown-body code .token.keyword{color:#9894f9}:root[theme=dark] :not([theme])>*>.markdown-body pre.plugin-rendered,:root[theme] [theme=dark] .markdown-body pre.plugin-rendered{background-color:#fff;color:#000}:root[theme=dark] :not([theme])>*>.markdown-body table,:root[theme] [theme=dark] .markdown-body table{border-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body table thead tr,:root[theme] [theme=dark] .markdown-body table thead tr{background-color:#303036;border-bottom-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body table td,:root[theme=dark] :not([theme])>*>.markdown-body table th,:root[theme] [theme=dark] .markdown-body table td,:root[theme] [theme=dark] .markdown-body table th{border-left-color:#52525b;border-top-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body table tbody tr,:root[theme=dark] :not([theme])>*>.markdown-body table tr:nth-child(2n),:root[theme] [theme=dark] .markdown-body table tbody tr,:root[theme] [theme=dark] .markdown-body table tr:nth-child(2n){background-color:#27272a}:root[theme=light] :not([theme])>*>.markdown-body,:root[theme] [theme=light] .markdown-body{color:#3f3f46}:root[theme=light] :not([theme])>*>.markdown-body h1,:root[theme=light] :not([theme])>*>.markdown-body h2,:root[theme] [theme=light] .markdown-body h1,:root[theme] [theme=light] .markdown-body h2{border-bottom-color:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body h6,:root[theme] [theme=light] .markdown-body h6{color:#71717a}:root[theme=light] :not([theme])>*>.markdown-body iframe,:root[theme] [theme=light] .markdown-body iframe{border:1px solid #e4e4e7;box-sizing:border-box}:root[theme=light] :not([theme])>*>.markdown-body details,:root[theme] [theme=light] .markdown-body details{background-color:#f4f4f5}:root[theme=light] :not([theme])>*>.markdown-body details:hover,:root[theme] [theme=light] .markdown-body details:hover{background:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body details[open]:hover,:root[theme] [theme=light] .markdown-body details[open]:hover{background-color:#f4f4f5}:root[theme=light] :not([theme])>*>.markdown-body details code,:root[theme] [theme=light] .markdown-body details code{background-color:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body hr,:root[theme] [theme=light] .markdown-body hr{background-color:#d4d4d8}:root[theme=light] :not([theme])>*>.markdown-body blockquote,:root[theme] [theme=light] .markdown-body blockquote{border-left-color:#e4e4e7;color:#71717a}:root[theme=light] :not([theme])>*>.markdown-body blockquote a span,:root[theme] [theme=light] .markdown-body blockquote a span{color:#564dff}:root[theme=light] :not([theme])>*>.markdown-body a.mention-anchor.user-card-popover,:root[theme] [theme=light] .markdown-body a.mention-anchor.user-card-popover{background-color:#ecebfe;color:#564dff}:root[theme=light] :not([theme])>*>.markdown-body ::selection,:root[theme] [theme=light] .markdown-body ::selection{background-color:#cccafc}:root[theme=light] :not([theme])>*>.markdown-body .alert.alert-info,:root[theme] [theme=light] .markdown-body .alert.alert-info{background-color:#e0f2fe;border-left-color:#0284c7;color:#0284c7}:root[theme=light] :not([theme])>*>.markdown-body .alert.alert-warning,:root[theme] [theme=light] .markdown-body .alert.alert-warning{background-color:#fef3c799;border-left-color:#f59e0b;color:#f59e0b}:root[theme=light] :not([theme])>*>.markdown-body .alert.alert-success,:root[theme] [theme=light] .markdown-body .alert.alert-success{background-color:#d9f9e5;border-left-color:#43946c;color:#43946c}:root[theme=light] :not([theme])>*>.markdown-body .alert.alert-danger,:root[theme] [theme=light] .markdown-body .alert.alert-danger{background-color:#fee2e299;border-left-color:#ef4444;color:#ef4444}:root[theme=light] :not([theme])>*>.markdown-body .mark,:root[theme=light] :not([theme])>*>.markdown-body mark,:root[theme] [theme=light] .markdown-body .mark,:root[theme] [theme=light] .markdown-body mark{background-color:#fef3c799;color:#f59e0b}:root[theme=light] :not([theme])>*>.markdown-body .mark span,:root[theme=light] :not([theme])>*>.markdown-body mark span,:root[theme] [theme=light] .markdown-body .mark span,:root[theme] [theme=light] .markdown-body mark span{color:#f59e0b}:root[theme=light] :not([theme])>*>.markdown-body .highlight pre,:root[theme=light] :not([theme])>*>.markdown-body pre,:root[theme] [theme=light] .markdown-body .highlight pre,:root[theme] [theme=light] .markdown-body pre{background-color:#f4f4f5}:root[theme=light] :not([theme])>*>.markdown-body pre.plugin-rendered,:root[theme] [theme=light] .markdown-body pre.plugin-rendered{background-color:inherit;color:inherit}:root[theme=light] :not([theme])>*>.markdown-body :not(pre)>code,:root[theme] [theme=light] .markdown-body :not(pre)>code{background-color:#0000000a}:root[theme=light] :not([theme])>*>.markdown-body table,:root[theme] [theme=light] .markdown-body table{border-color:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body table thead tr,:root[theme] [theme=light] .markdown-body table thead tr{background-color:#f4f4f5;border-bottom-color:#d4d4d8}:root[theme=light] :not([theme])>*>.markdown-body table td,:root[theme=light] :not([theme])>*>.markdown-body table th,:root[theme] [theme=light] .markdown-body table td,:root[theme] [theme=light] .markdown-body table th{border-left-color:#e4e4e7;border-top-color:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body table tbody tr,:root[theme=light] :not([theme])>*>.markdown-body table tr:nth-child(2n),:root[theme] [theme=light] .markdown-body table tbody tr,:root[theme] [theme=light] .markdown-body table tr:nth-child(2n){background-color:#fdfdfd}.markdown-body{font-family:Inter,-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,system-ui,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;max-width:758px;overflow:visible!important;padding-bottom:40px;padding-top:40px;position:relative}.markdown-body>*{max-width:100%}.markdown-body .alert a,.markdown-body a{color:var(--hmd-tw-link-text-default, #337ab7)}.markdown-body .alert a:focus,.markdown-body .alert a:hover,.markdown-body a:focus,.markdown-body a:hover{color:var(--hmd-tw-link-text-hover)}.markdown-body .alert a:hover,.markdown-body a:hover{text-decoration-thickness:2px;text-underline-offset:4px}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5{font-family:Readex Pro,-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;font-weight:700}.markdown-body h1,.markdown-body h2{border-bottom:1px solid}.markdown-body iframe,.markdown-body img{background-color:initial;border-radius:6px;margin:.5rem 0}.markdown-body iframe{max-width:100%;width:728px}.markdown-body details{border-radius:4px;margin-bottom:.5rem;padding:.5rem 1rem}.markdown-body details:hover{transition:all .1s}.markdown-body details summary+p{margin-top:.5rem}.markdown-body details p:last-child{margin-bottom:0}.markdown-body hr{height:2px}.markdown-body img.emoji{border:none;height:20px;vertical-align:middle;width:20px}.markdown-body li small{color:#a1a1aa}.markdown-body blockquote{border-left:3px solid}.markdown-body blockquote .small,.markdown-body blockquote small,.markdown-body li small{display:initial;font-size:85%}.markdown-body a.mention-anchor:before{content:"";margin-right:0}.markdown-body a.mention-anchor.user-card-popover{border-radius:4px;padding:1px 4px}.markdown-body .alert{border:none;border-radius:4px;margin-top:10px}.markdown-body .alert h2,.markdown-body .alert h3,.markdown-body .alert h4,.markdown-body .alert h5,.markdown-body .alert h6{margin-top:0}.markdown-body .alert h2{border:none}.markdown-body .alert.alert-danger,.markdown-body .alert.alert-info,.markdown-body .alert.alert-success,.markdown-body .alert.alert-warning{border-left:3px solid}.markdown-body .highlight pre,.markdown-body .mark,.markdown-body mark,.markdown-body pre{border-radius:4px}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.fretboard,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega-embed{border-radius:4px;max-width:100%;overflow:auto}.markdown-body .code-block-wrapper{border-radius:4px;outline-color:#0000;outline-style:solid;outline-width:1px;position:relative}.markdown-body .code-block-wrapper .code-toolbar{--tw-translate-y:-100%;--tw-shadow:0 3px 15px 0 #00000026;--tw-shadow-colored:0 3px 15px 0 var(--tw-shadow-color);background-color:var(--hmd-tw-element-bg-default);border-color:var(--hmd-tw-border-default);border-radius:4px;border-style:solid;border-width:1px;box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow);opacity:0;position:absolute;right:0;top:-1px;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));transition-duration:.15s;transition-property:all;transition-timing-function:cubic-bezier(.4,0,.2,1);visibility:hidden}.markdown-body .code-block-wrapper:hover{outline-color:var(--hmd-tw-border-primary-default);transition-duration:.15s;transition-property:outline-color;transition-timing-function:cubic-bezier(.4,0,.2,1)}.markdown-body .code-block-wrapper:hover .code-toolbar{opacity:1;visibility:visible}.markdown-body table{border:1px solid;border-radius:4px;width:fit-content}.markdown-body table thead tr{border-bottom:1px solid;border-top:none}.markdown-body table tbody tr,.markdown-body table thead tr th{border-top:none}.markdown-body table tbody tr td:first-child,.markdown-body table thead,.markdown-body table thead th:first-child{border-left:none}.markdown-body table td,.markdown-body table th{border:1px solid;border-bottom:none;border-right:none;padding:6px 13px}.markdown-body.next-editor{overflow-x:hidden!important}.markdown-body pre{border:inherit}.markdown-body code{color:inherit}html[lang^=ja] .markdown-body code code,html[lang^=ja] .markdown-body code kbd,html[lang^=ja] .markdown-body code pre{font-family:Source Code Pro,Consolas,monaco,Meiryo, ,MS Gothic,monospace}html[lang=zh-tw] .markdown-body code code,html[lang=zh-tw] .markdown-body code kbd,html[lang=zh-tw] .markdown-body code pre{font-family:Source Code Pro,Consolas,monaco,Microsoft JhengHei,,monospace}html[lang=zh-cn] .markdown-body code code,html[lang=zh-cn] .markdown-body code kbd,html[lang=zh-cn] .markdown-body code pre{font-family:Source Code Pro,Consolas,monaco,Microsoft YaHei,,monospace}html .markdown-body code[lang^=ja] code,html .markdown-body code[lang^=ja] kbd,html .markdown-body code[lang^=ja] pre{font-family:Source Code Pro,Consolas,monaco,Meiryo, ,MS Gothic,monospace}html .markdown-body code[lang=zh-tw] code,html .markdown-body code[lang=zh-tw] kbd,html .markdown-body code[lang=zh-tw] pre{font-family:Source Code Pro,Consolas,monaco,Microsoft JhengHei,,monospace}html .markdown-body code[lang=zh-cn] code,html .markdown-body code[lang=zh-cn] kbd,html .markdown-body code[lang=zh-cn] pre{font-family:Source Code Pro,Consolas,monaco,Microsoft YaHei,,monospace}.markdown-body pre code .wrapper{display:-moz-inline-flex;display:-ms-inline-flex;display:-o-inline-flex;display:inline-flex}.markdown-body pre code .gutter{float:left;overflow:hidden;-webkit-user-select:none;user-select:none}.markdown-body pre code .gutter.linenumber{border-right:2px solid #766df8;box-sizing:initial;color:#a1a1aa;cursor:default;display:inline-block;min-width:20px;padding:0 8px 0 0;position:relative;text-align:right;z-index:4}.markdown-body pre code .gutter.linenumber>span:before{content:attr(data-linenumber)}.markdown-body pre code .code{float:left;margin:0 0 0 16px}.markdown-body .gist .line-numbers{border-bottom:none;border-left:none;border-top:none}.markdown-body .gist .line-data{border:none}.markdown-body .gist table{border-collapse:inherit!important;border-spacing:0}.markdown-body code[data-gist-id]{background:none;padding:0}.markdown-body code[data-gist-id]:after,.markdown-body code[data-gist-id]:before{content:""}.markdown-body code[data-gist-id] .blob-num{border:unset}.markdown-body code[data-gist-id] table{margin-bottom:unset;overflow:unset}.markdown-body code[data-gist-id] table tr{background:unset}.markdown-body[dir=rtl] pre{direction:ltr}.markdown-body[dir=rtl] code{direction:ltr;unicode-bidi:embed}.markdown-body .alert{display:flex;flex-direction:column;gap:16px}.markdown-body .alert>*{margin:0}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega{background-color:inherit;border-radius:0;overflow:visible;text-align:center;white-space:inherit}.markdown-body pre.abc>code,.markdown-body pre.flow-chart>code,.markdown-body pre.graphviz>code,.markdown-body pre.mermaid>code,.markdown-body pre.sequence-diagram>code,.markdown-body pre.vega>code{text-align:left}.markdown-body pre.abc>svg,.markdown-body pre.flow-chart>svg,.markdown-body pre.graphviz>svg,.markdown-body pre.mermaid>svg,.markdown-body pre.sequence-diagram>svg,.markdown-body pre.vega>svg{height:100%;max-width:100%}.markdown-body pre>code.wrap{word-wrap:break-word;white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap}.markdown-body pre.pseudocode{white-space-collapse:collapse}.markdown-body summary{display:list-item}.markdown-body summary:focus{outline:none}.markdown-body details summary{cursor:pointer}.markdown-body details:not([open])>:not(summary){display:none}.markdown-body figure{margin:1em 40px}.markdown-body .mark,.markdown-body mark{background-color:#fff1a7}:root[theme] .markdown-body{line-height:1.75}:root[theme] .markdown-body ::marker,:root[theme] .markdown-body code{color:var(--hmd-tw-text-default)}:root[theme] .markdown-body h1,:root[theme] .markdown-body h2,:root[theme] .markdown-body h3,:root[theme] .markdown-body h4,:root[theme] .markdown-body h5,:root[theme] .markdown-body h6{overflow:visible}:root[theme] .markdown-body h1 .octicon-link,:root[theme] .markdown-body h2 .octicon-link,:root[theme] .markdown-body h3 .octicon-link,:root[theme] .markdown-body h4 .octicon-link,:root[theme] .markdown-body h5 .octicon-link,:root[theme] .markdown-body h6 .octicon-link{color:var(--hmd-tw-text-subtle)}:root[theme] .markdown-body .anchor{left:0;margin-left:0;position:absolute}:root[theme] .markdown-body .gist table{border-color:inherit}:root[theme] .markdown-body .gist table thead tr{background-color:inherit;border-bottom-color:inherit}:root[theme] .markdown-body .gist table td,:root[theme] .markdown-body .gist table th{border-left-color:inherit;border-top-color:inherit}:root[theme] .markdown-body .gist table tbody tr,:root[theme] .markdown-body .gist table tr:nth-child(2n){background-color:inherit}:root[theme] .markdown-body ol ol,:root[theme] .markdown-body ol ul,:root[theme] .markdown-body ul ol,:root[theme] .markdown-body ul ul{margin-bottom:12px;margin-top:6px}@media (max-width:767px){.markdown-body h1{font-size:1.6em}.markdown-body h2{font-size:1.4em}.markdown-body h3{font-size:1.125em}}.vimeo,.youtube{background-color:#000;background-position:50%;background-repeat:no-repeat;background-size:contain;cursor:pointer;display:table;overflow:hidden;text-align:center}.vimeo,.youtube{position:relative;width:100%}.youtube{padding-bottom:56.25%}.vimeo img{object-fit:contain;width:100%;z-index:0}.youtube img{object-fit:cover;z-index:0}.vimeo iframe,.youtube iframe,.youtube img{height:100%;left:0;position:absolute;top:0;width:100%}.vimeo iframe,.youtube iframe{vertical-align:middle;z-index:1}.vimeo .icon,.youtube .icon{color:#fff;height:auto;left:50%;opacity:.3;position:absolute;top:50%;transform:translate(-50%,-50%);transition:opacity .2s;width:auto;z-index:0}.vimeo:hover .icon,.youtube:hover .icon{opacity:.6;transition:opacity .2s}.slideshare .inner,.speakerdeck .inner{position:relative;width:100%}.slideshare .inner iframe,.speakerdeck .inner iframe{bottom:0;height:100%;left:0;position:absolute;right:0;top:0;width:100%}.figma{display:table;padding-bottom:56.25%;position:relative;width:100%}.figma iframe{border:1px solid #eee;bottom:0;height:100%;left:0;position:absolute;right:0;top:0;width:100%}.markmap-container{height:300px}.markmap-container>svg{height:100%;width:100%}.MJX_Assistive_MathML{display:none}#MathJax_Message{z-index:1000!important}.ui-infobar{color:var(--hmd-tw-text-default);font-size:14px;margin:25px auto -25px;max-width:760px;position:relative;z-index:2}.ui-infobar .ui-user-icon.small{height:18px;margin:2px;vertical-align:top;width:18px}.toc .invisable-node{list-style-type:none}.ui-toc{bottom:20px;position:fixed;z-index:998}.ui-toc.both-mode{margin-left:2px}.ui-toc.both-mode .ui-toc-label{border-bottom-left-radius:0;border-top-left-radius:0;height:40px;padding:10px 4px}:root[theme=light] :not([theme])>*>.ui-toc .ui-toc-label,:root[theme] [theme=light] .ui-toc-label{background-color:#fdfdfd;border-color:#d4d4d8;color:#a1a1aa}:root[theme=light] :not([theme])>*>.ui-toc .ui-toc-label:active,:root[theme=light] :not([theme])>*>.ui-toc .ui-toc-label:hover,:root[theme] [theme=light] .ui-toc-label:active,:root[theme] [theme=light] .ui-toc-label:hover{background-color:#f4f4f5;border-color:#d4d4d8;color:#a1a1aa}:root[theme=dark] :not([theme])>*>.ui-toc .ui-toc-label,:root[theme=dark] :not([theme])>*>.ui-toc .ui-toc-label:active,:root[theme=dark] :not([theme])>*>.ui-toc .ui-toc-label:hover,:root[theme] [theme=dark] .ui-toc-label,:root[theme] [theme=dark] .ui-toc-label:active,:root[theme] [theme=dark] .ui-toc-label:hover{background-color:#303036;border-color:#52525b;color:#a1a1aa}:root[theme=dark] :not([theme])>*>.ui-toc.both-mode .ui-toc-label,:root[theme] [theme=dark] .ui-toc.both-mode .ui-toc-label{background-color:#303036;border-color:#3f3f46;color:#d4d4d8}:root[theme=dark] :not([theme])>*>.ui-toc.both-mode .ui-toc-label:hover,:root[theme] [theme=dark] .ui-toc.both-mode .ui-toc-label:hover{background-color:#52525b}.ui-toc-label{border:1px solid;transition:opacity .2s}.ui-toc .open .ui-toc-label,.ui-toc-label:hover{opacity:1;transition:opacity .2s}.ui-toc-dropdown{letter-spacing:normal;margin-bottom:20px;margin-top:20px;max-height:70vh;max-width:45vw;overflow:auto;padding-left:10px;padding-right:10px;text-align:inherit;width:25vw}.ui-toc-dropdown.dropdown-menu{box-shadow:0 3px 15px 0 #00000026}.ui-toc-dropdown>.toc{max-height:calc(70vh - 100px);overflow:auto}.ui-toc-dropdown[dir=rtl] .nav{letter-spacing:.0029em;padding-right:0}.ui-toc-dropdown a{overflow:hidden;text-overflow:ellipsis;white-space:pre}.ui-toc-dropdown .nav>li>a{color:var(--hmd-tw-text-subtle);display:block;font-size:12px;font-weight:500;line-height:16px;padding:4px 20px}.ui-toc-dropdown .nav>li:first-child:last-child>ul,.ui-toc-dropdown .toc.expand ul{display:block}.ui-toc-dropdown .nav>li>a:focus,.ui-toc-dropdown .nav>li>a:hover{background-color:initial;border-color:var(--hmd-tw-border-bold);border-style:solid;border-width:0 0 0 1px;color:#000;color:var(--hmd-tw-text-emphasize);padding-left:19px;text-decoration:none}.ui-toc-dropdown[dir=rtl] .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav>li>a:hover{border-left:none;border-right:1px solid #000;padding-right:19px}.ui-toc-dropdown .nav>.active:focus>a,.ui-toc-dropdown .nav>.active:hover>a,.ui-toc-dropdown .nav>.active>a{background-color:initial;border-color:var(--hmd-tw-border-bold);border-style:solid;border-width:0 0 0 2px;color:var(--hmd-tw-text-emphasize);font-weight:600;padding-left:18px}.ui-toc-dropdown[dir=rtl] .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav>.active>a{border-width:0 2px 0 medium;border-left:0;border-color:var(--hmd-tw-border-bold);border-style:solid;padding-right:18px}.ui-toc-dropdown .nav .nav{display:none;padding-bottom:10px}.ui-toc-dropdown .nav>.active>ul{display:block}.ui-toc-dropdown .nav .nav>li>a{font-size:12px;font-weight:400;padding-bottom:1px;padding-left:30px;padding-top:1px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a{padding-right:30px}.ui-toc-dropdown .nav .nav>li>ul>li>a{font-size:12px;font-weight:400;padding-bottom:1px;padding-left:40px;padding-top:1px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a{padding-right:40px}.ui-toc-dropdown .nav .nav>li>a:focus,.ui-toc-dropdown .nav .nav>li>a:hover{padding-left:29px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:hover{padding-right:29px}.ui-toc-dropdown .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown .nav .nav>li>ul>li>a:hover{padding-left:39px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:hover{padding-right:39px}.ui-toc-dropdown .nav .nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>a{font-weight:500;padding-left:28px}.ui-toc-dropdown[dir=rtl] .nav .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>a{padding-right:28px}.ui-toc-dropdown .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active>a{font-weight:500;padding-left:38px}.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active>a{padding-right:38px}.ui-affix-toc{max-height:70vh;max-width:15vw;overflow:auto;position:fixed;top:0}.back-to-top,.expand-toggle,.go-to-bottom{color:var(--hmd-tw-text-subtle);display:block;font-size:12px;font-weight:500;line-height:16px;margin-left:10px;margin-top:10px;padding:2px 10px}.back-to-top:focus,.back-to-top:hover,.expand-toggle:focus,.expand-toggle:hover,.go-to-bottom:focus,.go-to-bottom:hover{color:var(--hmd-tw-text-primary);text-decoration:none}.back-to-top,.go-to-bottom{margin-top:0}.ui-user-icon{background-position:50%;background-repeat:no-repeat;background-size:cover;border-radius:50%;display:block;height:20px;margin-bottom:2px;margin-right:5px;margin-top:2px;width:20px}.ui-user-icon.small{display:inline-block;height:18px;margin:0 0 .2em;vertical-align:middle;width:18px}.ui-infobar>small>span{line-height:22px}.ui-infobar>small .dropdown{display:inline-block}.ui-infobar>small .dropdown a:focus,.ui-infobar>small .dropdown a:hover{text-decoration:none}.ui-more-info{cursor:pointer;vertical-align:middle}.ui-connectedGithub{line-height:23px;white-space:nowrap}.ui-connectedGithub a.file-path{text-decoration:none}.ui-connectedGithub a.file-path:active,.ui-connectedGithub a.file-path:hover{text-decoration:underline}.unselectable{-webkit-user-select:none;-o-user-select:none;user-select:none}.selectable{-webkit-user-select:text;-o-user-select:text;user-select:text}.inline-spoiler-section{cursor:pointer}.inline-spoiler-section .spoiler-text{background-color:#333;border-radius:2px}.inline-spoiler-section .spoiler-text>*{opacity:0}.inline-spoiler-section .spoiler-img{filter:blur(10px)}.inline-spoiler-section.raw{background-color:#333;border-radius:2px}.inline-spoiler-section.raw>*{opacity:0}.inline-spoiler-section.unveil{cursor:auto}.inline-spoiler-section.unveil .spoiler-text{background-color:#3333331a}.inline-spoiler-section.unveil .spoiler-text>*{opacity:1}.inline-spoiler-section.unveil .spoiler-img{filter:none}@media print{blockquote,div,img,pre,table{page-break-inside:avoid!important}a[href]:after{font-size:12px!important}}.markdown-body.slides{color:#222;position:relative;z-index:1}.markdown-body.slides:before{background-color:currentColor;bottom:0;box-shadow:0 0 0 50vw;content:"";display:block;left:0;position:absolute;right:0;top:0;z-index:-1}.markdown-body.slides section[data-markdown]{background-color:#fff;margin-bottom:1.5em;position:relative;text-align:center}.markdown-body.slides section[data-markdown] code{text-align:left}.markdown-body.slides section[data-markdown]:before{content:"";display:block;padding-bottom:56.23%}.markdown-body.slides section[data-markdown]>div:first-child{left:1em;max-height:100%;overflow:hidden;position:absolute;right:1em;top:50%;transform:translateY(-50%)}.markdown-body.slides section[data-markdown]>ul{display:inline-block}.markdown-body.slides>section>section+section:after{border:3px solid #777;content:"";height:1.5em;position:absolute;right:1em;top:-1.5em}.site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro, Pro W3,Osaka,Meiryo,,MS Gothic, ,sans-serif}html[lang=zh-tw] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,,sans-serif}html[lang=zh-cn] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,,sans-serif}body{font-smoothing:subpixel-antialiased!important;-webkit-font-smoothing:subpixel-antialiased!important;-moz-osx-font-smoothing:auto!important;-webkit-overflow-scrolling:touch;font-family:Source Sans Pro,Helvetica,Arial,sans-serif;letter-spacing:.025em}html[lang^=ja] body{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro, Pro W3,Osaka,Meiryo,,MS Gothic, ,sans-serif}html[lang=zh-tw] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,,sans-serif}html[lang=zh-cn] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,,sans-serif}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}abbr[data-original-title],abbr[title]{cursor:help}body.modal-open{overflow-y:auto;padding-right:0!important}svg{text-shadow:none}
    </style>

    <style>
        *,:before,:after {
            --tw-border-spacing-x: 0;
            --tw-border-spacing-y: 0;
            --tw-translate-x: 0;
            --tw-translate-y: 0;
            --tw-rotate: 0;
            --tw-skew-x: 0;
            --tw-skew-y: 0;
            --tw-scale-x: 1;
            --tw-scale-y: 1;
            --tw-pan-x: ;
            --tw-pan-y: ;
            --tw-pinch-zoom: ;
            --tw-scroll-snap-strictness: proximity;
            --tw-gradient-from-position: ;
            --tw-gradient-via-position: ;
            --tw-gradient-to-position: ;
            --tw-ordinal: ;
            --tw-slashed-zero: ;
            --tw-numeric-figure: ;
            --tw-numeric-spacing: ;
            --tw-numeric-fraction: ;
            --tw-ring-inset: ;
            --tw-ring-offset-width: 0px;
            --tw-ring-offset-color: #fff;
            --tw-ring-color: rgb(59 130 246 / .5);
            --tw-ring-offset-shadow: 0 0 #0000;
            --tw-ring-shadow: 0 0 #0000;
            --tw-shadow: 0 0 #0000;
            --tw-shadow-colored: 0 0 #0000;
            --tw-blur: ;
            --tw-brightness: ;
            --tw-contrast: ;
            --tw-grayscale: ;
            --tw-hue-rotate: ;
            --tw-invert: ;
            --tw-saturate: ;
            --tw-sepia: ;
            --tw-drop-shadow: ;
            --tw-backdrop-blur: ;
            --tw-backdrop-brightness: ;
            --tw-backdrop-contrast: ;
            --tw-backdrop-grayscale: ;
            --tw-backdrop-hue-rotate: ;
            --tw-backdrop-invert: ;
            --tw-backdrop-opacity: ;
            --tw-backdrop-saturate: ;
            --tw-backdrop-sepia: ;
            --tw-contain-size: ;
            --tw-contain-layout: ;
            --tw-contain-paint: ;
            --tw-contain-style:
        }

        ::backdrop {
            --tw-border-spacing-x: 0;
            --tw-border-spacing-y: 0;
            --tw-translate-x: 0;
            --tw-translate-y: 0;
            --tw-rotate: 0;
            --tw-skew-x: 0;
            --tw-skew-y: 0;
            --tw-scale-x: 1;
            --tw-scale-y: 1;
            --tw-pan-x: ;
            --tw-pan-y: ;
            --tw-pinch-zoom: ;
            --tw-scroll-snap-strictness: proximity;
            --tw-gradient-from-position: ;
            --tw-gradient-via-position: ;
            --tw-gradient-to-position: ;
            --tw-ordinal: ;
            --tw-slashed-zero: ;
            --tw-numeric-figure: ;
            --tw-numeric-spacing: ;
            --tw-numeric-fraction: ;
            --tw-ring-inset: ;
            --tw-ring-offset-width: 0px;
            --tw-ring-offset-color: #fff;
            --tw-ring-color: rgb(59 130 246 / .5);
            --tw-ring-offset-shadow: 0 0 #0000;
            --tw-ring-shadow: 0 0 #0000;
            --tw-shadow: 0 0 #0000;
            --tw-shadow-colored: 0 0 #0000;
            --tw-blur: ;
            --tw-brightness: ;
            --tw-contrast: ;
            --tw-grayscale: ;
            --tw-hue-rotate: ;
            --tw-invert: ;
            --tw-saturate: ;
            --tw-sepia: ;
            --tw-drop-shadow: ;
            --tw-backdrop-blur: ;
            --tw-backdrop-brightness: ;
            --tw-backdrop-contrast: ;
            --tw-backdrop-grayscale: ;
            --tw-backdrop-hue-rotate: ;
            --tw-backdrop-invert: ;
            --tw-backdrop-opacity: ;
            --tw-backdrop-saturate: ;
            --tw-backdrop-sepia: ;
            --tw-contain-size: ;
            --tw-contain-layout: ;
            --tw-contain-paint: ;
            --tw-contain-style:
        }

        :root,:root[theme=light],:root[theme] [theme=light] {
            --hmd-tw-text-default: #3F3F46;
            --hmd-tw-text-subtle: #71717A;
            --hmd-tw-text-subtler: #A1A1AA;
            --hmd-tw-text-emphasize: #27272A;
            --hmd-tw-text-primary: #564DFF;
            --hmd-tw-text-pink: #FF288F;
            --hmd-tw-background-default: #FDFDFD;
            --hmd-tw-background-subtle: #F4F4F5;
            --hmd-tw-background-subtler: #FAFAFA;
            --hmd-tw-background-sunken: #F4F4F5;
            --hmd-tw-background-selected: #F4F4F5;
            --hmd-tw-background-primary-default: #564DFF;
            --hmd-tw-background-primary-subtler: #ECEBFE;
            --hmd-tw-background-primary-subtle: #CCCAFC;
            --hmd-tw-background-primary-hover: #2E01A5;
            --hmd-tw-background-primary-disabled: #9894F9;
            --hmd-tw-background-primary-focus: #2E01A5;
            --hmd-tw-background-blur: rgba(253, 253, 253, .6);
            --hmd-tw-icon-default: #71717A;
            --hmd-tw-icon-subtle: #A1A1AA;
            --hmd-tw-icon-subtler: #D4D4D8;
            --hmd-tw-icon-subtlest: #E4E4E7;
            --hmd-tw-icon-disabled: #A1A1AA;
            --hmd-tw-icon-primary: var(--hmd-tw-text-primary);
            --hmd-tw-icon-emphasize: #27272A;
            --hmd-tw-border-default: #D4D4D8;
            --hmd-tw-border-bold: #52525B;
            --hmd-tw-border-subtle: #71717A;
            --hmd-tw-border-subtler: #A1A1AA;
            --hmd-tw-border-subtlest: #E4E4E7;
            --hmd-tw-border-primary-focus: #766DF8;
            --hmd-tw-border-primary-default: #564DFF;
            --hmd-tw-border-primary-subtler: #766DF8;
            --hmd-tw-border-primary-subtlest: #564DFF80;
            --hmd-tw-overlay: rgba(0, 0, 0, .3);
            --hmd-tw-state-info-text: #0284c7;
            --hmd-tw-state-info-icon: #0ea5e9;
            --hmd-tw-state-info-background: #e0f2fe;
            --hmd-tw-state-info-border: #bae6fd;
            --hmd-tw-state-info-border-subtle: rgb(186, 230, 253);
            --hmd-tw-state-info-default: #0ea5e9;
            --hmd-tw-state-success-text: #479C2B;
            --hmd-tw-state-success-icon: #76D158;
            --hmd-tw-state-success-background: #E5FBEF;
            --hmd-tw-state-success-border: #B6E7A6;
            --hmd-tw-state-success-border-subtle: rgba(182, 231, 166, 1);
            --hmd-tw-state-success-default: #76D158;
            --hmd-tw-state-warning-text: #d97706;
            --hmd-tw-state-warning-icon: #fbbf24;
            --hmd-tw-state-warning-background: #FEF8DD;
            --hmd-tw-state-warning-border: #fcd34d;
            --hmd-tw-state-warning-border-subtle: rgba(253, 230, 138, 1);
            --hmd-tw-state-warning-default: #fbbf24;
            --hmd-tw-state-danger-text: #ef4444;
            --hmd-tw-state-danger-icon: #ef4444;
            --hmd-tw-state-danger-bg-light: #FEEEEE;
            --hmd-tw-state-danger-bg-default: #ef4444;
            --hmd-tw-state-danger-bg-hover: #dc2626;
            --hmd-tw-state-danger-border: #fca5a5;
            --hmd-tw-state-danger-border-subtle: rgba(254, 202, 202, 1);
            --hmd-tw-state-danger-default: #ef4444;
            --hmd-tw-state-default-background: #D4D4D8;
            --hmd-tw-element-text-selected: #564DFF;
            --hmd-tw-element-text-disabled: #A1A1AA;
            --hmd-tw-element-bg-default: #fff;
            --hmd-tw-element-bg-hover: #F4F4F5;
            --hmd-tw-element-bg-disabled: #E4E4E7;
            --hmd-tw-element-border-hover: #71717A;
            --hmd-tw-element-border-focus: #71717A;
            --hmd-tw-element-border-error: #dc2626;
            --hmd-tw-element-border-disabled: var(--hmd-tw-border-subtler);
            --hmd-tw-raised-bg-default: #E4E4E7;
            --hmd-tw-raised-bg-hover: #D4D4D8;
            --hmd-tw-raised-border-default: #D4D4D8;
            --hmd-tw-raised-border-hover: #A1A1AA;
            --hmd-tw-raised-icon-hover: #52525B;
            --hmd-tw-raised-icon-default: #71717A;
            --hmd-tw-link-text-default: #564DFF;
            --hmd-tw-link-text-hover: #2E01A5;
            --hmd-tw-link-text-pressed: #2E01A5;
            --hmd-tw-text-mark-comment-default: #453AFF4D;
            --hmd-tw-text-mark-comment-selected: #453AFF73;
            --hmd-tw-text-mark-diff-del: #fee2e2;
            --hmd-tw-text-mark-diff-ins: #D9F9E5;
            --hmd-tw-text-mark-suggest-default: #B8F1D2;
            --hmd-tw-text-mark-suggest-selected: #8DE4BA;
            --hmd-tw-text-mark-suggest-border: #43946C;
            --hmd-tw-prime-border: #f59e0b;
            --hmd-tw-prime-default: #f59e0b
        }

        :root[theme=dark],:root[theme] [theme=dark] {
            --hmd-tw-text-default: #D4D4D8;
            --hmd-tw-text-subtle: #A1A1AA;
            --hmd-tw-text-subtler: #71717A;
            --hmd-tw-text-emphasize: #F4F4F5;
            --hmd-tw-text-primary: #9894F9;
            --hmd-tw-text-pink: #FF4CA2;
            --hmd-tw-background-default: #27272A;
            --hmd-tw-background-subtle: #52525B;
            --hmd-tw-background-subtler: #303036;
            --hmd-tw-background-sunken: #18181B;
            --hmd-tw-background-selected: #52525B;
            --hmd-tw-background-primary-default: #564DFF;
            --hmd-tw-background-primary-subtler: #2c2a4a;
            --hmd-tw-background-primary-subtle: #302d6a;
            --hmd-tw-background-primary-hover: #766DF8;
            --hmd-tw-background-primary-disabled: #3932aa;
            --hmd-tw-background-primary-focus: #766DF8;
            --hmd-tw-background-blur: rgba(39, 39, 42, .6);
            --hmd-tw-icon-default: #D4D4D8;
            --hmd-tw-icon-subtle: #A1A1AA;
            --hmd-tw-icon-subtler: #71717A;
            --hmd-tw-icon-subtlest: #52525B;
            --hmd-tw-icon-disabled: #71717A;
            --hmd-tw-icon-primary: var(--hmd-tw-text-primary);
            --hmd-tw-icon-emphasize: #F4F4F5;
            --hmd-tw-border-default: #52525B;
            --hmd-tw-border-bold: #D4D4D8;
            --hmd-tw-border-subtle: #A1A1AA;
            --hmd-tw-border-subtler: #71717A;
            --hmd-tw-border-subtlest: #3F3F46;
            --hmd-tw-border-primary-focus: #766DF8;
            --hmd-tw-border-primary-default: #9894F9;
            --hmd-tw-border-primary-subtler: #766DF8;
            --hmd-tw-border-primary-subtlest: #564DFF80;
            --hmd-tw-overlay: rgba(0, 0, 0, .7);
            --hmd-tw-state-info-text: #38bdf8;
            --hmd-tw-state-info-icon: #0ea5e9;
            --hmd-tw-state-info-background: #38BDF81A;
            --hmd-tw-state-info-border: #0284c7;
            --hmd-tw-state-info-border-subtle: rgba(56, 189, 248, .2);
            --hmd-tw-state-info-default: #0ea5e9;
            --hmd-tw-state-success-text: #59C335;
            --hmd-tw-state-success-icon: #59C335;
            --hmd-tw-state-success-background: #6DB19D26;
            --hmd-tw-state-success-border: #43946C;
            --hmd-tw-state-success-border-subtle: rgba(107, 209, 157, .2);
            --hmd-tw-state-success-default: #59C335;
            --hmd-tw-state-warning-text: #fbbf24;
            --hmd-tw-state-warning-icon: #fbbf24;
            --hmd-tw-state-warning-background: #FBBF241A;
            --hmd-tw-state-warning-border: #f59e0b;
            --hmd-tw-state-warning-border-subtle: rgba(251, 191, 36, .2);
            --hmd-tw-state-warning-default: #f59e0b;
            --hmd-tw-state-danger-text: #f87171;
            --hmd-tw-state-danger-icon: #f87171;
            --hmd-tw-state-danger-bg-light: #EF444433;
            --hmd-tw-state-danger-bg-default: #ef4444;
            --hmd-tw-state-danger-bg-hover: #f87171;
            --hmd-tw-state-danger-border: #f87171;
            --hmd-tw-state-danger-border-subtle: rgba(239, 68, 68, .3);
            --hmd-tw-state-danger-default: #f87171;
            --hmd-tw-state-default-background: #52525B;
            --hmd-tw-element-text-selected: #fff;
            --hmd-tw-element-text-disabled: #71717A;
            --hmd-tw-element-bg-default: var(--hmd-tw-background-subtler);
            --hmd-tw-element-bg-hover: #3F3F46;
            --hmd-tw-element-bg-disabled: #303036;
            --hmd-tw-element-border-hover: #71717A;
            --hmd-tw-element-border-focus: #71717A;
            --hmd-tw-element-border-error: #f87171;
            --hmd-tw-element-border-disabled: var(--hmd-tw-border-subtler);
            --hmd-tw-raised-bg-default: #3F3F46;
            --hmd-tw-raised-bg-hover: #52525B;
            --hmd-tw-raised-border-default: #52525B;
            --hmd-tw-raised-border-hover: #71717A;
            --hmd-tw-raised-icon-hover: #FAFAFA;
            --hmd-tw-raised-icon-default: #D4D4D8;
            --hmd-tw-link-text-default: #9894F9;
            --hmd-tw-link-text-hover: #B2ABFB;
            --hmd-tw-link-text-pressed: #B2ABFB;
            --hmd-tw-text-mark-comment-default: #453AFF4D;
            --hmd-tw-text-mark-comment-selected: #453AFF99;
            --hmd-tw-text-mark-diff-del: #EF444433;
            --hmd-tw-text-mark-diff-ins: #6DB19D4D;
            --hmd-tw-text-mark-suggest-default: rgba(64, 255, 106, .2);
            --hmd-tw-text-mark-suggest-selected: rgba(64, 255, 106, .4);
            --hmd-tw-text-mark-suggest-border: #6DB19D;
            --hmd-tw-prime-border: #fbbf24;
            --hmd-tw-prime-default: #fbbf24
        }
    </style>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js" integrity="sha256-g6iAfvZp+nDQ2TdTR/VVKJf3bGro4ub5fvWSWVRi2NE=" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js" integrity="sha256-8E4Is26QH0bD52WoQpcB+R/tcWQtpzlCojrybUd7Mxo=" crossorigin="anonymous"></script>
    <![endif]-->
</head>

<body>
    <div id="doc" class="markdown-body container-fluid comment-inner comment-enabled" data-hard-breaks="false"><p><strong><a href="http://cs.brown.edu/courses/csci1390/" target="_blank" rel="noopener"><span> Back to the CS1390 website</span></a></strong></p><h1 id="Assignment-1-Parallelism-Techniques-" data-id="Assignment-1-Parallelism-Techniques-"><a class="anchor hidden-xs" href="#Assignment-1-Parallelism-Techniques-" title="Assignment-1-Parallelism-Techniques-"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Assignment 1: Parallelism Techniques </span><img class="emoji offline-handled error-handled" alt=":computer:" src="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/images/basic/computer.png"><span> </span><img class="emoji offline-handled error-handled" alt=":link:" src="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/images/basic/link.png"><span> </span><img class="emoji offline-handled error-handled" alt=":computer:" src="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/images/basic/computer.png"></h1><h4 id="Parts-1-2-code-only-due-Tuesday-February-4th-at-600pm-EST" data-id="Parts-1-2-code-only-due-Tuesday-February-4th-at-600pm-EST"><a class="anchor hidden-xs" href="#Parts-1-2-code-only-due-Tuesday-February-4th-at-600pm-EST" title="Parts-1-2-code-only-due-Tuesday-February-4th-at-600pm-EST"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><mark><strong><span>Parts 1-2 (code only) due Tuesday, February 4th at 6:00pm EST</span></strong></mark></h4><h4 id="All-parts-due-Wednesday-February-19th-at-600pm-EST" data-id="All-parts-due-Wednesday-February-19th-at-600pm-EST"><a class="anchor hidden-xs" href="#All-parts-due-Wednesday-February-19th-at-600pm-EST" title="All-parts-due-Wednesday-February-19th-at-600pm-EST"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><mark><strong><span>All parts due Wednesday, February 19th at 6:00pm EST</span></strong></mark></h4><h1 id="Introduction" data-id="Introduction"><a class="anchor hidden-xs" href="#Introduction" title="Introduction"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Introduction</span></h1><p><span>With increasingly larger models and training data becoming the norm, it has become challenging to train machine learning models efficiently due to constraints in computational resources and memory. These challenges have led to the development of various parallelism strategies to distribute computation and memory usage across multiple devices or nodes.</span></p><p><span>In this assignment, you will explore two common parallelism techniques in training machine learning models: data parallelism (DDP) and model parallelism. After this, you will explore fully sharded data parallelism (FSDP) and pipeline parallelism, which address some of the limitations with each of these techniques respectively.</span></p><h2 id="Logistics-and-due-dates" data-id="Logistics-and-due-dates"><a class="anchor hidden-xs" href="#Logistics-and-due-dates" title="Logistics-and-due-dates"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Logistics and due dates</span></h2><p><span>The official lateness policy is described on the </span><a href="https://cs.brown.edu/courses/csci1390/#coursestructure" target="_blank" rel="noopener"><span>course website</span></a><span>, in terms of the total number of late hours and how they can be split across assignments. The grading server will display for your final submission, if turned in late, the number of late hours accrued.</span></p><p><span>This assignment has </span><em><span>two due dates</span></em><span>, one as an initial check in (deliverables described below), and one where the final assignment will be submitted. </span><em><span>You cannot use late hours on the initial check in.</span></em></p><p><strong><span>Initial check in due on February 4th at 6 PM</span></strong><span>:</span></p><ul>
<li><span>By this point, you should complete the implementation tasks in Part 1 (DDP) and Part 2 (Model Parallelism), and submit your code to the grading server. We run the correctness tests for both these parts on your implementation.</span>
<ul>
<li><span>It is </span><em><span>ok</span></em><span> if your code does not pass the correctness tests; we are mostly looking to see that you have made an effort to complete these parts. This deadline is there to ensure that you have adequate time to complete the rest of the assignment!</span></li>
</ul>
</li>
<li><span>You </span><em><span>do not need to finish</span></em><span> the performance analysis or conceptual question sections for Parts 1 and 2 for this initial check-in.</span></li>
</ul><p><strong><span>Final assignment due on February 19th at 6 PM</span></strong></p><ul>
<li><span>For your final submission, you should submit your code for all parts of the assignment to the grading server, and the writeup containing your generated graphs, explanations of the generated graphs, and answers to the math/conceptual questions.</span>
<ul>
<li><span>These questions are included in the </span><code>README.md</code><span> of the assignment repository; simply fill in your answers directly in the </span><code>README.md</code><span> and generate your graphs as directed in the assignment (which your </span><code>README.md</code><span> will automatically display).</span></li>
</ul>
</li>
</ul><p><span>We are still in the process of setting up the grading server; we will post instructions on registering with the grading server later this week.</span></p><p><span>We hope to have a way for you to submit runs of any parts of the assignment below so you can generate the data to graph on the grading server; we will have more information on this later.</span></p><h2 id="Learning-Goals" data-id="Learning-Goals"><a class="anchor hidden-xs" href="#Learning-Goals" title="Learning-Goals"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Learning Goals</span></h2><ul>
<li><span>Learn about some of the different ways to parallelize training machine learning models, and understand their tradeoffs with respect to the following:</span>
<ul>
<li><strong><span>Memory Overhead</span></strong><span>: does this parallelism method require replicating any model state, causing extra memory overhead as we scale to multiple nodes?</span></li>
<li><strong><span>Communication Overhead</span></strong><span>: does this parallellism method require any communication between workers to synchronize any model state? how does that affect its scalability?</span></li>
</ul>
</li>
<li><span>Get hands on experience implementing these methods in PyTorch, and measuring and reasoning about the performance of your implementations.</span></li>
</ul><p><strong><span>A note about resources</span></strong><span>: Your implementation will run on a </span><strong><span>CPU</span></strong><span> to demonstrate parallel training. Because of this, the observed speedups may not actually match what one would see on a GPU. However, we have designed the conceptual questions and explorations in the assignment for you to understand what the </span><em><span>method should be doing</span></em><span>, so later, if you are ever in a situation where you use one of these methods for parallel training, you have a better understanding of its tradeoffs.</span></p><h2 id="Assignment-Installation" data-id="Assignment-Installation"><a class="anchor hidden-xs" href="#Assignment-Installation" title="Assignment-Installation"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Assignment Installation</span></h2><p><span>The Github classroom link with the starter code can be found </span><a href="https://classroom.github.com/a/jf-LR4iw" target="_blank" rel="noopener"><span>here</span></a><span>.</span></p><h3 id="Using-Containers-for-Development" data-id="Using-Containers-for-Development"><a class="anchor hidden-xs" href="#Using-Containers-for-Development" title="Using-Containers-for-Development"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Using Containers for Development</span></h3><p><span>For this project and project 4, we'll use a course Docker container for development, that you can run locally on your own machine. From your introductory systems course (CS300 or CS33), you should have </span><a href="https://www.docker.com/" target="_blank" rel="noopener"><span>Docker</span></a><span> installed on your local machine (if not, refer to </span><a href="https://csci0300.github.io/assign/labs/lab0.html#Docker" target="_blank" rel="noopener"><span>these instructions</span></a><span>). Clone your assignment repostiory onto your machine, and navigate to it in your terminal (for Windows users, you should perform these steps in WSL).</span></p><p><span>You can then use our provided </span><code>run_docker</code><span> script to pull and run the course container. To download the container, run the following commands:</span></p><div class="code-block-wrapper">
        <pre><code class="sh hljs"><span class="hljs-built_in">chmod</span> +x ./run_docker
./run_docker download
</code></pre>
      </div><p><span>This will download the Docker image for the course container, as according to the platform you are running on.</span></p><p><span>To run the container, you can run the following command:</span></p><div class="code-block-wrapper">
        <pre><code>./run_docker run
</code></pre>
      </div><p><span>which will run the container, by default, with 4 CPUs and 4 GB of memory, and mount the current directory into your container. You can also customize these options if needed, as such:</span></p><div class="code-block-wrapper">
        <pre><code class="sh hljs">./run_docker run -s [mount_dir] -c [num_cpus] -m [mem_in_gb]
</code></pre>
      </div><p><span>After executing this command, you should enter the container and see the mounted directory as your work files within the current directory.</span></p><div class="alert alert-warning">
<details><summary><span><span>Instructions to run manually, if the script gives an error:</span></span></summary>
<p><span>Try running the following command (if you are using Podman instead, just replace </span><code>docker</code><span> with </span><code>pod</code><span>):</span></p>
<p><span>For </span><code>linux/amd</code><span> architecture:</span></p>

      <div class="code-block-wrapper" data-startline-back="71" data-endline-back="75">
        <pre><code class="sh hljs">docker pull cs1390mlsys/cs1390
docker tag cs1390mlsys/cs1390 cs1390
docker run -it --shm-size=1g --cpus=[cpu_num] -m=[memory] --mount <span class="hljs-built_in">type</span>=<span class="hljs-built_in">bind</span>,<span class="hljs-built_in">source</span>=./,target=/home/cs1390-user cs1390 /bin/bash
</code></pre>
      </div>
      
<p><span>For </span><code>linux/arm</code><span> architecture:</span></p>

      <div class="code-block-wrapper" data-startline-back="77" data-endline-back="81">
        <pre><code class="sh hljs">docker pull cs1390mlsys/cs1390.arm
docker tag cs1390mlsys/cs1390.arm cs1390.arm
docker run -it --shm-size=1g --cpus=[cpu_num] -m=[memory] --mount <span class="hljs-built_in">type</span>=<span class="hljs-built_in">bind</span>,<span class="hljs-built_in">source</span>=./,target=/home/cs1390-user cs1390.arm /bin/bash
</code></pre>
      </div>
      
</details>
</div><div class="alert alert-warning">
<details><summary><span><span>If you can't get Docker or Podman to work, here are alternate instructions:</span></span></summary>
<p><span>For projects 1 and 4, you can alternately use a local python environment. Note that project 1 requires the use of a function </span><code>os.sched_affinity</code><span>, which is not implemented for MacOS. You can comment out this function (it is called within </span><code>pin_to_core</code><span> in </span><code>utils.py</code><span>) out for the purpose of getting the computation working, but your performance results may not make sense.</span></p>
<ol style="padding-left: 2em;">
<li data-startline-back="89" data-endline-back="90">
<p><span>Install Miniconda with the instructions </span><a href="https://docs.anaconda.com/miniconda/install/" target="_blank" rel="noopener"><span>here</span></a><span>. Take note of the location where Miniconda is installed, which we will call </span><code>$PATH_TO_MINICONDA</code><span>.</span></p>
</li>
<li data-startline-back="91" data-endline-back="92">
<p><span>Shell initialization: we recommend adding the Conda initialization to your shell configuration (which may have been done during the install). To do this, run:</span></p>
</li>
</ol>

      <div class="code-block-wrapper" data-startline-back="93" data-endline-back="96">
        <pre><code class="sh hljs"><span class="hljs-built_in">source</span> <span class="hljs-variable">$PATH_TO_MINICONDA</span>/bin/activate
conda init --all
</code></pre>
      </div>
      
<ol start="3" style="padding-left: 2em;">
<li data-startline-back="98" data-endline-back="98"><span>Check that Conda is properly is initialized:</span></li>
</ol>

      <div class="code-block-wrapper" data-startline-back="99" data-endline-back="101">
        <pre><code class="sh hljs">conda --version <span class="hljs-comment"># should print "24.11" or something similar</span>
</code></pre>
      </div>
      
<ol start="4" style="padding-left: 2em;">
<li data-startline-back="103" data-endline-back="105">
<p><span>We have found that </span><em><span>even if you modify your </span><code>.bashrc</code><span>/</span><code>.zshrc</code><span> to include the Conda initialization sequence</span></em><span>, Conda does not always initialize. Simply check if the Conda initialization sequence is inside your </span><code>~/.bashrc</code><span>, and if not, repeat step 2; if so, run </span><code>source ~/.bashrc.</code></p>
</li>
<li data-startline-back="106" data-endline-back="106">
<p><span>Create a new environment for cs1390. The referenced requirements file is in the root folder of this assignment's repository:</span></p>
</li>
</ol>

      <div class="code-block-wrapper" data-startline-back="107" data-endline-back="112">
        <pre><code class="sh hljs">conda <span class="hljs-built_in">env</span> create --name cs1390 python=3.12
conda activate cs1390
conda install pytorch torchvision -c pytorch
pip install -r requirements.txt
</code></pre>
      </div>
      
</details>
</div><h1 id="Part-1-Distributed-Data-Parallel-DDP" data-id="Part-1-Distributed-Data-Parallel-DDP"><a class="anchor hidden-xs" href="#Part-1-Distributed-Data-Parallel-DDP" title="Part-1-Distributed-Data-Parallel-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Part 1: Distributed Data Parallel (DDP)</span></h1><p><span>Distributed Data Parallel (DDP) works by replicating the model on each device, splitting the dataset into smaller shards, one per device, and training the model on each shard independently. After each forward and backward pass, gradients are synchronized across all devices to ensure consistency, before the optimizer step is performed.</span></p><p><span>In the first part of the assignment, you will use PyTorch to create a wrapper class for a machine learning model, which performs DDP training of the </span><a href="https://pytorch.org/vision/main/models/generated/torchvision.models.vgg16.html" target="_blank" rel="noopener"><span>VGG16 model</span></a><span> on </span><strong><span>CPUs</span></strong><span>, and inspect its scalability.</span></p><h2 id="Implement-DDP" data-id="Implement-DDP"><a class="anchor hidden-xs" href="#Implement-DDP" title="Implement-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Implement DDP</span></h2><p><span>Now you'll complete an implementation of DDP!</span></p><div class="alert alert-success">
<p><strong><span>Task 1.1</span></strong><span>: Implement the </span><code>DistributedDataParallel</code><span> class in </span><code>ddp.py</code><span>. This class serves as a wrapper for the model, enabling distributed training across multiple devices. In particular, implement the methods </span><code>broadcast_params</code><span> and </span><code>average_gradients</code><span>.</span></p>
<p><span>Feel free to add/initialize any state to the wrapper class you might need (or for debugging) in the </span><code>__init__</code><span> function.</span></p>
<p><em><span>Hints:</span></em></p>
<ul>
<li><em><span>For communicating between devices, take a look at the library </span><a href="https://pytorch.org/docs/stable/distributed.html" target="_blank" rel="noopener"><code>torch.distributed</code></a><span> (imported as </span><code>dist</code><span>).</span></em></li>
<li><em><span>A model's parameters are stored as </span><a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html" target="_blank" rel="noopener"><code>Parameter</code></a><span>s, which can be obtained from a model </span><code>model</code><span> via </span><a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" target="_blank" rel="noopener"><code>model.parameters()</code></a><span>.</span></em></li>
<li><em><span>Recall that a </span><a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="noopener"><code>Tensor</code></a><span> </span><code>t</code><span>'s accumulated gradient is stored in </span><a href="https://pytorch.org/docs/stable/generated/torch.Tensor.grad.html#torch.Tensor.grad" target="_blank" rel="noopener"><code>t.grad</code></a><span>.</span></em></li>
</ul>
</div><div class="alert alert-success">
<p><strong><span>Task 1.2</span></strong><span>: Complete the training loop in </span><code>train_vgg16_cifar10_ddp_worker</code><span>. This involves:</span></p>
<ul>
<li><span>Zeroing all gradients and performing a forward pass on the model on each worker</span></li>
<li><span>Calculating loss and performing the backward pass on each worker</span></li>
<li><span>Updating gradients across all ranks</span></li>
<li><span>Updating model weights using the accumulated gradients and optimizer</span></li>
</ul>
<p><span>We have provided a debugging print statement that can be called as </span><code>utils.debug_print()</code><span> (we've already given several debug statements that call this method). These debug print statements can be toggled on and off with the </span><code>DEBUG_PRINT</code><span> flag in </span><code>utils.py</code><span>.</span></p>
<p><span>You can verify the correctness of your implementation by running the below command.</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs">python3 train.py ddp --num_batches 2 --num_workers 2 --learning_rate 1e-3 --batch_size 32 --check_weights --check_output
</code></pre>
      </div>
      
<p><span>The test will set PyTorch's random seeding to ensure deterministic training results, and compare the weights of your trained model, along with the output of it on a test batch, to that of a baseline model trained without any parallelism techniques.</span></p>
</div><h2 id="Performance-Analysis" data-id="Performance-Analysis"><a class="anchor hidden-xs" href="#Performance-Analysis" title="Performance-Analysis"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Performance Analysis</span></h2><p><span>Before analyzing the performance of your DDP model, </span><strong><span>please be cognizant that your machine may not support 4 workers</span></strong><span> (due to its memory overhead). If this is the case, feel free to use up to 3 (or 2) workers for the below measurements. We recommend shutting down memory intensive applications (e.g. Chrome, Slack).</span></p><p><span>By default, </span><code>train.py</code><span> uses 1 CPU core per worker; you can also increase this by using the </span><code>--cores_per_worker</code><span> argument, if you have enough resources.</span></p><h3 id="Split-Time-of-Each-Worker" data-id="Split-Time-of-Each-Worker"><a class="anchor hidden-xs" href="#Split-Time-of-Each-Worker" title="Split-Time-of-Each-Worker"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Split Time of Each Worker</span></h3><p><span>In distributed training, each node/worker will spend time performing computation and on communcation with other nodes. Understanding how time is spent relatively between each stage is crucial for evaluating the scalability of your implementation.</span></p><div class="alert alert-success">
<p><strong><span>Task 1.3</span></strong><span>: </span><code>train.py</code><span> will record statistics on the time spent in each stage within the training loop and save them to a file. We've provided a script which generates a graph from this stored data that breaks down the time each worker spent on each stage (communication, computation, and optimizer updates) and shows how this breakdown changes as the number of workers increase.</span></p>
<p><span>You can use the following commands to generate the data for the graph and plot the graph:</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs"><span class="hljs-comment"># Run DDP for 1, 2, and 4 workers</span>
python3 train.py ddp --num_workers 1
python3 train.py ddp --num_workers 2
python3 train.py ddp --num_workers 4

<span class="hljs-comment"># Plot the data</span>
python3 plot.py split_time ddp=1,ddp=2,ddp=4 --output graphs/ddp_split_time.png
</code></pre>
      </div>
      
<p><strong><span>If you are not able to finish this part of the assignment, we have provided a reference graph (generated on the grading server) for you to answer the question below and in your </span><code>README.md</code><span>.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.1</span></strong><span>:</span>
<span>Please use your graph or the reference graph below to answer the following questions:</span></p>
<ul>
<li><span>What is the expected behavior for how computation time, optimizer update time, and communication time change as the number of workers increase?</span></li>
<li><span>Does the generated graph match your expectations? If it looks different, try to analyze the reasons for the discrepancy.</span></li>
<li><span>How might the relative difference between computation and communication time change if we instead ran on a system containing GPUs connected by high-bandwidth interconnects?</span></li>
</ul>
<p><span>If you could not generate the graph locally, we have provided a reference from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/ddp_split_time.png" style="zoom:65%" class="offline-handled error-handled">
</div>
<details><summary><span><em><span>Hint</span></em></span></summary>
<p><em><span>Differences between your graph and the expected graph could be influenced by factors related to your OS, concurrently running applications, or access/use of computational resources. But feel free to comment on any factors you believe are reasonable.</span></em></p>
</details>
</div><h3 id="Throughput" data-id="Throughput"><a class="anchor hidden-xs" href="#Throughput" title="Throughput"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Throughput</span></h3><p><span>Throughput, when referring to training, generally refers to the number of samples a model can process per second. We calculate it by the total of number of samples the model is trained on divided by the time taken to train.</span></p><div class="alert alert-success">
<p><strong><span>Task 1.4</span></strong><span>: Now analyze how throughput scales with the number of workers for your implementation of DDP. To generate a graph displaying this data (using the data of your previous runs for Task 1.3), run the following:</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs"><span class="hljs-comment"># Plot the data</span>
python3 plot.py throughput ddp=1,ddp=2,ddp=4 --output graphs/ddp_throughput_comparison.png
</code></pre>
      </div>
      
<p><strong><span>If you are not able to finish this part of the assignment, we have provided a reference graph (generated on the grading server) for you to answer the question below and in your </span><code>README.md</code><span>.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.2</span></strong><span>: Analyze the scalability of your implementation. Consider what the ideal case would look like (perfect scalability with no overheads); then think about how potential bottlenecks would influence performance. Does your graph match your expectations for the ideal case? Why or why not?</span></p>
<p><span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/ddp_throughput.png" style="zoom:70%" class="offline-handled error-handled">
</div>
</div><h2 id="Math-time-Memory-Usage-and-Communication-in-DDP" data-id="Math-time-Memory-Usage-and-Communication-in-DDP"><a class="anchor hidden-xs" href="#Math-time-Memory-Usage-and-Communication-in-DDP" title="Math-time-Memory-Usage-and-Communication-in-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Math time: Memory Usage and Communication in DDP</span></h2><p><span>The main limitation of data parallelism is a high memory requirement, as the model is replicated on each device.</span></p><p><span>Assume we have a model with </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span> parameters. This means that we need to store in memory </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span> model parameters, </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span> gradients, and </span><span class="mathjax code-block-wrapper" data-raw-code="S1A" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="3" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span> optimizer states (</span><span class="mathjax code-block-wrapper" data-raw-code="Sw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="4" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container></span><span> represents how many variables the optimizer holds per parameter).</span></p><div class="alert alert-info">
<p><strong><span>Question 1.3</span></strong><span>: For the data given above, determine the memory consumption when there are </span><span class="mathjax code-block-wrapper" data-raw-code="Vw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="5" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></mjx-assistive-mml></mjx-container></span><span> parallel workers. Let </span><span class="mathjax code-block-wrapper" data-raw-code="Uw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="6" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi></math></mjx-assistive-mml></mjx-container></span><span> be the precision (in </span><em><span>bits</span></em><span>) used to store the model parameters, the gradients, and the optimizer states. Provide your answer in bytes (B); your answer should be in terms of </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="7" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span>, </span><span class="mathjax code-block-wrapper" data-raw-code="Sw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="8" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container></span><span>, </span><span class="mathjax code-block-wrapper" data-raw-code="Vw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="9" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></mjx-assistive-mml></mjx-container></span><span>, and </span><span class="mathjax code-block-wrapper" data-raw-code="Uw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi></math></mjx-assistive-mml></mjx-container></span><span>.</span></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.4</span></strong><span>: Now, consider a real-world scenario: suppose that we use the optimizer SGD (which stores </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="11" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span> parameters as state, i.e. just re-stores the parameters), with </span><strong><span>8</span></strong><span> workers, to train a model with </span><strong><span>10 billion</span></strong><span> parameters. We will use FP16 to store the model parameters and gradients, but use FP32 to store the optimizer states (this is referred to as </span><a href="https://arxiv.org/pdf/1710.03740" target="_blank" rel="noopener"><span>mixed-precision training</span></a><span>). How much memory is required to run DDP with this setup? Provide your answer in gigabytes (GB).</span></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.5</span></strong><span>: In DDP, the workers have to communicate after each iteration in order to synchronize gradients. Suppose that we have <span class="mathjax code-block-wrapper" data-raw-code="Qg" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="23" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></mjx-assistive-mml></mjx-container></span> workers, our model has </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="12" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span> parameters, our network bandwidth is </span><span class="mathjax code-block-wrapper" data-raw-code="Qg" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="13" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container></span><span> Gb/s (giga</span><em><span>bits</span></em><span> per second) between any pair of workers, and we use a ring all-reduce algorithm. Let </span><span class="mathjax code-block-wrapper" data-raw-code="U19w" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="14" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container></span><span> be the precision (in </span><em><span>bits</span></em><span>) used to store the model parameters, </span><span class="mathjax code-block-wrapper" data-raw-code="U19n" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="15" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D454 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>g</mi></msub></math></mjx-assistive-mml></mjx-container></span><span> be that used to store the gradients, and </span><span class="mathjax code-block-wrapper" data-raw-code="U19v" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="16" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>o</mi></msub></math></mjx-assistive-mml></mjx-container></span><span> be that used to store the optimizer states. Write down an expression that captures the time (in seconds) it takes for the gradient synchronization. Your answer should be in terms of </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="17" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span>, </span><span class="mathjax code-block-wrapper" data-raw-code="Sw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="18" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container></span><span>, </span><span class="mathjax code-block-wrapper" data-raw-code="Vw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="19" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></mjx-assistive-mml></mjx-container></span><span>, </span><span class="mathjax code-block-wrapper" data-raw-code="U19w" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="20" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container></span><span>, </span><span class="mathjax code-block-wrapper" data-raw-code="U19n" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="21" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D454 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>g</mi></msub></math></mjx-assistive-mml></mjx-container></span><span>, </span><span class="mathjax code-block-wrapper" data-raw-code="U19v" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="22" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>o</mi></msub></math></mjx-assistive-mml></mjx-container></span><span>, and </span><span class="mathjax code-block-wrapper" data-raw-code="Qg" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="23" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container></span><span>.</span></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.6</span></strong><span>: Now let's plug in real values to the above expression. Assume that we have </span><strong><span>8</span></strong><span> workers, </span><strong><span>10 billion</span></strong><span> parameters, and we use FP16 for parameters and gradients, but FP32 to store optimizer states. Assume the network bandwidth is </span><strong><span>100 Gb/s</span></strong><span>. Provide your answer in seconds.</span></p>
</div><h1 id="Part-2-Model-Parallelism" data-id="Part-2-Model-Parallelism"><a class="anchor hidden-xs" href="#Part-2-Model-Parallelism" title="Part-2-Model-Parallelism"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Part 2: Model Parallelism</span></h1><p><span>Model parallelism works by splitting the model into separate pieces, each of which are placed onto different nodes. For this assignment, the model will be split into partitions of contiguous layers, which are each placed on separate devices. The forward pass goes through the partitions in order, while the backward pass propagates gradients in reverse order.</span></p><p><span>As we will go over in class, this variation of model parallelism is not the only way to split a model across nodes (for instance, you can also split parameters on the same layer between devices, referred to as tensor model parallelism).</span></p><p><span>This form of model parallelism reduces communication overhead compared to DDP because communication only happens at partition boundaries between devices. However, it has very low worker utilization because only one worker is running at a time. We will explore a way to improve this later in the assignment.</span></p><p><span>In this part of the assignment, you will use PyTorch to create a wrapper class for model parallel training of the VGG16 model on CPUs, and inspect its throughput, as well as a timeline of when computation occurs on each worker.</span></p><h2 id="Model-Parallelism-Code-Structure" data-id="Model-Parallelism-Code-Structure"><a class="anchor hidden-xs" href="#Model-Parallelism-Code-Structure" title="Model-Parallelism-Code-Structure"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Model Parallelism Code Structure</span></h2><p><span>The code for model parallelism is structured slightly differently than the DDP wrapper. We recommend taking a look at it before starting to understand the differences (located in </span><code>model_parallel.py</code><span>):</span></p><ol style="padding-left: 2em;">
<li><span>Instead of a single wrapper, there are two wrappers: </span><code>ModelParallelWrapper</code><span> which the training loop uses to orchestrate forward and backward passes on each worker, and </span><code>ModelParallelWorker</code><span> which actually does the forward and backward pass on each worker, communicating with the previous and next partition.</span></li>
<li><code>train_vgg16_cifar10_model_parallel</code><span> additionally calls </span><code>split_vgg16</code><span> to partition the VGG16 model, and then passes a partition to each worker. This shows how with model parallelism, the entire model is actually </span><em><span>split</span></em><span> across workers, so there is no immediate memory overhead.</span></li>
</ol><h2 id="Implement-Model-Parallelism" data-id="Implement-Model-Parallelism"><a class="anchor hidden-xs" href="#Implement-Model-Parallelism" title="Implement-Model-Parallelism"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Implement Model Parallelism</span></h2><p><span>We have divided the implementation for model parallelism into 4 parts: figuring out the communication sizes for each partition boundary, implementing the forward pass, implementing the backward pass, and then combining the forward and backward pass into a single training step.</span></p><div class="alert alert-success">
<p><strong><span>Task 2.1</span></strong><span>: In </span><code>utils.py</code><span>, fill in the function </span><code>analyze_communication_with_partitions</code><span>. You will be using point-to-point communication functions to move data between workers during the forward and backward passes, and these functions require the receiver to know what exactly is the size of data that will be received.</span></p>
<p><em><span>Hints:</span></em></p>
<ul>
<li><em><span>You'll want to perform a dummy forward pass to determine the output activations of each layer.</span></em></li>
<li><em><span>Consider what the gradient is that each partition receives. How could you determine its size?</span></em></li>
</ul>
<p><span>You can verify the correctness of your implementation by running:</span></p>

      <div class="code-block-wrapper">
        <pre><code>python3 comm_test.py
</code></pre>
      </div>
      
</div><div class="alert alert-success">
<p><strong><span>Task 2.2</span></strong><span>: Next, implement </span><code>ModelParallelWrapper::forward</code><span> and </span><code>ModelParallelWorker::forward</code><span> in </span><code>model_parallel.py</code><span>.</span></p>
<p><span>As with DDP, feel free to add/initialize any state to the wrapper class you might need (or for debugging) in the </span><code>__init__</code><span> function.</span></p>
<p><em><span>Hint: We recommend using the point-to-point communication primitives given in the </span><a href="https://pytorch.org/docs/stable/distributed.html" target="_blank" rel="noopener"><code>torch.distributed</code></a><span> library (imported as </span><code>dist</code><span>); see its </span><a href="https://pytorch.org/docs/stable/distributed.html#torch.distributed.send" target="_blank" rel="noopener"><code>send</code></a><span> and </span><a href="https://pytorch.org/docs/stable/distributed.html#torch.distributed.send" target="_blank" rel="noopener"><code>recv</code></a><span> functions.</span></em></p>
</div><div class="alert alert-success">
<p><strong><span>Task 2.3</span></strong><span>: Now, implement </span><code>ModelParallelWrapper::backward</code><span> and </span><code>ModelParallelWorker::backward</code><span> in </span><code>model_parallel.py</code><span>.</span></p>
<p><span>To help you understand the memory requirements of this technique, you </span><strong><span>must</span></strong><span> use </span><a href="https://pytorch.org/docs/stable/generated/torch.autograd.grad.html" target="_blank" rel="noopener"><code>torch.autograd.grad</code></a><span> to calculate/propagate gradients </span><strong><span>individually for each layer within the partition</span></strong><span> to perform the backward pass. (In other words, the number of calls your implementation makes to </span><code>torch.autograd.grad</code><span> should scale with the number of layers in the partition.) We will manually review your code to ensure that this is the case.</span></p>
</div><div class="alert alert-success">
<p><strong><span>Task 2.4</span></strong><span>: Finally, combine the previous two steps by implementing </span><code>ModelParallelWrapper::train_step</code><span> and </span><code>ModelParallelWorker::optimizer_step</code><span> in </span><code>model_parallel.py</code><span>.</span></p>
<p><span>You can verify the correctness of your implementation by running the following command:</span></p>

      <div class="code-block-wrapper">
        <pre><code>python3 train.py model --num_batches 2 --num_workers 2 --learning_rate 1e-3 --batch_size 32 --check_output
</code></pre>
      </div>
      
</div><h2 id="Performance-Analysis17" data-id="Performance-Analysis"><a class="anchor hidden-xs" href="#Performance-Analysis17" title="Performance-Analysis17"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Performance Analysis</span></h2><div class="alert alert-success">
<p><strong><span>Task 2.5</span></strong><span>: Generate a timeline graph for model parallelism with 3 workers. This timeline graph shows what computation is happening on each worker across an entire training step. To do this, run the following commands:</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs"><span class="hljs-comment"># Train using model parallelism with 3 workers</span>
python3 train.py model --num_workers 3

<span class="hljs-comment"># Plot the data</span>
python3 plot.py timeline model=3 --output graphs/model_timeline.png
</code></pre>
      </div>
      
<p><strong><span>If you are not able to finish this part of the assignment, we have provided a reference graph (generated on the grading server) for you to answer the question below and in your </span><code>README.md</code><span>.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 2.1</span></strong><span>: Analyze your (or the reference) timeline graph. What does it indicate about how work is distributed between each worker? How does this reflect the internals of how model parallelism is implemented?</span></p>
<p><span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/model_timeline.png" style="zoom:75%" class="offline-handled error-handled">
</div>
</div><div class="alert alert-success">
<p><strong><span>Task 2.6</span></strong><span>: Generate a throughput graph for model parallelism.</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs"><span class="hljs-comment"># Train using model parallelism with 1, 2, and 3 workers</span>
python3 train.py model --num_workers 1
python3 train.py model --num_workers 2
python3 train.py model --num_workers 3

<span class="hljs-comment"># Plot the data</span>
python3 plot.py throughput model=1,model=2,model=3 --output graphs/model_throughput_comparison.png
</code></pre>
      </div>
      
<p><strong><span>If you are not able to finish this part of the assignment, we have provided a reference graph (generated on the grading server) for you to answer the question below and in your </span><code>README.md</code><span>.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 2.2</span></strong><span>: Analyze your (or the reference) throughput graph. Does it match your expectations of how model parallelism should scale as the number of workers increases? Why or why not?</span></p>
<p><span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/model_throughput.png" style="zoom:60%" class="offline-handled error-handled">
</div>
</div><h2 id="Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP" data-id="Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP"><a class="anchor hidden-xs" href="#Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP" title="Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Math time: Comparison of Communication in Model Parallel vs. DDP</span></h2><div class="alert alert-info">
<p><strong><span>Question 2.3</span></strong><span>: In DDP, the workers have to communicate after each iteration in order to synchronize gradients (as you explored in Questions 1.5 and 1.6). In model parallelism, communication happens at partition boundaries. Assume that there are </span><span class="mathjax code-block-wrapper" data-raw-code="TA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="24" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container></span><span> total layers, divided into </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="25" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span> partitions (equally). Let the input batch size be </span><span class="mathjax code-block-wrapper" data-raw-code="Qg" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="26" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container></span><span>.</span></p>
<ul>
<li><span>Let </span><span class="mathjax code-block-wrapper" data-raw-code="Tl9m" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="27" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.085em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mi>f</mi></msub></math></mjx-assistive-mml></mjx-container></span><span> be the size (in bytes) of the input to each layer in the model (i.e. assume this is uniform across all layers). How much communication occurs (across all partitions in aggregate) during the forward pass?</span></li>
<li><span>Let </span><span class="mathjax code-block-wrapper" data-raw-code="Tl9i" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="28" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.085em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mi>b</mi></msub></math></mjx-assistive-mml></mjx-container></span><span> be the size (in bytes) of the gradient with respect to each layer's output in the model (i.e. assume this is uniform across all layers). How much communication occurs (across all partitions in aggregate) during the backward pass?</span></li>
</ul>
<p><span>When we say "how much", we mean the amount of data (in bytes) that is being transferred in one iteration of training (i.e. with one batch).</span></p>
</div><h1 id="Part-3-Reducing-the-Memory-Overhead-of-DDP" data-id="Part-3-Reducing-the-Memory-Overhead-of-DDP"><a class="anchor hidden-xs" href="#Part-3-Reducing-the-Memory-Overhead-of-DDP" title="Part-3-Reducing-the-Memory-Overhead-of-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Part 3: Reducing the Memory Overhead of DDP</span></h1><p><span>One downside of DDP is that it requires the entire model to be loaded on a single device. To reduce the memory overhead of the model, its tensors can be sharded across devices. Whenever a device requires the entire tensor (during a forward or backward pass), the tensor can be gathered to perform the computation and then freed. Each device is responsible for its own shard, and updates it accordingly.</span></p><p><span>In this part of the assignment, you will implement a simplified version of FSDP (Fully Sharded Data Parallel), where only the parameters of each layer are sharded among workers. Once implemented, we'll compare FSDP to DDP to understand how the two methods scale.</span></p><h2 id="Implement-FSDP" data-id="Implement-FSDP"><a class="anchor hidden-xs" href="#Implement-FSDP" title="Implement-FSDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Implement FSDP</span></h2><p><span>Now you'll complete an implementation of FSDP! Note that we keep a copy of the entire model in </span><code>self.layers</code><span>; this is so that we can determine the architecture of the underlying model (and thus, how accumulated parameters should be used to construct a layer of the model). In an actual FSDP implementation, each worker wouldn't store the entire model, just the architecture and its own local shard of parameters.</span></p><p><span>To get started, take a look at </span><code>init_layers_and_params</code><span> and </span><code>FullyShardedDataParallel::get_local_info</code><span> in </span><code>fsdp.py</code><span>, which determine how the model's parameter tensors are sharded.</span></p><div class="alert alert-success">
<p><strong><span>Task 3.1</span></strong><span>: Implement the forward pass of the model in the methods </span><code>gather_param_data</code><span> and </span><code>forward</code><span> of the </span><code>FullyShardedDataParallel</code><span> class within </span><code>fsdp.py</code><span>.</span></p>
<p><span>As before, feel free to add/initialize any state to the wrapper class you might need (or for debugging) in the </span><code>__init__</code><span> function.</span></p>
<p><em><span>Hint: Take a look at how the parameter tensors are obtained from a layer in </span><code>init_layers_and_params</code><span> and sharded in </span><code>FullyShardedDataParallel::get_local_info</code><span>. (Note that these parameter shards and associated metadata are stored in </span><code>self.local_params</code><span> and </span><code>self.unsharded_param_shapes</code><span>.) How would you therefore gather the parameter tensors of a layer in </span><code>self.layers</code><span> from all ranks, and set them within the layer?</span></em></p>
</div><div class="alert alert-success">
<p><strong><span>Task 3.2</span></strong><span>: Implement the backward pass of the model in the methods </span><code>get_local_grad_shard</code><span> and </span><code>backward</code><span> of the </span><code>FullyShardedDataParallel</code><span> class within </span><code>fsdp.py</code><span>. Then implement </span><code>FullyShardedDataParallel::optimizer_step</code><span>.</span></p>
<p><span>Just as for model parallelism, you </span><strong><span>must</span></strong><span> use </span><a href="https://pytorch.org/docs/stable/generated/torch.autograd.grad.html" target="_blank" rel="noopener"><code>torch.autograd.grad</code></a><span> to calculate/propagate gradients </span><strong><span>individually for each layer within the partition</span></strong><span> to perform the backward pass. (Think about what would be required if you performed a constant number of calls to </span><code>torch.autograd.grad</code><span> - which properties of FSDP would you need to violate?) We will manually review your code to ensure that this is the case.</span></p>
<p><em><span>Hints:</span></em></p>
<ul>
<li><em><span>Recall that the computational graph for gradient calculation is constructed along the forward pass. Therefore, you'll need to calculate gradients using the same </span><code>Tensor</code><span>s used in the forward pass.</span></em></li>
<li><em><span>However, you should only be updating/storing gradients for the local parameter shards (take a look at how </span><code>self.optimizer</code><span> is constructed in </span><code>FullyShardedDataParallel</code><span>!).</span></em></li>
<li><em><span>The backend we are using, </span><code>gloo</code><span>, does not support the reduce scatter operation. You can instead perform an all-reduce across all ranks, and then correspondingly slice the globally reduced tensor.</span></em></li>
</ul>
<p><span>You can verify the correctness of your implementation by running the following command:</span></p>

      <div class="code-block-wrapper">
        <pre><code>python3 train.py fsdp --num_batches 2 --num_workers 2 --learning_rate 1e-2 --batch_size 32 --check_weights --check_output
</code></pre>
      </div>
      
</div><h2 id="Performance-Analysis21" data-id="Performance-Analysis"><a class="anchor hidden-xs" href="#Performance-Analysis21" title="Performance-Analysis21"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Performance Analysis</span></h2><div class="alert alert-success">
<p><strong><span>Task 3.3</span></strong><span>: Now use your implementation of FSDP to analyze the throughput as the number of workers scale.</span>
<span>To run this experiment, please run the following:</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs"><span class="hljs-comment"># Run FSDP for 1, 2 and 4 workers</span>
python3 train.py fsdp --num_workers 1
python3 train.py fsdp --num_workers 2
python3 train.py fsdp --num_workers 4

<span class="hljs-comment"># Plot the data</span>
python3 plot.py throughput fsdp=1,fsdp=2,fsdp=4 --output graphs/fsdp_throughput_comparison.png
</code></pre>
      </div>
      
<p><strong><span>If you are not able to finish this part of the assignment, we have provided a reference graph (generated on the grading server) for you to answer the question below and in your </span><code>README.md</code><span>.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 3.1</span></strong><span>: Please analyze the scalability of your FSDP implementation. Compare this graph to the previous DDP throughout graph. Do the two methods scale as you expected? Why or why not? Which one has better raw performance? Why? How does the communication required for FSDP and DDP differ?</span></p>
<p><span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/fsdp_throughput.png" style="zoom:60%" class="offline-handled error-handled">
</div>
</div><h2 id="Math-Time-Memory-Overhead-of-DDP-vs-FSDP" data-id="Math-Time-Memory-Overhead-of-DDP-vs-FSDP"><a class="anchor hidden-xs" href="#Math-Time-Memory-Overhead-of-DDP-vs-FSDP" title="Math-Time-Memory-Overhead-of-DDP-vs-FSDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Math Time: Memory Overhead of DDP vs. FSDP</span></h2><div class="alert alert-info">
<p><strong><span>Question 3.2</span></strong><span>: Our implementation of FSDP only handled sharding the parameter states, but in reality, a full implementation would shard the gradients during the backward pass, and the optimizer state as well. Let's return to the scenario from Question 1.3 and 1.4, but instead consider the optimizer Adam. Specifically:</span></p>
<ul>
<li><span>We have a model with </span><span class="mathjax code-block-wrapper" data-raw-code="UA" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="29" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container></span><span> parameters.</span></li>
<li><span>The Adam optimizer stores the parameter, momentum, and variance for each parameter.</span></li>
<li><span>Again assume that all data is stored with the same precision </span><span class="mathjax code-block-wrapper" data-raw-code="Uw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="30" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi></math></mjx-assistive-mml></mjx-container></span><span> (in bits).</span></li>
</ul>
<p><span>Write expressions that capture the following, when we have </span><span class="mathjax code-block-wrapper" data-raw-code="Vw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="31" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></mjx-assistive-mml></mjx-container></span><span> workers:</span></p>
<ol style="padding-left: 2em;">
<li><span>The memory overhead (in bytes) on each worker when nothing is sharded (same as DDP)</span></li>
<li><span>The memory overhead (in bytes) when the optimizer state is sharded.</span></li>
<li><span>The memory overhead (in bytes) when the optimizer state and gradients are sharded.</span></li>
<li><span>The memory overhead (in bytes) when everything is sharded.</span></li>
</ol>
</div><div class="alert alert-info">
<p><strong><span>Question 3.3</span></strong>
<span>Now let's plug in some values. We are again using mixed-precision training, where models and gradients are stored in FP16, but the optimizer states are stored in FP32. Our model has 10 billion parameters, and we split training across 8 workers. In bytes, what is the memory overhead per worker, when:</span></p>
<ol style="padding-left: 2em;">
<li><span>The optimizer is sharded?</span></li>
<li><span>The optimizer and gradients are sharded?</span></li>
<li><span>Everything is sharded?</span></li>
</ol>
<p><span>For full credit, please write out exactly how you arrived at these values.</span></p>
</div><h1 id="Part-4-Pipeline-Parallelism" data-id="Part-4-Pipeline-Parallelism"><a class="anchor hidden-xs" href="#Part-4-Pipeline-Parallelism" title="Part-4-Pipeline-Parallelism"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Part 4: Pipeline Parallelism</span></h1><p><span>In model parallelism, the forward/backward pass for each partition begins only after that for the previous/next partition is completed, which leads to low resource utilization on worker nodes. To improve resource utilization, we can introduce pipelining, by dividing the data into multiple microbatches. By doing so, the computation of different microbatches can overlap in time, enhancing resource utilization.</span></p><h2 id="Implement-Pipeline-Parallelism" data-id="Implement-Pipeline-Parallelism"><a class="anchor hidden-xs" href="#Implement-Pipeline-Parallelism" title="Implement-Pipeline-Parallelism"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Implement Pipeline Parallelism</span></h2><div class="alert alert-success">
<p><strong><span>Task 4.1</span></strong><span>: The overall workflow of pipeline parallelsim is very similar to model parallelism, but notice the new </span><code>microbatch_idx</code><span> parameter which is used to keep track of the currently processed microbatch of the current batch.</span></p>
<p><span>To start with, implement the </span><code>forward</code><span>, </span><code>backward</code><span>, and </span><code>optimizer_step</code><span> methods for the </span><code>PipelineParallelWorker</code><span> class, and the </span><code>forward</code><span> and </span><code>backward</code><span> methods for the </span><code>PipelineParallel</code><span> class.</span></p>
<p><span>Just as for model parallelism, you </span><strong><span>must</span></strong><span> use </span><a href="https://pytorch.org/docs/stable/generated/torch.autograd.grad.html" target="_blank" rel="noopener"><code>torch.autograd.grad</code></a><span> to calculate/propagate gradients </span><strong><span>individually for each layer within the partition</span></strong><span> to perform the backward pass. We will manually review your code to ensure that this is the case.</span></p>
<p><em><span>Hint: Your code for these sections should be very similar to that for model parallelism!</span></em></p>
</div><div class="alert alert-success">
<p><strong><span>Task 4.2</span></strong><span>: Implement the </span><code>train_step</code><span> and </span><code>eval</code><span> methods for the </span><code>PipelineParallel</code><span> class. Note that each of these steps take in a </span><em><span>full batch</span></em><span> of inputs.</span></p>
<p><span>You can verify the correctness of your implementation by running the below command.</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs">python3 train.py pipeline --num_batches 2 --num_workers 2 --learning_rate 1e-2 --batch_size 32 --check_output
</code></pre>
      </div>
      
</div><h2 id="Performance-Analysis25" data-id="Performance-Analysis"><a class="anchor hidden-xs" href="#Performance-Analysis25" title="Performance-Analysis25"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Performance Analysis</span></h2><div class="alert alert-success">
<p><strong><span>Task 4.3</span></strong><span>: Generate a timeline graph for pipeline parallelism with 3 workers. To do this, run the following commands:</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs"><span class="hljs-comment"># Train using model parallelism with 3 workers</span>
python3 train.py pipeline --num_workers 3

<span class="hljs-comment"># Plot the data</span>
python3 plot.py timeline pipeline=3 --output graphs/pipeline_timeline.png
</code></pre>
      </div>
      
<p><strong><span>If you are not able to finish this part of the assignment, we have provided a reference graph (generated on the grading server) for you to answer the question below and in your </span><code>README.md</code><span>.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 4.1</span></strong><span>: Analyze your (or the reference) timeline graph. What does it indicate about how work is distributed between each worker? How does this reflect the internals of how pipeline parallelism is implemented?</span></p>
<p><span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/pipeline_timeline.png" style="zoom:75%" class="offline-handled error-handled">
</div>
</div><div class="alert alert-success">
<p><strong><span>Task 4.4</span></strong><span>: Generate a throughput graph for pipeline parallelism.</span></p>

      <div class="code-block-wrapper">
        <pre><code class="sh hljs"><span class="hljs-comment"># Train using pipeline parallelism with 1, 2, and 3 workers</span>
python3 train.py --num_workers 1 pipeline
python3 train.py --num_workers 2 pipeline
python3 train.py --num_workers 3 pipeline

<span class="hljs-comment"># Plot the data</span>
python3 plot.py throughput pipeline=1,pipeline=2,pipeline=3 --output graphs/pipeline_throughput_comparison.png
</code></pre>
      </div>
      
<p><strong><span>If you are not able to finish this part of the assignment, we have provided a reference graph (generated on the grading server) for you to answer the question below and in your </span><code>README.md</code><span>.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 4.2</span></strong><span>: Analyze your (or the reference) throughput graph. Does it match your expectations of how pipeline parallelism should scale as the number of workers increases? Why or why not? How does the performance of pipeline parallelism compare with model parallelism and why?</span></p>
<p><span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/pipeline_throughput.png" style="zoom:60%" class="offline-handled error-handled">
</div>
</div><h3 id="Math-Time-Pipeline-Bubble-Size" data-id="Math-Time-Pipeline-Bubble-Size"><a class="anchor hidden-xs" href="#Math-Time-Pipeline-Bubble-Size" title="Math-Time-Pipeline-Bubble-Size"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Math Time: Pipeline Bubble Size</span></h3><div class="alert alert-info">
<p><strong><span>Question 4.3</span></strong><span>: In the </span><a href="https://arxiv.org/pdf/1811.06965" target="_blank" rel="noopener"><span>GPipe</span></a><span> paper, </span><strong><span>section 2.3</span></strong><span> entitled </span><strong><span>Performance Optimization</span></strong><span>, the author proposed that the size of the pipeline bubble (the fraction of times when workers are not being utilized) is:</span>
<span class="mathjax code-block-wrapper" data-raw-code="T1xsZWZ0KFxmcmFje0stMX17TStLLTF9XHJpZ2h0KQ" style="display: block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="32" style="font-size: 123.5%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>O</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mrow><mi>K</mi><mo></mo><mn>1</mn></mrow><mrow><mi>M</mi><mo>+</mo><mi>K</mi><mo></mo><mn>1</mn></mrow></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container></span>
<span>where </span><span class="mathjax code-block-wrapper" data-raw-code="Sw" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="33" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container></span><span> is the number of partitions and </span><span class="mathjax code-block-wrapper" data-raw-code="TQ" style="display: inline-block;"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="34" style="font-size: 123.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi></math></mjx-assistive-mml></mjx-container></span><span> is the number of microbatches. Please derive this expression based on Figure 2a in the paper.</span></p>
</div><p><span>Even though the approach in </span><a href="https://arxiv.org/pdf/1811.06965" target="_blank" rel="noopener"><span>GPipe</span></a><span> improves utilization over model parallelism, we can still observe idle gaps where workers are not being used. In the paper </span><a href="https://people.eecs.berkeley.edu/~matei/papers/2019/sosp_pipedream.pdf" target="_blank" rel="noopener"><span>PipeDream</span></a><span>, the authors proposed a different approach (with a schedule called </span><strong><span>1F1B</span></strong><span>).</span></p><div class="alert alert-info">
<p><strong><span>Question 4.4</span></strong>
<span>Referring to Figure 4, does </span><strong><span>1F1B</span></strong><span> reduce bubble size compared to the GPipe version of pipeline parallelism? If so </span><span class="smartypants"></span><span> why? If not </span><span class="smartypants"></span><span> what are the benefits of the alternate schedule in terms of active memory use, compared to GPipe?</span></p>
</div>
<p><strong><span>Congratulations, you've completed the first CS 1390 assignment!</span></strong><span> </span><img class="emoji offline-handled error-handled" alt=":tada:" src="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/images/basic/tada.png"></p>
<h1 id="Further-References" data-id="Further-References"><a class="anchor hidden-xs" href="#Further-References" title="Further-References"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Further References</span></h1><p><span>We recommend taking a look at these resources if you would like to learn more; we also drew on some of these resources to create the assignment!</span></p><ul>
<li><a href="https://arxiv.org/pdf/1811.06965" target="_blank" rel="noopener"><span>GPipe Paper</span></a></li>
<li><a href="https://deepakn94.github.io/assets/papers/pipedream-sosp19.pdf" target="_blank" rel="noopener"><span>Pipedream Paper</span></a></li>
<li><a href="https://arxiv.org/pdf/1910.02054" target="_blank" rel="noopener"><span>ZeRO Paper</span></a></li>
<li><a href="https://arxiv.org/pdf/1710.03740" target="_blank" rel="noopener"><span>Mixed Precision Training Paper</span></a></li>
<li><a href="https://arxiv.org/pdf/2304.11277" target="_blank" rel="noopener"><span>Pytorch FSDP Paper</span></a></li>
</ul>
<hr><p><small><em><span>Acknowledgements:</span></em><span> This project was developed for CS 1390 by Sid Boppana, Nathan Harbison, Alice Song, and Deepti Raghavan. </span></small></p>
</div>
    <div class="ui-toc dropup unselectable hidden-print" style="display:none;">
        <div class="pull-right dropdown">
            <a id="tocLabel" class="ui-toc-label btn btn-default" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false" title="Table of content">
                <i class="fa fa-bars"></i>
            </a>
            <ul id="ui-toc" class="ui-toc-dropdown dropdown-menu" aria-labelledby="tocLabel">
                <div class="toc"><ul class="nav">
<li><a href="#Assignment-1-Parallelism-Techniques-" title="Assignment 1: Parallelism Techniques   ">Assignment 1: Parallelism Techniques   </a></li>
<li><a href="#Introduction" title="Introduction">Introduction</a><ul class="nav">
<li><a href="#Logistics-and-due-dates" title="Logistics and due dates">Logistics and due dates</a></li>
<li><a href="#Learning-Goals" title="Learning Goals">Learning Goals</a></li>
<li><a href="#Assignment-Installation" title="Assignment Installation">Assignment Installation</a><ul class="nav">
<li><a href="#Using-Containers-for-Development" title="Using Containers for Development">Using Containers for Development</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Part-1-Distributed-Data-Parallel-DDP" title="Part 1: Distributed Data Parallel (DDP)">Part 1: Distributed Data Parallel (DDP)</a><ul class="nav">
<li><a href="#Implement-DDP" title="Implement DDP">Implement DDP</a></li>
<li><a href="#Performance-Analysis" title="Performance Analysis">Performance Analysis</a><ul class="nav">
<li><a href="#Split-Time-of-Each-Worker" title="Split Time of Each Worker">Split Time of Each Worker</a></li>
<li><a href="#Throughput" title="Throughput">Throughput</a></li>
</ul>
</li>
<li><a href="#Math-time-Memory-Usage-and-Communication-in-DDP" title="Math time: Memory Usage and Communication in DDP">Math time: Memory Usage and Communication in DDP</a></li>
</ul>
</li>
<li><a href="#Part-2-Model-Parallelism" title="Part 2: Model Parallelism">Part 2: Model Parallelism</a><ul class="nav">
<li><a href="#Model-Parallelism-Code-Structure" title="Model Parallelism Code Structure">Model Parallelism Code Structure</a></li>
<li><a href="#Implement-Model-Parallelism" title="Implement Model Parallelism">Implement Model Parallelism</a></li>
<li><a href="#Performance-Analysis17" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP" title="Math time: Comparison of Communication in Model Parallel vs. DDP">Math time: Comparison of Communication in Model Parallel vs. DDP</a></li>
</ul>
</li>
<li><a href="#Part-3-Reducing-the-Memory-Overhead-of-DDP" title="Part 3: Reducing the Memory Overhead of DDP">Part 3: Reducing the Memory Overhead of DDP</a><ul class="nav">
<li><a href="#Implement-FSDP" title="Implement FSDP">Implement FSDP</a></li>
<li><a href="#Performance-Analysis21" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-Time-Memory-Overhead-of-DDP-vs-FSDP" title="Math Time: Memory Overhead of DDP vs. FSDP">Math Time: Memory Overhead of DDP vs. FSDP</a></li>
</ul>
</li>
<li><a href="#Part-4-Pipeline-Parallelism" title="Part 4: Pipeline Parallelism">Part 4: Pipeline Parallelism</a><ul class="nav">
<li><a href="#Implement-Pipeline-Parallelism" title="Implement Pipeline Parallelism">Implement Pipeline Parallelism</a></li>
<li><a href="#Performance-Analysis25" title="Performance Analysis">Performance Analysis</a><ul class="nav">
<li><a href="#Math-Time-Pipeline-Bubble-Size" title="Math Time: Pipeline Bubble Size">Math Time: Pipeline Bubble Size</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Further-References" title="Further References">Further References</a></li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
            </ul>
        </div>
    </div>
    <div id="ui-toc-affix" class="ui-affix-toc ui-toc-dropdown unselectable hidden-print" data-spy="affix" style="top:17px;display:none;"  >
        <div class="toc"><ul class="nav">
<li><a href="#Assignment-1-Parallelism-Techniques-" title="Assignment 1: Parallelism Techniques   ">Assignment 1: Parallelism Techniques   </a></li>
<li><a href="#Introduction" title="Introduction">Introduction</a><ul class="nav">
<li><a href="#Logistics-and-due-dates" title="Logistics and due dates">Logistics and due dates</a></li>
<li><a href="#Learning-Goals" title="Learning Goals">Learning Goals</a></li>
<li><a href="#Assignment-Installation" title="Assignment Installation">Assignment Installation</a><ul class="nav">
<li><a href="#Using-Containers-for-Development" title="Using Containers for Development">Using Containers for Development</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Part-1-Distributed-Data-Parallel-DDP" title="Part 1: Distributed Data Parallel (DDP)">Part 1: Distributed Data Parallel (DDP)</a><ul class="nav">
<li><a href="#Implement-DDP" title="Implement DDP">Implement DDP</a></li>
<li><a href="#Performance-Analysis" title="Performance Analysis">Performance Analysis</a><ul class="nav">
<li><a href="#Split-Time-of-Each-Worker" title="Split Time of Each Worker">Split Time of Each Worker</a></li>
<li><a href="#Throughput" title="Throughput">Throughput</a></li>
</ul>
</li>
<li><a href="#Math-time-Memory-Usage-and-Communication-in-DDP" title="Math time: Memory Usage and Communication in DDP">Math time: Memory Usage and Communication in DDP</a></li>
</ul>
</li>
<li><a href="#Part-2-Model-Parallelism" title="Part 2: Model Parallelism">Part 2: Model Parallelism</a><ul class="nav">
<li><a href="#Model-Parallelism-Code-Structure" title="Model Parallelism Code Structure">Model Parallelism Code Structure</a></li>
<li><a href="#Implement-Model-Parallelism" title="Implement Model Parallelism">Implement Model Parallelism</a></li>
<li><a href="#Performance-Analysis17" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP" title="Math time: Comparison of Communication in Model Parallel vs. DDP">Math time: Comparison of Communication in Model Parallel vs. DDP</a></li>
</ul>
</li>
<li><a href="#Part-3-Reducing-the-Memory-Overhead-of-DDP" title="Part 3: Reducing the Memory Overhead of DDP">Part 3: Reducing the Memory Overhead of DDP</a><ul class="nav">
<li><a href="#Implement-FSDP" title="Implement FSDP">Implement FSDP</a></li>
<li><a href="#Performance-Analysis21" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-Time-Memory-Overhead-of-DDP-vs-FSDP" title="Math Time: Memory Overhead of DDP vs. FSDP">Math Time: Memory Overhead of DDP vs. FSDP</a></li>
</ul>
</li>
<li><a href="#Part-4-Pipeline-Parallelism" title="Part 4: Pipeline Parallelism">Part 4: Pipeline Parallelism</a><ul class="nav">
<li><a href="#Implement-Pipeline-Parallelism" title="Implement Pipeline Parallelism">Implement Pipeline Parallelism</a></li>
<li><a href="#Performance-Analysis25" title="Performance Analysis">Performance Analysis</a><ul class="nav">
<li><a href="#Math-Time-Pipeline-Bubble-Size" title="Math Time: Pipeline Bubble Size">Math Time: Pipeline Bubble Size</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Further-References" title="Further References">Further References</a></li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous" defer></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.6.0/gist-embed.min.js" integrity="sha256-KyF2D6xPIJUW5sUDSs93vWyZm+1RzIpKCexxElmxl8g=" crossorigin="anonymous" defer></script>
    <script>
        var markdown = $(".markdown-body");
        //smooth all hash trigger scrolling
        function smoothHashScroll() {
            var hashElements = $("a[href^='#']").toArray();
            for (var i = 0; i < hashElements.length; i++) {
                var element = hashElements[i];
                var $element = $(element);
                var hash = element.hash;
                if (hash) {
                    $element.on('click', function (e) {
                        // store hash
                        var hash = this.hash;
                        if ($(hash).length <= 0) return;
                        // prevent default anchor click behavior
                        e.preventDefault();
                        // animate
                        $('body, html').stop(true, true).animate({
                            scrollTop: $(hash).offset().top
                        }, 100, "linear", function () {
                            // when done, add hash to url
                            // (default click behaviour)
                            window.location.hash = hash;
                        });
                    });
                }
            }
        }

        smoothHashScroll();
        var toc = $('.ui-toc');
        var tocAffix = $('.ui-affix-toc');
        var tocDropdown = $('.ui-toc-dropdown');
        //toc
        tocDropdown.click(function (e) {
            e.stopPropagation();
        });

        var enoughForAffixToc = true;

        function generateScrollspy() {
            $(document.body).scrollspy({
                target: ''
            });
            $(document.body).scrollspy('refresh');
            if (enoughForAffixToc) {
                toc.hide();
                tocAffix.show();
            } else {
                tocAffix.hide();
                toc.show();
            }
            $(document.body).scroll();
        }

        function windowResize() {
            //toc right
            var paddingRight = parseFloat(markdown.css('padding-right'));
            var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight));
            toc.css('right', right + 'px');
            //affix toc left
            var newbool;
            var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2;
            //for ipad or wider device
            if (rightMargin >= 133) {
                newbool = true;
                var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2;
                var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin;
                tocAffix.css('left', left + 'px');
            } else {
                newbool = false;
            }
            if (newbool != enoughForAffixToc) {
                enoughForAffixToc = newbool;
                generateScrollspy();
            }
        }
        $(window).resize(function () {
            windowResize();
        });
        $(document).ready(function () {
            windowResize();
            generateScrollspy();
        });

        //remove hash
        function removeHash() {
            window.location.hash = '';
        }

        var backtotop = $('.back-to-top');
        var gotobottom = $('.go-to-bottom');

        backtotop.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToTop)
                scrollToTop();
            removeHash();
        });
        gotobottom.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToBottom)
                scrollToBottom();
            removeHash();
        });

        var toggle = $('.expand-toggle');
        var tocExpand = false;

        checkExpandToggle();
        toggle.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            tocExpand = !tocExpand;
            checkExpandToggle();
        })

        function checkExpandToggle () {
            var toc = $('.ui-toc-dropdown .toc');
            var toggle = $('.expand-toggle');
            if (!tocExpand) {
                toc.removeClass('expand');
                toggle.text('Expand all');
            } else {
                toc.addClass('expand');
                toggle.text('Collapse all');
            }
        }

        function scrollToTop() {
            $('body, html').stop(true, true).animate({
                scrollTop: 0
            }, 100, "linear");
        }

        function scrollToBottom() {
            $('body, html').stop(true, true).animate({
                scrollTop: $(document.body)[0].scrollHeight
            }, 100, "linear");
        }
    </script>
</body>

</html>
