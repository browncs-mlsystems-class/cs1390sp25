<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="mobile-web-app-capable" content="yes">
    <title>
        Assignment 1: Parallelism Techniques - HackMD
    </title>
    <link rel="icon" type="image/png" href="https://hackmd.io/favicon.png">
    <link rel="apple-touch-icon" href="https://hackmd.io/apple-touch-icon.png">

    <link rel="stylesheet" href="project1_files/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
    <link rel="stylesheet" href="project1_files/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
    <link rel="stylesheet" href="project1_files/ionicons.min.css" integrity="sha256-3iu9jgsy9TpTwXKb7bNQzqWekRX7pPK+2OLj3R922fo=" crossorigin="anonymous">
    <link rel="stylesheet" href="project1_files/octicons.min.css" integrity="sha256-QiWfLIsCT02Sdwkogf6YMiQlj4NE84MKkzEMkZnMGdg=" crossorigin="anonymous">
    <link rel="stylesheet" href="project1_files/prism.min.css" integrity="sha256-vtR0hSWRc3Tb26iuN2oZHt3KRUomwTufNIf5/4oeCyg=" crossorigin="anonymous">
    <link rel="stylesheet" href="project1_files/emojify.min.css" integrity="sha256-UOrvMOsSDSrW6szVLe8ZDZezBxh5IoIfgTwdNDgTjiU=" crossorigin="anonymous">
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i|Source+Code+Pro:300,400,500|Source+Sans+Pro:300,300i,400,400i,600,600i|Source+Serif+Pro&subset=latin-ext);
/*!
  Theme: GitHub
  Description: Light theme as seen on github.com
  Author: github.com
  Maintainer: @Hirse
  Updated: 2021-05-15

  Outdated base version: https://github.com/primer/github-syntax-light
  Current colors taken from GitHub's CSS
*/:root[theme=light] :not([theme])>*>.markdown-body .hljs-doctag,:root[theme=light] :not([theme])>*>.markdown-body .hljs-keyword,:root[theme=light] :not([theme])>*>.markdown-body .hljs-meta .hljs-keyword,:root[theme=light] :not([theme])>*>.markdown-body .hljs-template-tag,:root[theme=light] :not([theme])>*>.markdown-body .hljs-template-variable,:root[theme=light] :not([theme])>*>.markdown-body .hljs-type,:root[theme=light] :not([theme])>*>.markdown-body .hljs-variable.language_,:root[theme] [theme=light] .markdown-body .hljs-doctag,:root[theme] [theme=light] .markdown-body .hljs-keyword,:root[theme] [theme=light] .markdown-body .hljs-meta .hljs-keyword,:root[theme] [theme=light] .markdown-body .hljs-template-tag,:root[theme] [theme=light] .markdown-body .hljs-template-variable,:root[theme] [theme=light] .markdown-body .hljs-type,:root[theme] [theme=light] .markdown-body .hljs-variable.language_{color:#d73a49}:root[theme=light] :not([theme])>*>.markdown-body .hljs-title,:root[theme=light] :not([theme])>*>.markdown-body .hljs-title.class_,:root[theme=light] :not([theme])>*>.markdown-body .hljs-title.class_.inherited__,:root[theme=light] :not([theme])>*>.markdown-body .hljs-title.function_,:root[theme] [theme=light] .markdown-body .hljs-title,:root[theme] [theme=light] .markdown-body .hljs-title.class_,:root[theme] [theme=light] .markdown-body .hljs-title.class_.inherited__,:root[theme] [theme=light] .markdown-body .hljs-title.function_{color:#6f42c1}:root[theme=light] :not([theme])>*>.markdown-body .hljs-attr,:root[theme=light] :not([theme])>*>.markdown-body .hljs-attribute,:root[theme=light] :not([theme])>*>.markdown-body .hljs-literal,:root[theme=light] :not([theme])>*>.markdown-body .hljs-meta,:root[theme=light] :not([theme])>*>.markdown-body .hljs-number,:root[theme=light] :not([theme])>*>.markdown-body .hljs-operator,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-attr,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-class,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-id,:root[theme=light] :not([theme])>*>.markdown-body .hljs-variable,:root[theme] [theme=light] .markdown-body .hljs-attr,:root[theme] [theme=light] .markdown-body .hljs-attribute,:root[theme] [theme=light] .markdown-body .hljs-literal,:root[theme] [theme=light] .markdown-body .hljs-meta,:root[theme] [theme=light] .markdown-body .hljs-number,:root[theme] [theme=light] .markdown-body .hljs-operator,:root[theme] [theme=light] .markdown-body .hljs-selector-attr,:root[theme] [theme=light] .markdown-body .hljs-selector-class,:root[theme] [theme=light] .markdown-body .hljs-selector-id,:root[theme] [theme=light] .markdown-body .hljs-variable{color:#005cc5}:root[theme=light] :not([theme])>*>.markdown-body .hljs-meta .hljs-string,:root[theme=light] :not([theme])>*>.markdown-body .hljs-regexp,:root[theme=light] :not([theme])>*>.markdown-body .hljs-string,:root[theme] [theme=light] .markdown-body .hljs-meta .hljs-string,:root[theme] [theme=light] .markdown-body .hljs-regexp,:root[theme] [theme=light] .markdown-body .hljs-string{color:#032f62}:root[theme=light] :not([theme])>*>.markdown-body .hljs-built_in,:root[theme=light] :not([theme])>*>.markdown-body .hljs-symbol,:root[theme] [theme=light] .markdown-body .hljs-built_in,:root[theme] [theme=light] .markdown-body .hljs-symbol{color:#e36209}:root[theme=light] :not([theme])>*>.markdown-body .hljs-code,:root[theme=light] :not([theme])>*>.markdown-body .hljs-comment,:root[theme=light] :not([theme])>*>.markdown-body .hljs-formula,:root[theme] [theme=light] .markdown-body .hljs-code,:root[theme] [theme=light] .markdown-body .hljs-comment,:root[theme] [theme=light] .markdown-body .hljs-formula{color:#6a737d}:root[theme=light] :not([theme])>*>.markdown-body .hljs-name,:root[theme=light] :not([theme])>*>.markdown-body .hljs-quote,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-pseudo,:root[theme=light] :not([theme])>*>.markdown-body .hljs-selector-tag,:root[theme] [theme=light] .markdown-body .hljs-name,:root[theme] [theme=light] .markdown-body .hljs-quote,:root[theme] [theme=light] .markdown-body .hljs-selector-pseudo,:root[theme] [theme=light] .markdown-body .hljs-selector-tag{color:#22863a}:root[theme=light] :not([theme])>*>.markdown-body .hljs-subst,:root[theme] [theme=light] .markdown-body .hljs-subst{color:#24292e}:root[theme=light] :not([theme])>*>.markdown-body .hljs-section,:root[theme] [theme=light] .markdown-body .hljs-section{color:#005cc5;font-weight:700}:root[theme=light] :not([theme])>*>.markdown-body .hljs-bullet,:root[theme] [theme=light] .markdown-body .hljs-bullet{color:#735c0f}:root[theme=light] :not([theme])>*>.markdown-body .hljs-emphasis,:root[theme] [theme=light] .markdown-body .hljs-emphasis{color:#24292e;font-style:italic}:root[theme=light] :not([theme])>*>.markdown-body .hljs-strong,:root[theme] [theme=light] .markdown-body .hljs-strong{color:#24292e;font-weight:700}:root[theme=light] :not([theme])>*>.markdown-body .hljs-addition,:root[theme] [theme=light] .markdown-body .hljs-addition{background-color:#f0fff4;color:#22863a}:root[theme=light] :not([theme])>*>.markdown-body .hljs-deletion,:root[theme] [theme=light] .markdown-body .hljs-deletion{background-color:#ffeef0;color:#b31d28}

/*!
  Theme: GitHub Dark Dimmed
  Description: Dark dimmed theme as seen on github.com
  Author: github.com
  Maintainer: @Hirse
  Updated: 2021-05-15

  Colors taken from GitHub's CSS
*/:root[theme=dark] :not([theme])>*>.markdown-body .hljs-doctag,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-keyword,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-meta .hljs-keyword,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-template-tag,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-template-variable,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-type,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-variable.language_,:root[theme] [theme=dark] .markdown-body .hljs-doctag,:root[theme] [theme=dark] .markdown-body .hljs-keyword,:root[theme] [theme=dark] .markdown-body .hljs-meta .hljs-keyword,:root[theme] [theme=dark] .markdown-body .hljs-template-tag,:root[theme] [theme=dark] .markdown-body .hljs-template-variable,:root[theme] [theme=dark] .markdown-body .hljs-type,:root[theme] [theme=dark] .markdown-body .hljs-variable.language_{color:#f47067}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-title,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-title.class_,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-title.class_.inherited__,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-title.function_,:root[theme] [theme=dark] .markdown-body .hljs-title,:root[theme] [theme=dark] .markdown-body .hljs-title.class_,:root[theme] [theme=dark] .markdown-body .hljs-title.class_.inherited__,:root[theme] [theme=dark] .markdown-body .hljs-title.function_{color:#dcbdfb}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-attr,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-attribute,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-literal,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-meta,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-number,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-operator,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-attr,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-class,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-id,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-variable,:root[theme] [theme=dark] .markdown-body .hljs-attr,:root[theme] [theme=dark] .markdown-body .hljs-attribute,:root[theme] [theme=dark] .markdown-body .hljs-literal,:root[theme] [theme=dark] .markdown-body .hljs-meta,:root[theme] [theme=dark] .markdown-body .hljs-number,:root[theme] [theme=dark] .markdown-body .hljs-operator,:root[theme] [theme=dark] .markdown-body .hljs-selector-attr,:root[theme] [theme=dark] .markdown-body .hljs-selector-class,:root[theme] [theme=dark] .markdown-body .hljs-selector-id,:root[theme] [theme=dark] .markdown-body .hljs-variable{color:#6cb6ff}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-meta .hljs-string,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-regexp,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-string,:root[theme] [theme=dark] .markdown-body .hljs-meta .hljs-string,:root[theme] [theme=dark] .markdown-body .hljs-regexp,:root[theme] [theme=dark] .markdown-body .hljs-string{color:#96d0ff}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-built_in,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-symbol,:root[theme] [theme=dark] .markdown-body .hljs-built_in,:root[theme] [theme=dark] .markdown-body .hljs-symbol{color:#f69d50}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-code,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-comment,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-formula,:root[theme] [theme=dark] .markdown-body .hljs-code,:root[theme] [theme=dark] .markdown-body .hljs-comment,:root[theme] [theme=dark] .markdown-body .hljs-formula{color:#768390}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-name,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-quote,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-pseudo,:root[theme=dark] :not([theme])>*>.markdown-body .hljs-selector-tag,:root[theme] [theme=dark] .markdown-body .hljs-name,:root[theme] [theme=dark] .markdown-body .hljs-quote,:root[theme] [theme=dark] .markdown-body .hljs-selector-pseudo,:root[theme] [theme=dark] .markdown-body .hljs-selector-tag{color:#8ddb8c}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-subst,:root[theme] [theme=dark] .markdown-body .hljs-subst{color:#adbac7}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-section,:root[theme] [theme=dark] .markdown-body .hljs-section{color:#316dca;font-weight:700}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-bullet,:root[theme] [theme=dark] .markdown-body .hljs-bullet{color:#eac55f}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-emphasis,:root[theme] [theme=dark] .markdown-body .hljs-emphasis{color:#adbac7;font-style:italic}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-strong,:root[theme] [theme=dark] .markdown-body .hljs-strong{color:#adbac7;font-weight:700}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-addition,:root[theme] [theme=dark] .markdown-body .hljs-addition{background-color:#1b4721;color:#b4f1b4}:root[theme=dark] :not([theme])>*>.markdown-body .hljs-deletion,:root[theme] [theme=dark] .markdown-body .hljs-deletion{background-color:#78191b;color:#ffd8d3}:root[theme=dark] :not([theme])>*>.markdown-body code[class*=language-],:root[theme=dark] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=dark] .markdown-body code[class*=language-],:root[theme] [theme=dark] .markdown-body pre[class*=language-]{word-wrap:normal;background:none;color:#ccc;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;white-space:pre;word-break:normal;word-spacing:normal}:root[theme=dark] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=dark] .markdown-body pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:root[theme=dark] :not([theme])>*>.markdown-body :not(pre)>code[class*=language-],:root[theme=dark] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=dark] .markdown-body :not(pre)>code[class*=language-],:root[theme] [theme=dark] .markdown-body pre[class*=language-]{background:#2d2d2d}:root[theme=dark] :not([theme])>*>.markdown-body :not(pre)>code[class*=language-],:root[theme] [theme=dark] .markdown-body :not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}:root[theme=dark] :not([theme])>*>.markdown-body .token.block-comment,:root[theme=dark] :not([theme])>*>.markdown-body .token.cdata,:root[theme=dark] :not([theme])>*>.markdown-body .token.comment,:root[theme=dark] :not([theme])>*>.markdown-body .token.doctype,:root[theme=dark] :not([theme])>*>.markdown-body .token.prolog,:root[theme] [theme=dark] .markdown-body .token.block-comment,:root[theme] [theme=dark] .markdown-body .token.cdata,:root[theme] [theme=dark] .markdown-body .token.comment,:root[theme] [theme=dark] .markdown-body .token.doctype,:root[theme] [theme=dark] .markdown-body .token.prolog{color:#999}:root[theme=dark] :not([theme])>*>.markdown-body .token.punctuation,:root[theme] [theme=dark] .markdown-body .token.punctuation{color:#ccc}:root[theme=dark] :not([theme])>*>.markdown-body .token.attr-name,:root[theme=dark] :not([theme])>*>.markdown-body .token.deleted,:root[theme=dark] :not([theme])>*>.markdown-body .token.namespace,:root[theme=dark] :not([theme])>*>.markdown-body .token.tag,:root[theme] [theme=dark] .markdown-body .token.attr-name,:root[theme] [theme=dark] .markdown-body .token.deleted,:root[theme] [theme=dark] .markdown-body .token.namespace,:root[theme] [theme=dark] .markdown-body .token.tag{color:#e2777a}:root[theme=dark] :not([theme])>*>.markdown-body .token.function-name,:root[theme] [theme=dark] .markdown-body .token.function-name{color:#6196cc}:root[theme=dark] :not([theme])>*>.markdown-body .token.boolean,:root[theme=dark] :not([theme])>*>.markdown-body .token.function,:root[theme=dark] :not([theme])>*>.markdown-body .token.number,:root[theme] [theme=dark] .markdown-body .token.boolean,:root[theme] [theme=dark] .markdown-body .token.function,:root[theme] [theme=dark] .markdown-body .token.number{color:#f08d49}:root[theme=dark] :not([theme])>*>.markdown-body .token.class-name,:root[theme=dark] :not([theme])>*>.markdown-body .token.constant,:root[theme=dark] :not([theme])>*>.markdown-body .token.property,:root[theme=dark] :not([theme])>*>.markdown-body .token.symbol,:root[theme] [theme=dark] .markdown-body .token.class-name,:root[theme] [theme=dark] .markdown-body .token.constant,:root[theme] [theme=dark] .markdown-body .token.property,:root[theme] [theme=dark] .markdown-body .token.symbol{color:#f8c555}:root[theme=dark] :not([theme])>*>.markdown-body .token.atrule,:root[theme=dark] :not([theme])>*>.markdown-body .token.builtin,:root[theme=dark] :not([theme])>*>.markdown-body .token.important,:root[theme=dark] :not([theme])>*>.markdown-body .token.keyword,:root[theme=dark] :not([theme])>*>.markdown-body .token.selector,:root[theme] [theme=dark] .markdown-body .token.atrule,:root[theme] [theme=dark] .markdown-body .token.builtin,:root[theme] [theme=dark] .markdown-body .token.important,:root[theme] [theme=dark] .markdown-body .token.keyword,:root[theme] [theme=dark] .markdown-body .token.selector{color:#cc99cd}:root[theme=dark] :not([theme])>*>.markdown-body .token.attr-value,:root[theme=dark] :not([theme])>*>.markdown-body .token.char,:root[theme=dark] :not([theme])>*>.markdown-body .token.regex,:root[theme=dark] :not([theme])>*>.markdown-body .token.string,:root[theme=dark] :not([theme])>*>.markdown-body .token.variable,:root[theme] [theme=dark] .markdown-body .token.attr-value,:root[theme] [theme=dark] .markdown-body .token.char,:root[theme] [theme=dark] .markdown-body .token.regex,:root[theme] [theme=dark] .markdown-body .token.string,:root[theme] [theme=dark] .markdown-body .token.variable{color:#7ec699}:root[theme=dark] :not([theme])>*>.markdown-body .token.entity,:root[theme=dark] :not([theme])>*>.markdown-body .token.operator,:root[theme=dark] :not([theme])>*>.markdown-body .token.url,:root[theme] [theme=dark] .markdown-body .token.entity,:root[theme] [theme=dark] .markdown-body .token.operator,:root[theme] [theme=dark] .markdown-body .token.url{color:#67cdcc}:root[theme=dark] :not([theme])>*>.markdown-body .token.bold,:root[theme=dark] :not([theme])>*>.markdown-body .token.important,:root[theme] [theme=dark] .markdown-body .token.bold,:root[theme] [theme=dark] .markdown-body .token.important{font-weight:700}:root[theme=dark] :not([theme])>*>.markdown-body .token.italic,:root[theme] [theme=dark] .markdown-body .token.italic{font-style:italic}:root[theme=dark] :not([theme])>*>.markdown-body .token.entity,:root[theme] [theme=dark] .markdown-body .token.entity{cursor:help}:root[theme=dark] :not([theme])>*>.markdown-body .token.inserted,:root[theme] [theme=dark] .markdown-body .token.inserted{color:green}:root[theme=light] :not([theme])>*>.markdown-body code[class*=language-],:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=light] .markdown-body code[class*=language-],:root[theme] [theme=light] .markdown-body pre[class*=language-]{word-wrap:normal;background:none;color:#000;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;text-shadow:0 1px #fff;white-space:pre;word-break:normal;word-spacing:normal}:root[theme=light] :not([theme])>*>.markdown-body code[class*=language-] ::selection,:root[theme=light] :not([theme])>*>.markdown-body code[class*=language-]::selection,:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-] ::selection,:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-]::selection,:root[theme] [theme=light] .markdown-body code[class*=language-] ::selection,:root[theme] [theme=light] .markdown-body code[class*=language-]::selection,:root[theme] [theme=light] .markdown-body pre[class*=language-] ::selection,:root[theme] [theme=light] .markdown-body pre[class*=language-]::selection{background:#b3d4fc;text-shadow:none}:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=light] .markdown-body pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:root[theme=light] :not([theme])>*>.markdown-body :not(pre)>code[class*=language-],:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=light] .markdown-body :not(pre)>code[class*=language-],:root[theme] [theme=light] .markdown-body pre[class*=language-]{background:#f5f2f0}:root[theme=light] :not([theme])>*>.markdown-body :not(pre)>code[class*=language-],:root[theme] [theme=light] .markdown-body :not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}:root[theme=light] :not([theme])>*>.markdown-body .token.cdata,:root[theme=light] :not([theme])>*>.markdown-body .token.comment,:root[theme=light] :not([theme])>*>.markdown-body .token.doctype,:root[theme=light] :not([theme])>*>.markdown-body .token.prolog,:root[theme] [theme=light] .markdown-body .token.cdata,:root[theme] [theme=light] .markdown-body .token.comment,:root[theme] [theme=light] .markdown-body .token.doctype,:root[theme] [theme=light] .markdown-body .token.prolog{color:#708090}:root[theme=light] :not([theme])>*>.markdown-body .token.punctuation,:root[theme] [theme=light] .markdown-body .token.punctuation{color:#999}:root[theme=light] :not([theme])>*>.markdown-body .token.namespace,:root[theme] [theme=light] .markdown-body .token.namespace{opacity:.7}:root[theme=light] :not([theme])>*>.markdown-body .token.boolean,:root[theme=light] :not([theme])>*>.markdown-body .token.constant,:root[theme=light] :not([theme])>*>.markdown-body .token.deleted,:root[theme=light] :not([theme])>*>.markdown-body .token.number,:root[theme=light] :not([theme])>*>.markdown-body .token.property,:root[theme=light] :not([theme])>*>.markdown-body .token.symbol,:root[theme=light] :not([theme])>*>.markdown-body .token.tag,:root[theme] [theme=light] .markdown-body .token.boolean,:root[theme] [theme=light] .markdown-body .token.constant,:root[theme] [theme=light] .markdown-body .token.deleted,:root[theme] [theme=light] .markdown-body .token.number,:root[theme] [theme=light] .markdown-body .token.property,:root[theme] [theme=light] .markdown-body .token.symbol,:root[theme] [theme=light] .markdown-body .token.tag{color:#905}:root[theme=light] :not([theme])>*>.markdown-body .token.attr-name,:root[theme=light] :not([theme])>*>.markdown-body .token.builtin,:root[theme=light] :not([theme])>*>.markdown-body .token.char,:root[theme=light] :not([theme])>*>.markdown-body .token.inserted,:root[theme=light] :not([theme])>*>.markdown-body .token.selector,:root[theme=light] :not([theme])>*>.markdown-body .token.string,:root[theme] [theme=light] .markdown-body .token.attr-name,:root[theme] [theme=light] .markdown-body .token.builtin,:root[theme] [theme=light] .markdown-body .token.char,:root[theme] [theme=light] .markdown-body .token.inserted,:root[theme] [theme=light] .markdown-body .token.selector,:root[theme] [theme=light] .markdown-body .token.string{color:#690}:root[theme=light] :not([theme])>*>.markdown-body .language-css .token.string,:root[theme=light] :not([theme])>*>.markdown-body .style .token.string,:root[theme=light] :not([theme])>*>.markdown-body .token.entity,:root[theme=light] :not([theme])>*>.markdown-body .token.operator,:root[theme=light] :not([theme])>*>.markdown-body .token.url,:root[theme] [theme=light] .markdown-body .language-css .token.string,:root[theme] [theme=light] .markdown-body .style .token.string,:root[theme] [theme=light] .markdown-body .token.entity,:root[theme] [theme=light] .markdown-body .token.operator,:root[theme] [theme=light] .markdown-body .token.url{background:#ffffff80;color:#9a6e3a}:root[theme=light] :not([theme])>*>.markdown-body .token.atrule,:root[theme=light] :not([theme])>*>.markdown-body .token.attr-value,:root[theme=light] :not([theme])>*>.markdown-body .token.keyword,:root[theme] [theme=light] .markdown-body .token.atrule,:root[theme] [theme=light] .markdown-body .token.attr-value,:root[theme] [theme=light] .markdown-body .token.keyword{color:#07a}:root[theme=light] :not([theme])>*>.markdown-body .token.class-name,:root[theme=light] :not([theme])>*>.markdown-body .token.function,:root[theme] [theme=light] .markdown-body .token.class-name,:root[theme] [theme=light] .markdown-body .token.function{color:#dd4a68}:root[theme=light] :not([theme])>*>.markdown-body .token.important,:root[theme=light] :not([theme])>*>.markdown-body .token.regex,:root[theme=light] :not([theme])>*>.markdown-body .token.variable,:root[theme] [theme=light] .markdown-body .token.important,:root[theme] [theme=light] .markdown-body .token.regex,:root[theme] [theme=light] .markdown-body .token.variable{color:#e90}:root[theme=light] :not([theme])>*>.markdown-body .token.bold,:root[theme=light] :not([theme])>*>.markdown-body .token.important,:root[theme] [theme=light] .markdown-body .token.bold,:root[theme] [theme=light] .markdown-body .token.important{font-weight:700}:root[theme=light] :not([theme])>*>.markdown-body .token.italic,:root[theme] [theme=light] .markdown-body .token.italic{font-style:italic}:root[theme=light] :not([theme])>*>.markdown-body .token.entity,:root[theme] [theme=light] .markdown-body .token.entity{cursor:help}@media print{:root[theme=light] :not([theme])>*>.markdown-body code[class*=language-],:root[theme=light] :not([theme])>*>.markdown-body pre[class*=language-],:root[theme] [theme=light] .markdown-body code[class*=language-],:root[theme] [theme=light] .markdown-body pre[class*=language-]{text-shadow:none}}.markdown-body{word-wrap:break-word;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;font-size:16px;line-height:1.5}.markdown-body:after,.markdown-body:before{content:"";display:table}.markdown-body:after{clear:both}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:#c00}.markdown-body .anchor{float:left;line-height:1;margin-left:-20px;padding-right:4px}.markdown-body .anchor:focus{outline:none}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-bottom:16px;margin-top:0}.markdown-body hr{background-color:#e7e7e7;border:0;height:.25em;margin:24px 0;padding:0}.markdown-body blockquote{border-left:.25em solid #ddd;color:#777;font-size:16px;padding:0 1em}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body kbd,.popover kbd{background-color:#fcfcfc;border:1px solid;border-color:#ccc #ccc #bbb;border-radius:3px;box-shadow:inset 0 -1px 0 #bbb;color:#555;display:inline-block;font-size:11px;line-height:10px;padding:3px 5px;vertical-align:middle}.markdown-body .loweralpha{list-style-type:lower-alpha}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{font-weight:600;line-height:1.25;margin-bottom:16px;margin-top:24px}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#000;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 code,.markdown-body h1 tt,.markdown-body h2 code,.markdown-body h2 tt,.markdown-body h3 code,.markdown-body h3 tt,.markdown-body h4 code,.markdown-body h4 tt,.markdown-body h5 code,.markdown-body h5 tt,.markdown-body h6 code,.markdown-body h6 tt{font-size:inherit}.markdown-body h1{font-size:2em}.markdown-body h1,.markdown-body h2{border-bottom:1px solid #eee;padding-bottom:.3em}.markdown-body h2{font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{color:#777;font-size:.85em}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol.no-list,.markdown-body ul.no-list{list-style-type:none;padding:0}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-bottom:0;margin-top:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{padding-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{font-size:1em;font-style:italic;font-weight:700;margin-top:16px;padding:0}.markdown-body dl dd{margin-bottom:16px;padding:0 16px}.markdown-body table{display:block;overflow:auto;width:100%;word-break:normal;word-break:keep-all}.markdown-body table th{font-weight:700}.markdown-body table td,.markdown-body table th{border:1px solid #ddd}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{background-color:#fff;box-sizing:initial;max-width:100%}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{background-color:initial;max-width:none;vertical-align:text-top}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{border:1px solid #ddd;display:block;float:left;margin:13px 0 0;overflow:hidden;padding:7px;width:auto}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{clear:both;color:#333;display:block;padding:5px 0 0}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center>span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right>span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right>span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{background-color:#0000000a;border-radius:3px;font-size:85%;margin:0;padding:.2em 0}.markdown-body code:after,.markdown-body code:before,.markdown-body tt:after,.markdown-body tt:before{content:"\00a0";letter-spacing:-.2em}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{text-decoration:inherit}.markdown-body pre{word-wrap:normal}.markdown-body pre>code{background:#0000;border:0;font-size:100%;margin:0;padding:0;white-space:pre;word-break:normal}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{border-radius:3px;font-size:85%;line-height:1.45;overflow:auto}.markdown-body:not(.next-editor) pre{padding:16px}.markdown-body pre code,.markdown-body pre tt{word-wrap:normal;background-color:initial;border:0;display:inline;line-height:inherit;margin:0;max-width:auto;overflow:visible;padding:0}.markdown-body pre code:after,.markdown-body pre code:before,.markdown-body pre tt:after,.markdown-body pre tt:before{content:normal}.markdown-body .csv-data td,.markdown-body .csv-data th{font-size:12px;line-height:1;overflow:hidden;padding:5px;text-align:left;white-space:nowrap}.markdown-body .csv-data .blob-line-num{background:#fff;border:0;padding:10px 8px 9px;text-align:right}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{background:#f8f8f8;border-top:0;font-weight:700}.news .alert .markdown-body blockquote{border:0;padding:0 0 0 40px}.activity-tab .news .alert .commits,.activity-tab .news .markdown-body blockquote{padding-left:0}.task-list-item{list-style-type:none}.task-list-item label{font-weight:400}.task-list-item.enabled label{cursor:pointer}.task-list-item+.task-list-item{margin-top:3px}.task-list-item-checkbox{cursor:default!important;float:left;margin:.31em 0 .2em -1.3em!important;vertical-align:middle}.markdown-alert{border-left-style:solid;border-left-width:4px;color:inherit;margin-bottom:16px;padding:8px 16px}.markdown-alert .markdown-alert-title{align-items:center;display:flex;font-weight:500;line-height:1;white-space:break-spaces}.markdown-body .markdown-alert>*{margin-bottom:0;margin-top:16px}.markdown-body .markdown-alert .selection-popover,.markdown-body .markdown-alert>:first-child{margin-top:0}.markdown-alert.markdown-alert-note{border-left-color:var(--hmd-tw-state-info-default)}.markdown-alert.markdown-alert-note .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-state-info-text)}.markdown-alert.markdown-alert-tip{border-left-color:var(--hmd-tw-state-success-default)}.markdown-alert.markdown-alert-tip .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-state-success-text)}.markdown-alert.markdown-alert-important{border-left-color:var(--hmd-tw-border-primary-default)}.markdown-alert.markdown-alert-important .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-text-primary)}.markdown-alert.markdown-alert-warning{border-left-color:var(--hmd-tw-state-warning-default)}.markdown-alert.markdown-alert-warning .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-state-warning-text)}.markdown-alert.markdown-alert-caution{border-left-color:var(--hmd-tw-state-danger-default)}.markdown-alert.markdown-alert-caution .markdown-alert-title{fill:currentColor;color:var(--hmd-tw-state-danger-text)}:root[theme=dark] :not([theme])>*>.markdown-body,:root[theme] [theme=dark] .markdown-body{color:#d4d4d8}:root[theme=dark] :not([theme])>*>.markdown-body h1,:root[theme=dark] :not([theme])>*>.markdown-body h2,:root[theme] [theme=dark] .markdown-body h1,:root[theme] [theme=dark] .markdown-body h2{border-bottom-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body h6,:root[theme] [theme=dark] .markdown-body h6{color:#a1a1aa}:root[theme=dark] :not([theme])>*>.markdown-body details,:root[theme] [theme=dark] .markdown-body details{background-color:#303036;color:#d4d4d8}:root[theme=dark] :not([theme])>*>.markdown-body details summary::marker:first-child,:root[theme] [theme=dark] .markdown-body details summary::marker:first-child{color:#d4d4d8}:root[theme=dark] :not([theme])>*>.markdown-body details:hover,:root[theme] [theme=dark] .markdown-body details:hover{background:#303036}:root[theme=dark] :not([theme])>*>.markdown-body details code,:root[theme=dark] :not([theme])>*>.markdown-body details[open]:hover,:root[theme] [theme=dark] .markdown-body details code,:root[theme] [theme=dark] .markdown-body details[open]:hover{background-color:#303036}:root[theme=dark] :not([theme])>*>.markdown-body hr,:root[theme] [theme=dark] .markdown-body hr{background-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body blockquote,:root[theme] [theme=dark] .markdown-body blockquote{border-left-color:#71717a;color:#a1a1aa}:root[theme=dark] :not([theme])>*>.markdown-body blockquote a span,:root[theme] [theme=dark] .markdown-body blockquote a span{color:#9894f9}:root[theme=dark] :not([theme])>*>.markdown-body a.mention-anchor.user-card-popover,:root[theme] [theme=dark] .markdown-body a.mention-anchor.user-card-popover{background-color:#453aff26;color:#9894f9}:root[theme=dark] :not([theme])>*>.markdown-body ::selection,:root[theme] [theme=dark] .markdown-body ::selection{background-color:#453aff99}:root[theme=dark] :not([theme])>*>.markdown-body .alert.alert-info,:root[theme] [theme=dark] .markdown-body .alert.alert-info{background-color:#38bdf81a;border-left-color:#0ea5e9;color:#38bdf8}:root[theme=dark] :not([theme])>*>.markdown-body .alert.alert-warning,:root[theme] [theme=dark] .markdown-body .alert.alert-warning{background-color:#fbbf241a;border-left-color:#f59e0b;color:#f59e0b}:root[theme=dark] :not([theme])>*>.markdown-body .alert.alert-success,:root[theme] [theme=dark] .markdown-body .alert.alert-success{background-color:#6db19d26;border-left-color:#55b685;color:#6db19d}:root[theme=dark] :not([theme])>*>.markdown-body .alert.alert-danger,:root[theme] [theme=dark] .markdown-body .alert.alert-danger{background-color:#ef444433;border-left-color:#ef4444;color:#f87171}:root[theme=dark] :not([theme])>*>.markdown-body .mark,:root[theme=dark] :not([theme])>*>.markdown-body mark,:root[theme] [theme=dark] .markdown-body .mark,:root[theme] [theme=dark] .markdown-body mark{background-color:#fbbf241a;color:#f59e0b}:root[theme=dark] :not([theme])>*>.markdown-body .mark span,:root[theme=dark] :not([theme])>*>.markdown-body mark span,:root[theme] [theme=dark] .markdown-body .mark span,:root[theme] [theme=dark] .markdown-body mark span{color:#fbbf24}:root[theme=dark] :not([theme])>*>.markdown-body .highlight pre,:root[theme=dark] :not([theme])>*>.markdown-body pre,:root[theme] [theme=dark] .markdown-body .highlight pre,:root[theme] [theme=dark] .markdown-body pre{background-color:#303036;color:#a1a1aa}:root[theme=dark] :not([theme])>*>.markdown-body .style .token.string,:root[theme=dark] :not([theme])>*>.markdown-body .token.entity,:root[theme=dark] :not([theme])>*>.markdown-body .token.operator,:root[theme=dark] :not([theme])>*>.markdown-body .token.url,:root[theme=dark] :not([theme])>*>.markdown-body.language-css,:root[theme=dark] :not([theme])>*>.markdown-body.token.string,:root[theme] [theme=dark] .markdown-body .style .token.string,:root[theme] [theme=dark] .markdown-body .token.entity,:root[theme] [theme=dark] .markdown-body .token.operator,:root[theme] [theme=dark] .markdown-body .token.url,:root[theme] [theme=dark] .markdown-body.language-css,:root[theme] [theme=dark] .markdown-body.token.string{background:none}:root[theme=dark] :not([theme])>*>.markdown-body :not(pre)>code,:root[theme] [theme=dark] .markdown-body :not(pre)>code{background-color:#3f3f46}:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-tag,:root[theme] [theme=dark] .markdown-body code .hljs-tag{color:#d4d4d8}:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-keyword,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-selector-tag,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-type,:root[theme=dark] :not([theme])>*>.markdown-body code .token.boolean,:root[theme=dark] :not([theme])>*>.markdown-body code .token.constant,:root[theme=dark] :not([theme])>*>.markdown-body code .token.deleted,:root[theme=dark] :not([theme])>*>.markdown-body code .token.number,:root[theme=dark] :not([theme])>*>.markdown-body code .token.property,:root[theme=dark] :not([theme])>*>.markdown-body code .token.symbol,:root[theme=dark] :not([theme])>*>.markdown-body code .token.tag,:root[theme] [theme=dark] .markdown-body code .hljs-keyword,:root[theme] [theme=dark] .markdown-body code .hljs-selector-tag,:root[theme] [theme=dark] .markdown-body code .hljs-type,:root[theme] [theme=dark] .markdown-body code .token.boolean,:root[theme] [theme=dark] .markdown-body code .token.constant,:root[theme] [theme=dark] .markdown-body code .token.deleted,:root[theme] [theme=dark] .markdown-body code .token.number,:root[theme] [theme=dark] .markdown-body code .token.property,:root[theme] [theme=dark] .markdown-body code .token.symbol,:root[theme] [theme=dark] .markdown-body code .token.tag{color:#ff70b4}:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-attribute,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-bullet,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-literal,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-number,:root[theme=dark] :not([theme])>*>.markdown-body code .hljs-symbol,:root[theme=dark] :not([theme])>*>.markdown-body code .token.atrule,:root[theme=dark] :not([theme])>*>.markdown-body code .token.attr-value,:root[theme=dark] :not([theme])>*>.markdown-body code .token.keyword,:root[theme] [theme=dark] .markdown-body code .hljs-attribute,:root[theme] [theme=dark] .markdown-body code .hljs-bullet,:root[theme] [theme=dark] .markdown-body code .hljs-literal,:root[theme] [theme=dark] .markdown-body code .hljs-number,:root[theme] [theme=dark] .markdown-body code .hljs-symbol,:root[theme] [theme=dark] .markdown-body code .token.atrule,:root[theme] [theme=dark] .markdown-body code .token.attr-value,:root[theme] [theme=dark] .markdown-body code .token.keyword{color:#9894f9}:root[theme=dark] :not([theme])>*>.markdown-body pre.plugin-rendered,:root[theme] [theme=dark] .markdown-body pre.plugin-rendered{background-color:#fff;color:#000}:root[theme=dark] :not([theme])>*>.markdown-body table,:root[theme] [theme=dark] .markdown-body table{border-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body table thead tr,:root[theme] [theme=dark] .markdown-body table thead tr{background-color:#303036;border-bottom-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body table td,:root[theme=dark] :not([theme])>*>.markdown-body table th,:root[theme] [theme=dark] .markdown-body table td,:root[theme] [theme=dark] .markdown-body table th{border-left-color:#52525b;border-top-color:#52525b}:root[theme=dark] :not([theme])>*>.markdown-body table tbody tr,:root[theme=dark] :not([theme])>*>.markdown-body table tr:nth-child(2n),:root[theme] [theme=dark] .markdown-body table tbody tr,:root[theme] [theme=dark] .markdown-body table tr:nth-child(2n){background-color:#27272a}:root[theme=light] :not([theme])>*>.markdown-body,:root[theme] [theme=light] .markdown-body{color:#3f3f46}:root[theme=light] :not([theme])>*>.markdown-body h1,:root[theme=light] :not([theme])>*>.markdown-body h2,:root[theme] [theme=light] .markdown-body h1,:root[theme] [theme=light] .markdown-body h2{border-bottom-color:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body h6,:root[theme] [theme=light] .markdown-body h6{color:#71717a}:root[theme=light] :not([theme])>*>.markdown-body iframe,:root[theme] [theme=light] .markdown-body iframe{border:1px solid #e4e4e7;box-sizing:border-box}:root[theme=light] :not([theme])>*>.markdown-body details,:root[theme] [theme=light] .markdown-body details{background-color:#f4f4f5}:root[theme=light] :not([theme])>*>.markdown-body details:hover,:root[theme] [theme=light] .markdown-body details:hover{background:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body details[open]:hover,:root[theme] [theme=light] .markdown-body details[open]:hover{background-color:#f4f4f5}:root[theme=light] :not([theme])>*>.markdown-body details code,:root[theme] [theme=light] .markdown-body details code{background-color:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body hr,:root[theme] [theme=light] .markdown-body hr{background-color:#d4d4d8}:root[theme=light] :not([theme])>*>.markdown-body blockquote,:root[theme] [theme=light] .markdown-body blockquote{border-left-color:#e4e4e7;color:#71717a}:root[theme=light] :not([theme])>*>.markdown-body blockquote a span,:root[theme] [theme=light] .markdown-body blockquote a span{color:#564dff}:root[theme=light] :not([theme])>*>.markdown-body a.mention-anchor.user-card-popover,:root[theme] [theme=light] .markdown-body a.mention-anchor.user-card-popover{background-color:#ecebfe;color:#564dff}:root[theme=light] :not([theme])>*>.markdown-body ::selection,:root[theme] [theme=light] .markdown-body ::selection{background-color:#cccafc}:root[theme=light] :not([theme])>*>.markdown-body .alert.alert-info,:root[theme] [theme=light] .markdown-body .alert.alert-info{background-color:#e0f2fe;border-left-color:#0284c7;color:#0284c7}:root[theme=light] :not([theme])>*>.markdown-body .alert.alert-warning,:root[theme] [theme=light] .markdown-body .alert.alert-warning{background-color:#fef3c799;border-left-color:#f59e0b;color:#f59e0b}:root[theme=light] :not([theme])>*>.markdown-body .alert.alert-success,:root[theme] [theme=light] .markdown-body .alert.alert-success{background-color:#d9f9e5;border-left-color:#43946c;color:#43946c}:root[theme=light] :not([theme])>*>.markdown-body .alert.alert-danger,:root[theme] [theme=light] .markdown-body .alert.alert-danger{background-color:#fee2e299;border-left-color:#ef4444;color:#ef4444}:root[theme=light] :not([theme])>*>.markdown-body .mark,:root[theme=light] :not([theme])>*>.markdown-body mark,:root[theme] [theme=light] .markdown-body .mark,:root[theme] [theme=light] .markdown-body mark{background-color:#fef3c799;color:#f59e0b}:root[theme=light] :not([theme])>*>.markdown-body .mark span,:root[theme=light] :not([theme])>*>.markdown-body mark span,:root[theme] [theme=light] .markdown-body .mark span,:root[theme] [theme=light] .markdown-body mark span{color:#f59e0b}:root[theme=light] :not([theme])>*>.markdown-body .highlight pre,:root[theme=light] :not([theme])>*>.markdown-body pre,:root[theme] [theme=light] .markdown-body .highlight pre,:root[theme] [theme=light] .markdown-body pre{background-color:#f4f4f5}:root[theme=light] :not([theme])>*>.markdown-body pre.plugin-rendered,:root[theme] [theme=light] .markdown-body pre.plugin-rendered{background-color:inherit;color:inherit}:root[theme=light] :not([theme])>*>.markdown-body :not(pre)>code,:root[theme] [theme=light] .markdown-body :not(pre)>code{background-color:#0000000a}:root[theme=light] :not([theme])>*>.markdown-body table,:root[theme] [theme=light] .markdown-body table{border-color:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body table thead tr,:root[theme] [theme=light] .markdown-body table thead tr{background-color:#f4f4f5;border-bottom-color:#d4d4d8}:root[theme=light] :not([theme])>*>.markdown-body table td,:root[theme=light] :not([theme])>*>.markdown-body table th,:root[theme] [theme=light] .markdown-body table td,:root[theme] [theme=light] .markdown-body table th{border-left-color:#e4e4e7;border-top-color:#e4e4e7}:root[theme=light] :not([theme])>*>.markdown-body table tbody tr,:root[theme=light] :not([theme])>*>.markdown-body table tr:nth-child(2n),:root[theme] [theme=light] .markdown-body table tbody tr,:root[theme] [theme=light] .markdown-body table tr:nth-child(2n){background-color:#fdfdfd}.markdown-body{font-family:Inter,-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,system-ui,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;max-width:758px;overflow:visible!important;padding-bottom:40px;padding-top:40px;position:relative}.markdown-body>*{max-width:100%}.markdown-body .alert a,.markdown-body a{color:var(--hmd-tw-link-text-default)}.markdown-body .alert a:focus,.markdown-body .alert a:hover,.markdown-body a:focus,.markdown-body a:hover{color:var(--hmd-tw-link-text-hover)}.markdown-body .alert a:hover,.markdown-body a:hover{text-decoration-thickness:2px;text-underline-offset:4px}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5{font-family:Readex Pro,-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;font-weight:700}.markdown-body h1,.markdown-body h2{border-bottom:1px solid}.markdown-body iframe,.markdown-body img{background-color:initial;border-radius:6px;margin:.5rem 0}.markdown-body iframe{max-width:100%;width:728px}.markdown-body details{border-radius:4px;margin-bottom:.5rem;padding:.5rem 1rem}.markdown-body details:hover{transition:all .1s}.markdown-body details summary+p{margin-top:.5rem}.markdown-body details p:last-child{margin-bottom:0}.markdown-body hr{height:2px}.markdown-body img.emoji{border:none;height:20px;vertical-align:middle;width:20px}.markdown-body li small{color:#a1a1aa}.markdown-body blockquote{border-left:3px solid}.markdown-body blockquote .small,.markdown-body blockquote small,.markdown-body li small{display:initial;font-size:85%}.markdown-body a.mention-anchor:before{content:"";margin-right:0}.markdown-body a.mention-anchor.user-card-popover{border-radius:4px;padding:1px 4px}.markdown-body .alert{border:none;border-radius:4px;margin-top:10px}.markdown-body .alert h2,.markdown-body .alert h3,.markdown-body .alert h4,.markdown-body .alert h5,.markdown-body .alert h6{margin-top:0}.markdown-body .alert h2{border:none}.markdown-body .alert.alert-danger,.markdown-body .alert.alert-info,.markdown-body .alert.alert-success,.markdown-body .alert.alert-warning{border-left:3px solid}.markdown-body .highlight pre,.markdown-body .mark,.markdown-body mark,.markdown-body pre{border-radius:4px}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.fretboard,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega-embed{border-radius:4px;max-width:100%;overflow:auto}.markdown-body .code-block-wrapper{border-radius:4px;outline-color:#0000;outline-style:solid;outline-width:1px;position:relative}.markdown-body .code-block-wrapper .code-toolbar{--tw-translate-y:-100%;--tw-shadow:0 3px 15px 0 #00000026;--tw-shadow-colored:0 3px 15px 0 var(--tw-shadow-color);background-color:var(--hmd-tw-element-bg-default);border-color:var(--hmd-tw-border-default);border-radius:4px;border-style:solid;border-width:1px;box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow);opacity:0;position:absolute;right:0;top:-1px;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));transition-duration:.15s;transition-property:all;transition-timing-function:cubic-bezier(.4,0,.2,1);visibility:hidden}.markdown-body .code-block-wrapper:hover{outline-color:var(--hmd-tw-border-primary-default);transition-duration:.15s;transition-property:outline-color;transition-timing-function:cubic-bezier(.4,0,.2,1)}.markdown-body .code-block-wrapper:hover .code-toolbar{opacity:1;visibility:visible}.markdown-body table{border:1px solid;border-radius:4px;width:fit-content}.markdown-body table thead tr{border-bottom:1px solid;border-top:none}.markdown-body table tbody tr,.markdown-body table thead tr th{border-top:none}.markdown-body table tbody tr td:first-child,.markdown-body table thead,.markdown-body table thead th:first-child{border-left:none}.markdown-body table td,.markdown-body table th{border:1px solid;border-bottom:none;border-right:none;padding:6px 13px}.markdown-body.next-editor{overflow-x:hidden!important}.markdown-body pre{border:inherit}.markdown-body code{color:inherit}html[lang^=ja] .markdown-body code code,html[lang^=ja] .markdown-body code kbd,html[lang^=ja] .markdown-body code pre{font-family:Source Code Pro,Consolas,monaco,Meiryo, ,MS Gothic,monospace}html[lang=zh-tw] .markdown-body code code,html[lang=zh-tw] .markdown-body code kbd,html[lang=zh-tw] .markdown-body code pre{font-family:Source Code Pro,Consolas,monaco,Microsoft JhengHei,,monospace}html[lang=zh-cn] .markdown-body code code,html[lang=zh-cn] .markdown-body code kbd,html[lang=zh-cn] .markdown-body code pre{font-family:Source Code Pro,Consolas,monaco,Microsoft YaHei,,monospace}html .markdown-body code[lang^=ja] code,html .markdown-body code[lang^=ja] kbd,html .markdown-body code[lang^=ja] pre{font-family:Source Code Pro,Consolas,monaco,Meiryo, ,MS Gothic,monospace}html .markdown-body code[lang=zh-tw] code,html .markdown-body code[lang=zh-tw] kbd,html .markdown-body code[lang=zh-tw] pre{font-family:Source Code Pro,Consolas,monaco,Microsoft JhengHei,,monospace}html .markdown-body code[lang=zh-cn] code,html .markdown-body code[lang=zh-cn] kbd,html .markdown-body code[lang=zh-cn] pre{font-family:Source Code Pro,Consolas,monaco,Microsoft YaHei,,monospace}.markdown-body pre code .wrapper{display:-moz-inline-flex;display:-ms-inline-flex;display:-o-inline-flex;display:inline-flex}.markdown-body pre code .gutter{float:left;overflow:hidden;-webkit-user-select:none;user-select:none}.markdown-body pre code .gutter.linenumber{border-right:2px solid #766df8;box-sizing:initial;color:#a1a1aa;cursor:default;display:inline-block;min-width:20px;padding:0 8px 0 0;position:relative;text-align:right;z-index:4}.markdown-body pre code .gutter.linenumber>span:before{content:attr(data-linenumber)}.markdown-body pre code .code{float:left;margin:0 0 0 16px}.markdown-body .gist .line-numbers{border-bottom:none;border-left:none;border-top:none}.markdown-body .gist .line-data{border:none}.markdown-body .gist table{border-collapse:inherit!important;border-spacing:0}.markdown-body code[data-gist-id]{background:none;padding:0}.markdown-body code[data-gist-id]:after,.markdown-body code[data-gist-id]:before{content:""}.markdown-body code[data-gist-id] .blob-num{border:unset}.markdown-body code[data-gist-id] table{margin-bottom:unset;overflow:unset}.markdown-body code[data-gist-id] table tr{background:unset}.markdown-body[dir=rtl] pre{direction:ltr}.markdown-body[dir=rtl] code{direction:ltr;unicode-bidi:embed}.markdown-body .alert{display:flex;flex-direction:column;gap:16px}.markdown-body .alert>*{margin:0}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega{background-color:inherit;border-radius:0;overflow:visible;text-align:center;white-space:inherit}.markdown-body pre.abc>code,.markdown-body pre.flow-chart>code,.markdown-body pre.graphviz>code,.markdown-body pre.mermaid>code,.markdown-body pre.sequence-diagram>code,.markdown-body pre.vega>code{text-align:left}.markdown-body pre.abc>svg,.markdown-body pre.flow-chart>svg,.markdown-body pre.graphviz>svg,.markdown-body pre.mermaid>svg,.markdown-body pre.sequence-diagram>svg,.markdown-body pre.vega>svg{height:100%;max-width:100%}.markdown-body pre>code.wrap{word-wrap:break-word;white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap}.markdown-body pre.pseudocode{white-space-collapse:collapse}.markdown-body summary{display:list-item}.markdown-body summary:focus{outline:none}.markdown-body details summary{cursor:pointer}.markdown-body details:not([open])>:not(summary){display:none}.markdown-body figure{margin:1em 40px}.markdown-body .mark,.markdown-body mark{background-color:#fff1a7}:root[theme] .markdown-body{line-height:1.75}:root[theme] .markdown-body ::marker,:root[theme] .markdown-body code{color:var(--hmd-tw-text-default)}:root[theme] .markdown-body h1,:root[theme] .markdown-body h2,:root[theme] .markdown-body h3,:root[theme] .markdown-body h4,:root[theme] .markdown-body h5,:root[theme] .markdown-body h6{overflow:visible}:root[theme] .markdown-body h1 .octicon-link,:root[theme] .markdown-body h2 .octicon-link,:root[theme] .markdown-body h3 .octicon-link,:root[theme] .markdown-body h4 .octicon-link,:root[theme] .markdown-body h5 .octicon-link,:root[theme] .markdown-body h6 .octicon-link{color:var(--hmd-tw-text-subtle)}:root[theme] .markdown-body .anchor{left:0;margin-left:0;position:absolute}:root[theme] .markdown-body .gist table{border-color:inherit}:root[theme] .markdown-body .gist table thead tr{background-color:inherit;border-bottom-color:inherit}:root[theme] .markdown-body .gist table td,:root[theme] .markdown-body .gist table th{border-left-color:inherit;border-top-color:inherit}:root[theme] .markdown-body .gist table tbody tr,:root[theme] .markdown-body .gist table tr:nth-child(2n){background-color:inherit}:root[theme] .markdown-body ol ol,:root[theme] .markdown-body ol ul,:root[theme] .markdown-body ul ol,:root[theme] .markdown-body ul ul{margin-bottom:12px;margin-top:6px}@media (max-width:767px){.markdown-body h1{font-size:1.6em}.markdown-body h2{font-size:1.4em}.markdown-body h3{font-size:1.125em}}.vimeo,.youtube{background-color:#000;background-position:50%;background-repeat:no-repeat;background-size:contain;cursor:pointer;display:table;overflow:hidden;text-align:center}.vimeo,.youtube{position:relative;width:100%}.youtube{padding-bottom:56.25%}.vimeo img{object-fit:contain;width:100%;z-index:0}.youtube img{object-fit:cover;z-index:0}.vimeo iframe,.youtube iframe,.youtube img{height:100%;left:0;position:absolute;top:0;width:100%}.vimeo iframe,.youtube iframe{vertical-align:middle;z-index:1}.vimeo .icon,.youtube .icon{color:#fff;height:auto;left:50%;opacity:.3;position:absolute;top:50%;transform:translate(-50%,-50%);transition:opacity .2s;width:auto;z-index:0}.vimeo:hover .icon,.youtube:hover .icon{opacity:.6;transition:opacity .2s}.slideshare .inner,.speakerdeck .inner{position:relative;width:100%}.slideshare .inner iframe,.speakerdeck .inner iframe{bottom:0;height:100%;left:0;position:absolute;right:0;top:0;width:100%}.figma{display:table;padding-bottom:56.25%;position:relative;width:100%}.figma iframe{border:1px solid #eee;bottom:0;height:100%;left:0;position:absolute;right:0;top:0;width:100%}.markmap-container{height:300px}.markmap-container>svg{height:100%;width:100%}.MJX_Assistive_MathML{display:none}#MathJax_Message{z-index:1000!important}.ui-infobar{color:var(--hmd-tw-text-default);font-size:14px;margin:25px auto -25px;max-width:760px;position:relative;z-index:2}.ui-infobar .ui-user-icon.small{height:18px;margin:2px;vertical-align:top;width:18px}.toc .invisable-node{list-style-type:none}.ui-toc{bottom:20px;position:fixed;z-index:998}.ui-toc.both-mode{margin-left:2px}.ui-toc.both-mode .ui-toc-label{border-bottom-left-radius:0;border-top-left-radius:0;height:40px;padding:10px 4px}:root[theme=light] :not([theme])>*>.ui-toc .ui-toc-label,:root[theme] [theme=light] .ui-toc-label{background-color:#fdfdfd;border-color:#d4d4d8;color:#a1a1aa}:root[theme=light] :not([theme])>*>.ui-toc .ui-toc-label:active,:root[theme=light] :not([theme])>*>.ui-toc .ui-toc-label:hover,:root[theme] [theme=light] .ui-toc-label:active,:root[theme] [theme=light] .ui-toc-label:hover{background-color:#f4f4f5;border-color:#d4d4d8;color:#a1a1aa}:root[theme=dark] :not([theme])>*>.ui-toc .ui-toc-label,:root[theme=dark] :not([theme])>*>.ui-toc .ui-toc-label:active,:root[theme=dark] :not([theme])>*>.ui-toc .ui-toc-label:hover,:root[theme] [theme=dark] .ui-toc-label,:root[theme] [theme=dark] .ui-toc-label:active,:root[theme] [theme=dark] .ui-toc-label:hover{background-color:#303036;border-color:#52525b;color:#a1a1aa}:root[theme=dark] :not([theme])>*>.ui-toc.both-mode .ui-toc-label,:root[theme] [theme=dark] .ui-toc.both-mode .ui-toc-label{background-color:#303036;border-color:#3f3f46;color:#d4d4d8}:root[theme=dark] :not([theme])>*>.ui-toc.both-mode .ui-toc-label:hover,:root[theme] [theme=dark] .ui-toc.both-mode .ui-toc-label:hover{background-color:#52525b}.ui-toc-label{border:1px solid;transition:opacity .2s}.ui-toc .open .ui-toc-label,.ui-toc-label:hover{opacity:1;transition:opacity .2s}.ui-toc-dropdown{letter-spacing:normal;margin-bottom:20px;margin-top:20px;max-height:70vh;max-width:45vw;overflow:auto;padding-left:10px;padding-right:10px;text-align:inherit;width:25vw}.ui-toc-dropdown.dropdown-menu{box-shadow:0 3px 15px 0 #00000026}.ui-toc-dropdown>.toc{max-height:calc(70vh - 100px);overflow:auto}.ui-toc-dropdown[dir=rtl] .nav{letter-spacing:.0029em;padding-right:0}.ui-toc-dropdown a{overflow:hidden;text-overflow:ellipsis;white-space:pre}.ui-toc-dropdown .nav>li>a{color:var(--hmd-tw-text-subtle);display:block;font-size:12px;font-weight:500;line-height:16px;padding:4px 20px}.ui-toc-dropdown .nav>li:first-child:last-child>ul,.ui-toc-dropdown .toc.expand ul{display:block}.ui-toc-dropdown .nav>li>a:focus,.ui-toc-dropdown .nav>li>a:hover{background-color:initial;border-color:var(--hmd-tw-border-bold);border-style:solid;border-width:0 0 0 1px;color:#000;color:var(--hmd-tw-text-emphasize);padding-left:19px;text-decoration:none}.ui-toc-dropdown[dir=rtl] .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav>li>a:hover{border-left:none;border-right:1px solid #000;padding-right:19px}.ui-toc-dropdown .nav>.active:focus>a,.ui-toc-dropdown .nav>.active:hover>a,.ui-toc-dropdown .nav>.active>a{background-color:initial;border-color:var(--hmd-tw-border-bold);border-style:solid;border-width:0 0 0 2px;color:var(--hmd-tw-text-emphasize);font-weight:600;padding-left:18px}.ui-toc-dropdown[dir=rtl] .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav>.active>a{border-width:0 2px 0 medium;border-left:0;border-color:var(--hmd-tw-border-bold);border-style:solid;padding-right:18px}.ui-toc-dropdown .nav .nav{display:none;padding-bottom:10px}.ui-toc-dropdown .nav>.active>ul{display:block}.ui-toc-dropdown .nav .nav>li>a{font-size:12px;font-weight:400;padding-bottom:1px;padding-left:30px;padding-top:1px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a{padding-right:30px}.ui-toc-dropdown .nav .nav>li>ul>li>a{font-size:12px;font-weight:400;padding-bottom:1px;padding-left:40px;padding-top:1px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a{padding-right:40px}.ui-toc-dropdown .nav .nav>li>a:focus,.ui-toc-dropdown .nav .nav>li>a:hover{padding-left:29px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:hover{padding-right:29px}.ui-toc-dropdown .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown .nav .nav>li>ul>li>a:hover{padding-left:39px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:hover{padding-right:39px}.ui-toc-dropdown .nav .nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>a{font-weight:500;padding-left:28px}.ui-toc-dropdown[dir=rtl] .nav .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>a{padding-right:28px}.ui-toc-dropdown .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active>a{font-weight:500;padding-left:38px}.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active>a{padding-right:38px}.ui-affix-toc{max-height:70vh;max-width:15vw;overflow:auto;position:fixed;top:0}.back-to-top,.expand-toggle,.go-to-bottom{color:var(--hmd-tw-text-subtle);display:block;font-size:12px;font-weight:500;line-height:16px;margin-left:10px;margin-top:10px;padding:2px 10px}.back-to-top:focus,.back-to-top:hover,.expand-toggle:focus,.expand-toggle:hover,.go-to-bottom:focus,.go-to-bottom:hover{color:var(--hmd-tw-text-primary);text-decoration:none}.back-to-top,.go-to-bottom{margin-top:0}.ui-user-icon{background-position:50%;background-repeat:no-repeat;background-size:cover;border-radius:50%;display:block;height:20px;margin-bottom:2px;margin-right:5px;margin-top:2px;width:20px}.ui-user-icon.small{display:inline-block;height:18px;margin:0 0 .2em;vertical-align:middle;width:18px}.ui-infobar>small>span{line-height:22px}.ui-infobar>small .dropdown{display:inline-block}.ui-infobar>small .dropdown a:focus,.ui-infobar>small .dropdown a:hover{text-decoration:none}.ui-more-info{cursor:pointer;vertical-align:middle}.ui-connectedGithub{line-height:23px;white-space:nowrap}.ui-connectedGithub a.file-path{text-decoration:none}.ui-connectedGithub a.file-path:active,.ui-connectedGithub a.file-path:hover{text-decoration:underline}.unselectable{-webkit-user-select:none;-o-user-select:none;user-select:none}.selectable{-webkit-user-select:text;-o-user-select:text;user-select:text}.inline-spoiler-section{cursor:pointer}.inline-spoiler-section .spoiler-text{background-color:#333;border-radius:2px}.inline-spoiler-section .spoiler-text>*{opacity:0}.inline-spoiler-section .spoiler-img{filter:blur(10px)}.inline-spoiler-section.raw{background-color:#333;border-radius:2px}.inline-spoiler-section.raw>*{opacity:0}.inline-spoiler-section.unveil{cursor:auto}.inline-spoiler-section.unveil .spoiler-text{background-color:#3333331a}.inline-spoiler-section.unveil .spoiler-text>*{opacity:1}.inline-spoiler-section.unveil .spoiler-img{filter:none}@media print{blockquote,div,img,pre,table{page-break-inside:avoid!important}a[href]:after{font-size:12px!important}}.markdown-body.slides{color:#222;position:relative;z-index:1}.markdown-body.slides:before{background-color:currentColor;bottom:0;box-shadow:0 0 0 50vw;content:"";display:block;left:0;position:absolute;right:0;top:0;z-index:-1}.markdown-body.slides section[data-markdown]{background-color:#fff;margin-bottom:1.5em;position:relative;text-align:center}.markdown-body.slides section[data-markdown] code{text-align:left}.markdown-body.slides section[data-markdown]:before{content:"";display:block;padding-bottom:56.23%}.markdown-body.slides section[data-markdown]>div:first-child{left:1em;max-height:100%;overflow:hidden;position:absolute;right:1em;top:50%;transform:translateY(-50%)}.markdown-body.slides section[data-markdown]>ul{display:inline-block}.markdown-body.slides>section>section+section:after{border:3px solid #777;content:"";height:1.5em;position:absolute;right:1em;top:-1.5em}.site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro, Pro W3,Osaka,Meiryo,,MS Gothic, ,sans-serif}html[lang=zh-tw] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,,sans-serif}html[lang=zh-cn] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,,sans-serif}body{font-smoothing:subpixel-antialiased!important;-webkit-font-smoothing:subpixel-antialiased!important;-moz-osx-font-smoothing:auto!important;-webkit-overflow-scrolling:touch;font-family:Source Sans Pro,Helvetica,Arial,sans-serif;letter-spacing:.025em}html[lang^=ja] body{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro, Pro W3,Osaka,Meiryo,,MS Gothic, ,sans-serif}html[lang=zh-tw] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,,sans-serif}html[lang=zh-cn] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,,sans-serif}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}abbr[data-original-title],abbr[title]{cursor:help}body.modal-open{overflow-y:auto;padding-right:0!important}svg{text-shadow:none}
    </style>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js" integrity="sha256-g6iAfvZp+nDQ2TdTR/VVKJf3bGro4ub5fvWSWVRi2NE=" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js" integrity="sha256-8E4Is26QH0bD52WoQpcB+R/tcWQtpzlCojrybUd7Mxo=" crossorigin="anonymous"></script>
    <![endif]-->
</head>

<body>
    <div id="doc" class="markdown-body container-fluid comment-enabled comment-inner" data-hard-breaks="true"><p><strong><a href="http://cs.brown.edu/courses/csci1390/" target="_blank" rel="noopener"><span> Back to the CS1390 website</span></a></strong></p><h1 id="Assignment-1-Parallelism-Techniques-" data-id="Assignment-1-Parallelism-Techniques-"><a class="anchor hidden-xs" href="#Assignment-1-Parallelism-Techniques-" title="Assignment-1-Parallelism-Techniques-"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Assignment 1: Parallelism Techniques </span><img class="emoji offline-handled error-handled" alt=":computer:" src="project1_files/computer.png"><span> </span><img class="emoji offline-handled error-handled" alt=":link:" src="project1_files/link.png"><span> </span><img class="emoji offline-handled error-handled" alt=":computer:" src="project1_files/computer.png"></h1><h4 id="Parts-1-2-correctness-only-due-Tuesday-February-4th-at-600pm-EST" data-id="Parts-1-2-correctness-only-due-Tuesday-February-4th-at-600pm-EST"><a class="anchor hidden-xs" href="#Parts-1-2-correctness-only-due-Tuesday-February-4th-at-600pm-EST" title="Parts-1-2-correctness-only-due-Tuesday-February-4th-at-600pm-EST"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><mark><strong><span>Parts 1-2 (correctness only) due Tuesday, February 4th at 6:00pm EST</span></strong></mark></h4><h4 id="All-parts-due-Wednesday-February-19th-at-600pm-EST" data-id="All-parts-due-Wednesday-February-19th-at-600pm-EST"><a class="anchor hidden-xs" href="#All-parts-due-Wednesday-February-19th-at-600pm-EST" title="All-parts-due-Wednesday-February-19th-at-600pm-EST"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><mark><strong><span>All parts due Wednesday, February 19th at 6:00pm EST</span></strong></mark></h4><h1 id="Introduction" data-id="Introduction"><a class="anchor hidden-xs" href="#Introduction" title="Introduction"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Introduction</span></h1><p><span>With
 increasingly larger models and training data becoming the norm, it has 
become challenging to train machine learning models efficiently due to 
constraints in computational resources and memory. These challenges have
 led to the development of various parallelism strategies to distribute 
computation and memory usage across multiple devices or nodes.</span></p><p><span>In
 this assignment, you will explore two common parallelism techniques in 
training machine learning models: data parallelism and model 
parallelism. After this, you will explore fully sharded data parallelism
 and pipeline parallelism, which address some of the limitations with 
data and model parallelism.</span></p><h3 id="Due-dates" data-id="Due-dates"><a class="anchor hidden-xs" href="#Due-dates" title="Due-dates"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Due dates:</span></h3><ul>
<li><span>This assignment has </span><em><span>two due dates</span></em><span>, one as an initial check in (deliverables described below), and one where the final assignment will be submitted. </span><em><span>You cannot use late hours on the initial check in.</span></em>
<ul>
<li><strong><span>Initial check in due on 2/04/2025 at 6 PM</span></strong></li>
<li><strong><span>Final assignment due on 2/19/2025 at 6 PM</span></strong></li>
</ul>
</li>
<li><span>The official late policy is described on the </span><a href="https://cs.brown.edu/courses/csci1390/#coursestructure" target="_blank" rel="noopener"><span>website</span></a><span>,
 in terms of the total number of late hours and how they are split 
across assignments. The grading server takes care of accounting for 
these across assignments and showing you how many are leftover!</span></li>
</ul><h3 id="Deliverables-for-Initial-Check-In" data-id="Deliverables-for-Initial-Check-In"><a class="anchor hidden-xs" href="#Deliverables-for-Initial-Check-In" title="Deliverables-for-Initial-Check-In"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Deliverables for Initial Check-In:</span></h3><ul>
<li><span>For the initial check-in, you will need to submit your code to
 the grading server with the implementation tasks in Part 1 (DDP) and 
Part 2 (model parallel) completed.</span></li>
<li><span>We will run the </span><strong><span>correctness tests</span></strong><span> for the DDP and Model Parallel; your implementation should be working correctly by the time the check-in is due</span>
<ul>
<li><span>It is </span><em><span>ok</span></em><span> if the code does 
not pass the correctness tests; we are mostly looking to see that you 
have made an effort to complete both parts. We recommend at least 
getting through these correctness tests, so you have time for the rest 
of the assignment!</span></li>
</ul>
</li>
<li><span>You </span><em><span>do not need to finish</span></em><span> the performance analysis sections or conceptual question sections within Parts 1 and 2 for the initial check-in</span></li>
</ul><h3 id="Deliverables-for-Final-Assignment" data-id="Deliverables-for-Final-Assignment"><a class="anchor hidden-xs" href="#Deliverables-for-Final-Assignment" title="Deliverables-for-Final-Assignment"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Deliverables for Final Assignment:</span></h3><ul>
<li><span>For the final submission, you will need to submit your code 
for all parts of the assignment to the grading server, and the writeup 
containing your generated graphs, explanations of the generated graphs, 
and answers to the math/conceptual questions.</span>
<ul>
<li><span>These questins are included in the </span><code>README.md</code><span> of the assignment repository; simply fill in your answers and graphs directly on the </span><code>README.md</code><span>.</span></li>
</ul>
</li>
<li><span>We are still in the process of setting up the grading server; 
we will post instructions on registering with the grading server later 
this week.</span>
<ul>
<li><span>We potentially hope to have a way for you to submit runs of 
any parts of the assignment below so you can generate the data to graph 
on the grading server; we will have more information on this later.</span></li>
</ul>
</li>
</ul><h2 id="Learning-Goals" data-id="Learning-Goals"><a class="anchor hidden-xs" href="#Learning-Goals" title="Learning-Goals"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Learning Goals</span></h2><ul>
<li><span>Learn about some of the different ways to parallelize training
 machine learning models, and understand their tradeoffs with respect to
 the following:</span>
<ul>
<li><strong><span>Memory Overhead</span></strong><span>: does this parallelism method require replicating any model state, causing extra memory overhead as we scale to multiple nodes?</span></li>
<li><strong><span>Communication Overhead</span></strong><span>: does 
this parallellism method require any communication between workers to 
synchronize any model state, which limits the scalability of the 
training method?</span></li>
</ul>
</li>
<li><span>Get hands on experience implementing these methods in PyTorch and measuring the performance of your implementations.</span></li>
<li><strong><span>A note about resources</span></strong><span>: The assignment will use </span><em><span>CPUs</span></em><span>
 to demonstrate parallel training. Because of this, the observed 
speedups may not actually match what one would see on a GPU. However, we
 have designed the questions and explorations in the assignment for you 
to understand what the </span><em><span>method should be doing</span></em><span>,
 so later, if you are ever in a situation where you use one of these 
methods for parallel training, you have a better understanding of its 
tradeoffs.</span></li>
</ul><h2 id="Assignment-Installation" data-id="Assignment-Installation"><a class="anchor hidden-xs" href="#Assignment-Installation" title="Assignment-Installation"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Assignment Installation</span></h2><p><span>The Github classroom link with the starter code can be found </span><a href="https://classroom.github.com/a/jPLIUX4J" target="_blank" rel="noopener"><span>here</span></a><span>.</span></p><h3 id="Using-Containers-for-Development" data-id="Using-Containers-for-Development"><a class="anchor hidden-xs" href="#Using-Containers-for-Development" title="Using-Containers-for-Development"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Using Containers for Development</span></h3><p><span>Make sure you have a container management tool installed locally (e.g., Docker or Podman). Then, use the </span><code>./run_docker</code><span> scripts  to pull and run containers as needed. (You may need to use </span><code>sudo</code><span> or </span><code>dos2unix</code><span> if you see any related error.)</span></p><ul>
<li>
<p><strong><span>For downloading the container:</span></strong></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><div class="wrapper"><div class="gutter linenumber"><span></span>
<span></span></div><div class="code"><span class="hljs-built_in">chmod</span> +x ./run_docker
./run_docker download
</div></div></code></pre>
      </div>
      
<p><span>This will download images according to your platform.</span></p>
</li>
<li>
<p><strong><span>For running the container:</span></strong><br>
<span>You need to specify the mount directory to use the current working directory within the container. </span><strong><span>Note that</span></strong><span>
 If you do not specify any parameter, it will run the container with 4 
CPUs and 4 GB memory, with the current directory as the mount directory.</span></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs">./run_docker run -s
        [mount_dir] -c [cpu_number] -m [memory_size]
</code></pre>
      </div>
      
<p><span>After executing this command, you should be able to access the container and see your work files in the current directory.</span></p>
</li>
</ul><div class="alert alert-warning">
<details><summary><span><span>Running instructions manually if the script goes wrong:</span></span></summary>
<p><span>You can try to run the following command (if you are using Podman, just replace docker to pod):</span></p>
<ul>
<li data-startline-back="64" data-endline-back="69"><span>For </span><code>linux/amd</code><span> architecture:</span>
      <div class="code-block-wrapper" data-startline-back="65" data-endline-back="69"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><div class="wrapper"><div class="gutter linenumber"><span></span>
<span></span>
<span></span></div><div class="code">docker pull cs1390mlsys/cs1390
docker tag cs1390mlsys/cs1390 cs1390
docker run -it --shm-size=1g --cpus=[cpu_num] -m=[memory] --mount type=bind,source=./,target=/home/cs1390-user cs1390 /bin/bash
</div></div></code></pre>
      </div>
      
</li>
<li data-startline-back="70" data-endline-back="75"><span>For </span><code>linux/arm</code><span> architecture:</span>
      <div class="code-block-wrapper" data-startline-back="71" data-endline-back="75"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><div class="wrapper"><div class="gutter linenumber"><span></span>
<span></span>
<span></span></div><div class="code">docker pull cs1390mlsys/cs1390.arm
docker tag cs1390mlsys/cs1390.arm cs1390.arm
docker run -it --shm-size=1g --cpus=[cpu_num] -m=[memory] --mount type=bind,source=./,target=/home/cs1390-user cs1390.arm /bin/bash
</div></div></code></pre>
      </div>
      
</li>
</ul>
</details>
</div><div class="alert alert-warning">
<details><summary><span><span>If you can't get docker or podman to work, here are alternate instructions:</span></span></summary>
<p><span>For projects 1 and 4, you can alternately use a local python environment. Note that project 1 requires the use of a function </span><code>os.sched_affinity</code><span>, which is not implemented for MacOS. You can comment this function (it is called within a function called </span><code>pin_to_core</code><span>) out for the purpose of getting the computation working, but your performance results may not make sense.</span></p>
<ol style="padding-left: 2em;">
<li data-startline-back="83" data-endline-back="84">
<p><span>Install miniconda with the instructions </span><a href="https://docs.anaconda.com/miniconda/install/" target="_blank" rel="noopener"><span>here</span></a><span>. Take note of the location where miniconda is installed, which we will call $PATH_TO_MINICONDA.</span></p>
</li>
<li data-startline-back="85" data-endline-back="86">
<p><span>Shell initialization: we recommend adding the conda 
initialization to your shell configuration (which may have been done 
during the install). To do this:</span></p>
</li>
</ol>

      <div class="code-block-wrapper" data-startline-back="87" data-endline-back="90"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><div class="wrapper"><div class="gutter linenumber"><span></span>
<span></span></div><div class="code"><span class="hljs-built_in">source</span> <span class="hljs-variable">$PATH_TO_MINICONDA</span>/bin/activate
conda init --all
</div></div></code></pre>
      </div>
      
<ol start="3" style="padding-left: 2em;">
<li data-startline-back="92" data-endline-back="92"><span>Check that conda is properly is initialized:</span></li>
</ol>

      <div class="code-block-wrapper" data-startline-back="93" data-endline-back="95"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><div class="wrapper"><div class="gutter linenumber"><span></span></div><div class="code">conda --version <span class="hljs-comment"># should print "24.11" or something similar</span>
</div></div></code></pre>
      </div>
      
<ol start="4" style="padding-left: 2em;">
<li data-startline-back="97" data-endline-back="99">
<p><span>We have found that </span><em><span>even if you modify your bashrc/zshrc to include the conda initialization sequence</span></em><span>, conda does not always initialize. Simply check if the conda initialization sequence is inside your </span><code>~/.bashrc</code><span>, and if not, repeat step 2; if so, run </span><code>source ~/.bashrc.</code></p>
</li>
<li data-startline-back="100" data-endline-back="100">
<p><span>Create a new environment for cs1390. The referenced requirements file is in the root folder of the git repository:</span></p>
</li>
</ol>

      <div class="code-block-wrapper" data-startline-back="101" data-endline-back="106"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><div class="wrapper"><div class="gutter linenumber"><span></span>
<span></span>
<span></span>
<span></span></div><div class="code">conda <span class="hljs-built_in">env</span> create --name cs1390 python=3.12
conda activate cs1390
conda install pytorch torchvision -c pytorch
pip install -r requirements.txt
</div></div></code></pre>
      </div>
      
</details>
</div><h2 id="Part-1-Distributed-Data-Parallel" data-id="Part-1-Distributed-Data-Parallel"><a class="anchor hidden-xs" href="#Part-1-Distributed-Data-Parallel" title="Part-1-Distributed-Data-Parallel"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Part 1: Distributed Data Parallel</span></h2><p><span>Distributed
 Data Parallel (DDP) works by replicating the model on each device, 
splitting the dataset into smaller shards, and training the model on 
each shard independently. After each training step, gradients are 
synchronized across all devices to ensure consistency.</span></p><p><span>In
 the first part of the assignment, you will create a model wrapper class
 inside pytorch for data parallel training of the VGG16 model on </span><strong><span>CPUs</span></strong><span>, and inspect its scalability.</span></p><h3 id="Implement-DDP" data-id="Implement-DDP"><a class="anchor hidden-xs" href="#Implement-DDP" title="Implement-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Implement DDP</span></h3><p><span>To get started, you will complete the blank sections in the </span><code>ddp.py</code><span> file. If you're unsure about what a specific function does, take a closer look at the </span><code>train_vgg16_cifar10_ddp</code><span> and </span><code>train_vgg16_cifar10_ddp_worker</code><span> functions for hints. It will always be helpful to review the lecture notes as well!</span></p><div class="alert alert-success">
<p><strong><span>Task 1.1</span></strong></p>
<ol style="padding-left: 2em;">
<li><span>Implement the </span><code>DistributedDataParallel</code><span>
 class. This class serves as a wrapper for the model, enabling 
distributed training across multiple devices. This includes completing 
the methods </span><code>broadcast_params</code><span> and </span><code>average_gradients</code><span>.</span></li>
<li><span>Complete the training process in </span><code>train_vgg16_cifar10_ddp_worker</code><span>, in the training data loader loop. This includes:</span>
<ul>
<li><span>Inserting methods to call the parallel model wrapper on each iteration of the dataloader, calculating the loss.</span></li>
<li><span>Performing the backward pass on each worker, updating the gradients, and updating the optimizer.</span></li>
<li><span>Please insert these in the correct places with respect to the timing code that measures </span><code>COMP_TIME</code><span> (time from loading the iteration to finishing the BW pass), </span><code>COMM_TIME</code><span> (the time to communicate the gradients), and </span><code>OPT_TIME</code><span> (the time to update the optimizer.)</span></li>
</ul>
</li>
<li><span>Use correctness test command below to ensure your implementation is right.</span></li>
<li><span>Feel free to add any state to the wrapper class you might need for implementing the method or for debugging (in the </span><code>__init__</code><span>) function.</span></li>
</ol>
<details><summary><span><span>hint</span></span></summary>
<p><span>To actually do communication, you can use the library </span><code>dist</code><span> (</span><code>torch.distributed</code><span>) </span><span class="smartypants"></span><span> this will have access to any communication functions you may need.</span></p>
</details>
</div><h3 id="Check-Correctness" data-id="Check-Correctness"><a class="anchor hidden-xs" href="#Check-Correctness" title="Check-Correctness"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Check Correctness</span></h3><p><span>After you've done with </span><strong><span>Task 1.1</span></strong><span>, you can use the following command to check whether your implementation is correct:</span></p><div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs">python train.py --num_batches 2 --num_workers 2 --learning_rate 1e-3 --batch_size 32 --check_output ddp
</code></pre>
      </div><p><span>With our random seed ensuring deterministic model 
training, this correctness test will compare you trained model to a 
baseline PyTorch implementation. This allows you to verify your 
implementation against the expected results. The test will check the 
weights of the trained model, and the output of the trained model on a 
test batch.</span></p><h3 id="Performance-Analysis" data-id="Performance-Analysis"><a class="anchor hidden-xs" href="#Performance-Analysis" title="Performance-Analysis"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Performance Analysis</span></h3><p><span>Before
 analyzing the performance of your DDP model, please be cognizant that 
your machine may not support 4 workers (because of the memory overhead).
 If this is the case, feel free to use up to 3 (or 2) workers for the 
below measurements. We recommend shutting of memory intensive 
applications, such as Slack. By default, </span><code>train.py</code><span> uses 1 CPU per core; you can also scale this up with the </span><code>--cores_per_worker</code><span> argument if you have enough resources. We will also try to provide instructions for you to schedule runs on the grading server.</span></p><h4 id="Split-Time-of-Each-Worker" data-id="Split-Time-of-Each-Worker"><a class="anchor hidden-xs" href="#Split-Time-of-Each-Worker" title="Split-Time-of-Each-Worker"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Split Time of Each Worker</span></h4><p><span>In
 distributed training, each node spends time executing its own tasks, 
and each node spends time on communication. Understanding the time spent
 in each stage is crucial for evaluating the scalability of your 
implementation.</span></p><div class="alert alert-success">
<p><strong><span>Task 1.2</span></strong><br>
<span>Based on the statistics recorded within the training loop, we have
 provided a built-in function that generates a graph that breaks down 
the time spent on each stage (communication, computation, and optimizer 
updates) and shows how this breakdown changes as the number of workers 
increase.</span><br>
<span>You can use the following commands to generate the data for the graph and plot the graph:</span></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><span class="hljs-comment"># Run DDP for 1, 2 and 4 workers</span>
python3 train.py --num_workers 1 ddp
python3 train.py --num_workers 2 ddp
python3 train.py --num_workers 4 ddp

<span class="hljs-comment"># command to plot</span>
python3 plot.py --output graphs/ddp_split_time.png split_time ddp=1,ddp=2,ddp=4
</code></pre>
      </div>
      
<p><span>Note that the graph will be automatically saved into file </span><code>$REPO/graphs/ddp_split_time.png</code><span>.</span></p>
<p><strong><span>Please include your generated graph here. If you are 
not able to finish this part of the assignment, we have provided a 
reference graph (generated on the grading server) for you to answer the 
question below.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.1</span></strong><br>
<span>Please use your graph or the reference graph below to answer the following questions:</span></p>
<ul>
<li><span>What is the expected behavior for computation time, optimizer 
update time, and communication time as the number of workers increase?</span></li>
<li><span>Does the generated graph match your expectations? If it looks different, try to analyze the reasons for the discrepancy.</span></li>
<li><span>How might the relative difference of computation and 
communication change for a system containing GPUs connected by 
high-bandwidth interconnects?</span></li>
</ul>
<p><span>If you could not generate the graph locally, we have provided a reference from the grading server.</span></p>
<div style="text-align: center;">
<img src="project1_files/upload_1e8cfd3a09207959192b8dfc441ef0f4.png" style="zoom:65%" class="offline-handled error-handled">
</div>
<details><summary><span><span>hint</span></span></summary>
<p><em><span>The difference between your graph and the expected graph 
could be influenced by factors related to your OS, concurrently running 
applications, or resources. But feel free to comment on any factors you 
believe are reasonable.</span></em></p>
</details>
</div><h4 id="Throughput" data-id="Throughput"><a class="anchor hidden-xs" href="#Throughput" title="Throughput"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Throughput</span></h4><p><span>Throughput generally refers to the number of samples a model can process per second.</span></p><div class="alert alert-success">
<p><strong><span>Task 1.3</span></strong><br>
<span>Now use your implementation of DDP to analyze the throughput as the number of workers scale.</span><br>
<span>To run this experiment, please run the following:</span></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><span class="hljs-comment"># Run DDP for 1, 2 and 4 workers</span>
python3 train.py --num_workers 1 ddp
python3 train.py --num_workers 2 ddp
python3 train.py --num_workers 4 ddp

<span class="hljs-comment"># PLOT the data</span>
python3 plot.py throughput ddp=1,ddp=2,ddp=4 --output graphs/ddp_throughput_comparison.png
</code></pre>
      </div>
      
<p><span>Note the generated graph is stored in </span><code>$REPO/graphs/ddp_throughput_comparison.png</code><span>.</span></p>
<blockquote>
<p><strong><span>Please include your generated graph here. If you are 
not able to finish this part of the assignment, we have provided a 
reference graph (generated on the grading server) for you to answer the 
question below</span></strong><span>.</span></p>
</blockquote>
</div><div class="alert alert-info">
<p><strong><span>Question 1.2</span></strong><br>
<span>Please analyze the scalability of your implementation. Start by 
considering what the ideal case would look like (perfect scalability 
with no overheads); then think about how potential bottlenecks influece 
performance. Does your graph match your expectations? Why or why not?</span></p>
<p><span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/upload_e60143591fb8ce5f7512d1930463629d.png" style="zoom:70%" class="offline-handled error-handled">
</div>
</div><h3 id="Math-time-Memory-Usage-and-Communication-in-DDP" data-id="Math-time-Memory-Usage-and-Communication-in-DDP"><a class="anchor hidden-xs" href="#Math-time-Memory-Usage-and-Communication-in-DDP" title="Math-time-Memory-Usage-and-Communication-in-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Math time: Memory Usage and Communication in DDP</span></h3><p><span>The main limitation of data parallelism is the high memory requirement; the model is replicated on each device.</span></p><p><span>Assume
 we have a model with P parameters. This means concretely that there are
 P model parameters, P gradients, and KP optimizer states (K represents 
how many variables the optimizer holds per parameter).</span></p><div class="alert alert-info">
<p><strong><span>Question 1.3</span></strong><br>
<span>For the data given above, write the memory consumption (in terms 
of P and K) when there are W parallel workers. Assume that the all data 
is stored with the same precision (e.g., all fp32 or all fp16), so you 
do not need to account for the precision in your answer.</span></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.4</span></strong><br>
<span>Now, consider a real-world scenario: We use SGD (which uses P parameters as state, just re-storing the parameters), with </span><strong><span>8</span></strong><span> workers, to train a model with </span><strong><span>10 billion</span></strong><span> parameters. We will use fp16 to store the model parameters and gradients, but use fp32 to keep the optimizer states (</span><a href="https://arxiv.org/pdf/1710.03740" target="_blank" rel="noopener"><span>mixed-precision training</span></a><span>). How much memory is required? (answer in GB)</span></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.5</span></strong><span>: In distributed data
 parallel, the workers have to communicate after each iteration in order
 to synchronize gradients. Suppose that we have W workers, our model has
 P parameters, our network bandwidth is B (between any pair of workers),
 and we use a ring all-reduce algorithm. Write down an expression that 
captures the time it takes for the gradient synchronization.</span></p>
</div><div class="alert alert-info">
<p><strong><span>Question 1.6</span></strong><span>: Now let's plug in real values to the above expression. Assume that we have </span><strong><span>8</span></strong><span> workers, </span><strong><span>10 billion</span></strong><span> parameters, and we use fp16 for parameters and gradients, but fp32 to keep optimizer states. Assume the network bandwidth is </span><strong><span>100 Gb/s</span></strong><span>. Provide your answer in seconds.</span></p>
</div><h3 id="Deliverables-for-Mid-Project-Checkpoint-Due-on-204" data-id="Deliverables-for-Mid-Project-Checkpoint-Due-on-204"><a class="anchor hidden-xs" href="#Deliverables-for-Mid-Project-Checkpoint-Due-on-204" title="Deliverables-for-Mid-Project-Checkpoint-Due-on-204"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Deliverables for Mid-Project Checkpoint Due on 2/04</span></h3><p><span>For
 the mid-project check-in, we want you to have implemented DDP and have 
the correctness tests running (task 1.1). The test does not need to be 
successful, but you should have an attempt at the code.</span></p><h2
id="Part-2-Model-Parallelism" data-id="Part-2-Model-Parallelism"><a
class="anchor hidden-xs" href="#Part-2-Model-Parallelism"
title="Part-2-Model-Parallelism"><span class="octicon octicon-link ph
ph-link-simple-horizontal"></span></a><span>Part 2: Model
Parallelism</span></h2><p><span>One form of model
 parallelism works by splitting the model into layers, and putting 
partitions of contiguous layers on each device. The forward pass goes 
through the partitions in order, while the backward pass propagates 
gradients in reverse order. Model parallelism reduces communication 
overhead compared to DDP because communication only happens at partition
 boundaries. However, this form of model parallelism has very low worker 
utilization because only one worker is running at a time. We will 
explore a way to improve this in the next part of the assignment.</span></p><p><span>For
 now, in this part of the assignment, you will create a model parallel 
wrapper class inside pytorch for model parallel training of the VGG16 
model on CPUs, and inspect its throughput, as well as a timeline of when
 computation occurs on each worker. Note that there are different types of model
 parallelism, such as tensor model parallelism, which we will discuss in class,
 but you are not implementing here.</span></p><h3 id="Code-Structure-for-Model-Parallelisn" data-id="Code-Structure-for-Model-Parallelisn"><a class="anchor hidden-xs" href="#Code-Structure-for-Model-Parallelisn" title="Code-Structure-for-Model-Parallelisn"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Code Structure for Model Parallelisn</span></h3><p><span>The
 code for model parallelism is structured slightly differently than the 
data parallel wrapper. We recommend taking a look at it before starting 
to understand the differences (in </span><code>/model_parallel.py</code><span>):</span></p><ol style="padding-left: 2em;">
<li>
<p><span>Instead of a single wrapper, there are two wrappers: one which the training loop uses (</span><code>ModelParallelWrapper</code><span>) to orchestrate forward and backward passes on each worker, and </span><code>ModelParallelWorker</code><span>, which actually does the forward and backward pass on each worker, communicating with the previous and next partition.</span></p>
</li>
<li>
<p><span>The </span><code>train_vgg16_cifar10_model_parallel</code><span> additionally calls a method called </span><code>split_vgg16</code><span>
 to partition the model into partitions, and then passes a partition to 
each worker. This shows how in model parallel, the entire model is 
actually </span><em><span>split</span></em><span> across workers, and there is no immediate memory overhead.</span></p>
</li>
<li>
<p><span>As with DDP, feel free to add any state to the wrapper classes 
you might need for implementing the method or for debugging (in the </span><code>__init__</code><span>) function.</span></p>
</li>
</ol><h3 id="Implement-Model-Parallelism" data-id="Implement-Model-Parallelism"><a class="anchor hidden-xs" href="#Implement-Model-Parallelism" title="Implement-Model-Parallelism"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Implement Model Parallelism</span></h3><p><span>We
 have divided the implementation for model parallelism into 3 parts: 
figuring out the communication sizes for each partition boundary, the 
forward pass, and the backward pass.</span></p><h4 id="Model-Parallel-Part-1-Calculate-communication-sizes-at-each-partition-boundary" data-id="Model-Parallel-Part-1-Calculate-communication-sizes-at-each-partition-boundary"><a class="anchor hidden-xs" href="#Model-Parallel-Part-1-Calculate-communication-sizes-at-each-partition-boundary" title="Model-Parallel-Part-1-Calculate-communication-sizes-at-each-partition-boundary"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Model Parallel Part 1: Calculate communication sizes at each partition boundary</span></h4><div class="alert alert-success">
<p><strong><span>Task 2.1</span></strong><br>
<span>In </span><code>utils.py</code><span>, fill in the function </span><code>analyze_communication_with_partitons</code><span>.
 You will be using MPI point to point communication functions to move 
data between workers during the forward and backward passes, and these 
functions require the receiver to know </span><em><span>how much</span></em><span> data will exactly be received. This function will later be used for pipeline parallel as well.</span></p>
<details><summary><span><span>hint</span></span></summary>
<p><span>We recommend writing code to run the forward and backward pass 
to understand what data will be communicated. This will require the use 
of torch.autograd.grad.</span></p>
</details>
</div><p><span>We have provided a command with which you can check this is implemented correctly:</span></p><div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="shell hljs"><div class="wrapper"><div class="gutter linenumber"><span></span></div><div class="code">python3 comm_test.py
</div></div></code></pre>
      </div><h4 id="Model-Parallel-Part-2-Implement-forward-pass" data-id="Model-Parallel-Part-2-Implement-forward-pass"><a class="anchor hidden-xs" href="#Model-Parallel-Part-2-Implement-forward-pass" title="Model-Parallel-Part-2-Implement-forward-pass"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Model Parallel Part 2: Implement forward pass</span></h4><div class="alert alert-success">
<p><strong><span>Task 2.2</span></strong><br>
<span>Next, in </span><code>model_parallel.py</code><span>, inside both the </span><code>ModelParallelWrapper</code><span> and </span><code>ModelParallelWorker</code><span> classes, please fill in the </span><code>forward</code><span> functions.</span></p>
<details><summary><span><span>hint</span></span></summary>
<p><span>We recommend using the MPI point to point communication 
primitives to communicate data between workers. You can access 
communication through the </span><code>dist</code><span> library; see MPI's </span><code>send</code><span> and </span><code>recv</code><span> functions.</span></p>
</details>
</div><p><span>:::</span></p><h4 id="Model-Parallel-Part-3-Implement-backward-pass" data-id="Model-Parallel-Part-3-Implement-backward-pass"><a class="anchor hidden-xs" href="#Model-Parallel-Part-3-Implement-backward-pass" title="Model-Parallel-Part-3-Implement-backward-pass"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Model Parallel Part 3: Implement backward pass</span></h4><div class="alert alert-success">
<p><strong><span>Task 2.3</span></strong><br>
<span>Finally, in </span><code>model_parallel.py</code><span>, inside both the </span><code>ModelParallelWrapper</code><span> and the </span><code>ModelParallelWorker</code><span> classes, please fill in the </span><code>backward</code><span> functions.</span></p>
<details><summary><span><span>hint</span></span></summary>
<p><span>Remember that you will need to use torch.autograd.grad to 
calculate gradients; remember that this calculation requires the outputs
 and inputs at that layer.</span></p>
</details>
</div><p><span>After all these tasks are done, use following command to test correctness:</span></p><div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs">python train.py --num_batches 2 --num_workers 2 --learning_rate 1e-3 --batch_size 32 --check_output model

</code></pre>
      </div><h3 id="Performance-Analysis24" data-id="Performance-Analysis"><a class="anchor hidden-xs" href="#Performance-Analysis24" title="Performance-Analysis24"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Performance Analysis</span></h3><div class="alert alert-success">
<p><strong><span>Task 2.4</span></strong><br>
<span>Generate a timeline graph for model parallel with 3 workers and 
place it here. This timeline graph shows what computation is happening 
on each worker across an entire iteration. To do this, run the following
 commands:</span></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs">python3 train.py --num_workers 3 model

<span class="hljs-comment"># plot</span>
python3 plot.py --output model_timeline.png timeline model=3
</code></pre>
      </div>
      
<p><span>Note that this command will produce the plot in </span><code>$REPO/graphs/model_timeline.png</code><span>.</span></p>
<p><strong><span>Please include your generated graph here. If you are 
not able to finish this part of the assignment, we have provided a 
reference graph (generated on the grading server) for you to answer the 
question below.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 2.1</span></strong><br>
<span>Analyze the above timeline graph. Does it match your expectations of what model parallelism should be doing on each worker?</span><br>
<span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/upload_dee3c830e1dc0719dc6f41daad7d10fd.png" style="zoom:75%" class="offline-handled error-handled">
</div>
</div><div class="alert alert-success">
<p><span>Task 2.5: Generate a throughput graph for model parallelism</span></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs">python3 train.py --num_workers 1 model
python3 train.py --num_workers 2 model
python3 train.py --num_workers 3 model

<span class="hljs-comment"># plot</span>
python3 plot.py throughput  model=1,model=2,model=3 --output model_throughput_comparison.png
</code></pre>
      </div>
      
<p><span>Note that this command will produce the plot in </span><code>$REPO/model_throughput_comparison.png</code><span>.</span></p>
<p><strong><span>Please include your generated graph here. If you are 
not able to finish this part of the assignment, we have provided a 
reference graph (generated on the grading server) for you to answer the 
question below.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 2.2</span></strong><span>: Analyze the above 
throughput graph. Does it match your expectations of how model 
parallelism should scale as the number of workers increases?</span><br>
<span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/upload_3ea2772216ba43230f784c472225e3f2.png" style="zoom:60%" class="offline-handled error-handled">
</div>
</div><h3 id="Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP" data-id="Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP"><a class="anchor hidden-xs" href="#Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP" title="Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Math time: Comparison of Communication in Model Parallel vs. DDP</span></h3><div class="alert alert-info">
<p><strong><span>Question 2.3</span></strong><span>: In distributed data
 parallel, the workers have to communicate after each iteration in order
 to synchronize gradients (as you explored in Questions 1.5 and 1.6). In
 model parallelism, communication happens at partition boundaries. 
Assume that there are L total layers, divided into P partitions 
(equally). The input batch size is B.</span></p>
<ul>
<li><span>How much communication occurs (across all partitions in aggregate) during the forward pass?</span></li>
<li><span>How much communication occurs (across all partitions in aggregate) during the backward pass?</span></li>
</ul>
<p><span>When we say "how much", we mean the amount of data that is being transferred in one iteration.</span></p>
</div><h3 id="Deliverables-for-Mid-Project-Checkpoint-Due-on-20426" data-id="Deliverables-for-Mid-Project-Checkpoint-Due-on-204"><a class="anchor hidden-xs" href="#Deliverables-for-Mid-Project-Checkpoint-Due-on-20426" title="Deliverables-for-Mid-Project-Checkpoint-Due-on-20426"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Deliverables for Mid-Project Checkpoint Due on 2/04</span></h3><p><span>For
 the mid-project check-in, we want you to have implemented model 
parallelism and have the correctness tests running (tasks 2.1-2.3). The 
test does not need to be successful, but you should have an attempt at 
the code.</span></p><h2 id="Part-3-Reducing-the-Memory-Overhead-of-DDP" data-id="Part-3-Reducing-the-Memory-Overhead-of-DDP"><a class="anchor hidden-xs" href="#Part-3-Reducing-the-Memory-Overhead-of-DDP" title="Part-3-Reducing-the-Memory-Overhead-of-DDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Part 3: Reducing the Memory Overhead of DDP</span></h2><p><span>One
 downside of DDP is that it requires the entire model to be loaded on a 
single device. To reduce the memory overhead of the model, its tensors 
can be sharded across devices. Whenever a device requires the entire 
tensor (during a forward or backward pass), the tensor can be gathered 
to perform the computation and then freed. Each device is responsible 
for its own shard, and updates it accordingly.</span></p><p><span>In 
this part of the assignment, you will implement a simplified version of 
FSDP (Fully Sharded Data Parallel). Once implemented, FSDP will be 
compared to DDP to understand how the two methods scale.</span></p><h3 id="Implement-FSDP" data-id="Implement-FSDP"><a class="anchor hidden-xs" href="#Implement-FSDP" title="Implement-FSDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Implement FSDP</span></h3><p><span>Just like DDP and Model Parallel, fill in the blank section in the </span><code>fsdp.py</code><span> file. Note the </span><code>init_local_info</code><span> and </span><code>init_layers_and_params</code><span> methods, they set up the sharded tensors that you will be working with.</span></p><div class="alert alert-success">
<p><strong><span>Task 3.1</span></strong></p>
<ol style="padding-left: 2em;">
<li><span>Implement the </span><code>FullyShardedDataParllel</code><span> class. This class is the wrapper used for a single worker.</span></li>
<li><span>Complete the training process in </span><code>train_vgg16_cifar10_fsdp</code><span>.</span></li>
<li><span>Use the correctness test command below to ensure your implementation is right.</span></li>
<li><span>As with DDP and model parallel, feel free to add any state to 
the wrapper class you might need for implementing the method or for 
debugging (in the </span><code>__init__</code><span>) function.</span></li>
</ol>
</div><h3 id="Check-FSDP-for-Correctness" data-id="Check-FSDP-for-Correctness"><a class="anchor hidden-xs" href="#Check-FSDP-for-Correctness" title="Check-FSDP-for-Correctness"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Check FSDP for Correctness</span></h3><p><span>Once you've implemented FSDP, you can use the following command to check whether your implementation is correct:</span></p><div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs">python train.py fsdp --num_batches 2 --num_workers 2 --learning_rate 1e-2 --batch_size 32 --check_weights --check_output
</code></pre>
      </div><h3 id="Performance-Analysis30" data-id="Performance-Analysis"><a class="anchor hidden-xs" href="#Performance-Analysis30" title="Performance-Analysis30"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Performance Analysis</span></h3><h4 id="Throughput31" data-id="Throughput"><a class="anchor hidden-xs" href="#Throughput31" title="Throughput31"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Throughput</span></h4><div class="alert alert-success">
<p><strong><span>Task 3.2</span></strong><br>
<span>Now use your implementation of FSDP to analyze the throughput as the number of workers scale.</span><br>
<span>To run this experiment, please run the following:</span></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs"><span class="hljs-comment"># Run DDP for 1, 2 and 4 workers</span>
python3 train.py --num_workers 1 fsdp
python3 train.py --num_workers 2 fsdp
python3 train.py --num_workers 4 fsdp

<span class="hljs-comment"># PLOT the data</span>
python3 plot.py throughput fsdp=1,fsdp=2,fsdp=4 --output fsdp_throughput_comparison.png
</code></pre>
      </div>
      
<p><span>Note that this command will produce the plot in </span><code>$REPO/fsdp_throughput_comparison.png</code><span>.</span></p>
<p><strong><span>Please include your generated graph here. If you are 
not able to finish this part of the assignment, we have provided a 
reference graph (generated on the grading server) for you to answer the 
question below.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 3.1</span></strong><br>
<span>Please analyze the scalability of your FSDP implementation. 
Compare this graph to the previous DDP throughout graph. Do the two 
methods scale as you expected? Why or why not? Which one has better raw 
performance? Why? How does the communication required for FSDP and DDP 
differ?</span></p>
<p><span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/upload_73ff234321b436b52950b96a5175b1d2.png" style="zoom:60%" class="offline-handled error-handled">
</div>
</div><h3 id="Math-Time-Memory-Overhead-of-DDP-vs-FSDP" data-id="Math-Time-Memory-Overhead-of-DDP-vs-FSDP"><a class="anchor hidden-xs" href="#Math-Time-Memory-Overhead-of-DDP-vs-FSDP" title="Math-Time-Memory-Overhead-of-DDP-vs-FSDP"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Math Time: Memory Overhead of DDP vs. FSDP</span></h3><div class="alert alert-info">
<p><strong><span>Question 3.2</span></strong><br>
<span>Our implementation of FSDP only handled sharding the parameter 
states, but in reality, a full implementation would shard the gradients 
during the backward pass, and the optimizer state as well. Let's return 
to the scenario from Question 1.3 and 1.4, but instead consider Adam.</span><br>
<span>Specifically:</span></p>
<ul>
<li><span>We have a model with P parameters.</span></li>
<li><span>The Adam optimizer stores the parameters,  momentum and 
variance, for a total of 3P state. Again assume that the all data is 
stored with the same precision (e.g., all fp32 or all fp16), so you do 
not need to account for the precision in your answer.</span><br>
<span>Write expressions that capture the following, when we have W workers:</span></li>
</ul>
<ol style="padding-left: 2em;">
<li><span>The memory overhead on each worker when nothing is sharded (same as DDP)</span></li>
<li><span>The memory overhead when the optimizer state is sharded.</span></li>
<li><span>The memory overhead when the optimizer state and gradients are sharded.</span></li>
<li><span>The memory overhead when everything is sharded.</span></li>
</ol>
</div><div class="alert alert-info">
<p><strong><span>Question 3.3</span></strong><br>
<span>Now let's plug in some values above. We are again using 
mixed-precision training, where models and gradients are stored in fp16,
 but the optimizer states are stored in fp32. Our model has 10 billion 
parameters. In bytes, what is the memory overhead per worker, when:</span></p>
<ol style="padding-left: 2em;">
<li><span>The optimizer is sharded</span></li>
<li><span>The optimizer and gradients are sharded</span></li>
<li><span>Everything is sharded.</span></li>
</ol>
<p><span>For full credit, please write out exactly how you arrived at these values.</span></p>
</div><h2 id="Part-4-Pipeline-Parallelism" data-id="Part-4-Pipeline-Parallelism"><a class="anchor hidden-xs" href="#Part-4-Pipeline-Parallelism" title="Part-4-Pipeline-Parallelism"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Part 4: Pipeline Parallelism</span></h2><p><span>In
 model parallelism, backpropagation begins only after forward 
propagation is completed, which leads to low resource utilization on 
worker nodes. To improve resource utilization, we can introduce 
pipelining, by dividing the data into multiple microbatches. By doing 
so, the computation processes of different microbatches can overlap in 
time, enhancing resource utilization.</span></p><h3 id="Implement-Pipeline-Parallelism" data-id="Implement-Pipeline-Parallelism"><a class="anchor hidden-xs" href="#Implement-Pipeline-Parallelism" title="Implement-Pipeline-Parallelism"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Implement Pipeline Parallelism</span></h3><div class="alert alert-success">
<p><strong><span>Task 4.1</span></strong><br>
<span>The overall workflow of the pipeline is very similar to model parallelism, but notice the new </span><code>microbatch_idx</code><span> parameter which is to keep track of currently processed data.</span></p>
<ol style="padding-left: 2em;">
<li><span>Implement class </span><code>PipelineParallelWorker</code><span>: </span><code>forward</code><span> and </span><code>backward</code></li>
<li><span>Implement class </span><code>PipelineParallel</code><span>. </span><code>forward</code><span>, </span><code>backward</code><span>, </span><code>train_step</code><span> and </span><code>eval</code><span>:</span>
<ul>
<li><span>Note that </span><code>eval</code><span> and </span><code>train_step</code><span>
 may have some repeated logic; eval is for actually running the model 
(in microbatches) without the backward pass when running the correctness
 test.</span></li>
</ul>
</li>
<li><span>Pass the correctness test.</span></li>
<li><span>As with the previous methods, feel free to add any state to 
the wrapper classeses you might need for implementing the method or for 
debugging (in the </span><code>__init__</code><span>) function.</span></li>
</ol>
</div><details><summary><span><span>correctness check command</span></span></summary>

      <div class="code-block-wrapper" data-startline-back="473" data-endline-back="475"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs">python train.py pipeline --num_batches 2 --num_workers 2 --learning_rate 1e-2 --batch_size 32 --check_output
</code></pre>
      </div>
      
</details><h3 id="Performance-Analysis35" data-id="Performance-Analysis"><a class="anchor hidden-xs" href="#Performance-Analysis35" title="Performance-Analysis35"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Performance Analysis</span></h3><div class="alert alert-success">
<p><strong><span>Task 4.2</span></strong><br>
<span>Generate a timeline graph for pipeline parallelism with 3 workers and place it here. To do this, run the following commands:</span></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code class="sh hljs">python3 train.py --num_workers 3 pipeline

python3 plot.py timeline --output pipeline_timeline.png pipeline=3
</code></pre>
      </div>
      
<p><span>Note that this command will produce the plot in </span><code>$REPO/pipeline_timeline.png</code><span>.</span></p>
<p><strong><span>Please include your generated graph here. If you are 
not able to finish this part of the assignment, we have provided a 
reference graph (generated on the grading server) for you to answer the 
question below.</span></strong></p>
</div><p><span>Note that the above command stores the graph in </span><code>$REPO/pipeline_timeline.png</code></p><div class="alert alert-info">
<p><strong><span>Question 4.1</span></strong><br>
<span>Analyze the above timeline graph. Does it match your expectations of what pipeline parallelism should be doing on each worker?</span><br>
<span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/upload_1dc333c4ebbfd8c703daf36ed599daff.png" style="zoom:75%" class="offline-handled error-handled">
</div>
</div><div class="alert alert-success">
<p><strong><span>Task 4.3</span></strong><br>
<span>Generate a throughput graph for pipeline parallelism</span></p>

      <div class="code-block-wrapper"><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div>
        <pre><code>python3 train.py --num_workers 1 pipeline
python3 train.py --num_workers 2 pipeline
python3 train.py --num_workers 3 pipeline


python plot.py --output pipeline_throughput_comparison.png throughput pipeline=1,pipeline=2,pipeline=3
</code></pre>
      </div>
      
<p><span>Note that this command will produce the plot in </span><code>$REPO/pipeline_throughput_comparison.png</code><span>.</span></p>
<p><strong><span>Please include your generated graph here. If you are 
not able to finish this part of the assignment, we have provided a 
reference graph (generated on the grading server) for you to answer the 
question below.</span></strong></p>
</div><div class="alert alert-info">
<p><strong><span>Question 4.2</span></strong><br>
<span>Analyze the above throughput graph. Does it match your 
expectations of how model pipeline should scale as the number of workers
 increases? How does the performance of pipeline parallelism compare 
with model parallelism and why?</span><br>
<span>If you were not able to generate the graph, we have provided a reference version from the grading server:</span></p>
<div style="text-align: center;">
<img src="project1_files/upload_973ae5fe8141f827af2681d2e6cc2d9a.png" style="zoom:60%" class="offline-handled error-handled">
</div>
</div><h3 id="Math-Time-Pipeline-Bubble-Size" data-id="Math-Time-Pipeline-Bubble-Size"><a class="anchor hidden-xs" href="#Math-Time-Pipeline-Bubble-Size" title="Math-Time-Pipeline-Bubble-Size"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Math Time: Pipeline Bubble Size</span></h3><div class="alert alert-info">
<p><strong><span>Question 4.3</span></strong><br>
<span>In the </span><a href="https://arxiv.org/pdf/1811.06965" target="_blank" rel="noopener"><span>GPipe</span></a><span> paper, </span><strong><span>section 2.3 Performance Optimization</span></strong><span>, the author proposed that the size of the pipeline bubble (the fraction of times when workers are not being utilized) is:</span><br>
<span class="mathjax code-block-wrapper" data-raw-code="T1xsZWZ0KFxmcmFje0stMX17TStLLTF9XHJpZ2h0KQ" style="display: block;"></span></p><div class="code-toolbar"><button class="rounded text-normal font-normal leading-normal flex bg-transparent text-text-default border border-solid border-transparent hocus:bg-element-bg-hover hocus:text-text-emphasize hover:border-element-bg-hover focus:shadow-[0_0_0_2px_#77777733] focus:border-element-border-hover disabled:bg-transparent disabled:hocus:bg-transparent disabled:hocus:border-transparent disabled:text-element-text-disabled disabled:hocus:text-element-text-disabled ui-code-block-copy-button p-[7px]" data-state="closed"><i class="inline-flex ph ph-clipboard-text" aria-hidden="true" style="width: 20px; height: 20px; font-size: 20px; line-height: 20px;"></i></button></div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 113.1%; position: relative;" display="true" tabindex="0" ctxtmenu_counter="0"><mjx-math display="true" style="margin-left: 0px; margin-right: 0px;" class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>O</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mrow><mi>K</mi><mo></mo><mn>1</mn></mrow><mrow><mi>M</mi><mo>+</mo><mi>K</mi><mo></mo><mn>1</mn></mrow></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container><br>
<span>Please derive this expression based on Figure 2a in the paper.</span><p></p>
</div><p><span>Even though the approach in </span><a
    href="https://arxiv.org/pdf/1811.06965" target="_blank"
    rel="noopener"><span>GPipe</span></a><span> improves utilization over model
    parallelism, we can still observe idle gaps where workers are not being
    used. In the paper </span><a
    href="https://people.eecs.berkeley.edu/~matei/papers/2019/sosp_pipedream.pdf"
    target="_blank" rel="noopener"><span>PipeDream</span></a><span>, the authors
    proposed a different approach (with a schedule called </span><strong><span>1F1B</span></strong><span>).</span></p><div class="alert alert-info">
<p><strong><span>Question 4.4</span></strong><br>
<span>Referring to Figure 4, does </span><strong><span>1F1B</span></strong><span>
 reduce bubble size compared to the Gpipe version? If so -- why; if not -- what
 are the benefits of the alternate schedule in terms of active memory use,
 compared to gpipe?
 </span></p>
</div><h2 id="Further-References" data-id="Further-References"><a class="anchor hidden-xs" href="#Further-References" title="Further-References"><span class="octicon octicon-link ph ph-link-simple-horizontal"></span></a><span>Further References</span></h2><p><span>We
 recommend taking a look at these resources if you would like to learn 
more; we also drew on some of these resources to create the assignment!</span><br>
<a href="https://arxiv.org/pdf/1811.06965" target="_blank" rel="noopener"><span>GPipe Paper</span></a><br>
<a href="https://deepakn94.github.io/assets/papers/pipedream-sosp19.pdf" target="_blank" rel="noopener"><span>Pipedream Paper</span></a><br>
<a href="https://arxiv.org/pdf/1910.02054" target="_blank" rel="noopener"><span>ZeRO Paper</span></a><br>
<a href="https://arxiv.org/pdf/1710.03740" target="_blank" rel="noopener"><span>Mixed Precision Training Paper</span></a><br>
<a href="https://arxiv.org/pdf/2304.11277" target="_blank" rel="noopener"><span>Pytorch FSDP Paper</span></a></p></div>
    <div class="ui-toc dropup unselectable hidden-print" style="display: none; right: 343.5px;">
        <div class="pull-right dropdown">
            <a id="tocLabel" class="ui-toc-label btn btn-default" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false" title="Table of content">
                <i class="fa fa-bars"></i>
            </a>
            <ul id="ui-toc" class="ui-toc-dropdown dropdown-menu" aria-labelledby="tocLabel">
                <div class="toc"><ul class="nav">
<li class=""><a href="#Assignment-1-Parallelism-Techniques-" title="Assignment 1: Parallelism Techniques   ">Assignment 1: Parallelism Techniques   </a></li>
<li class=""><a href="#Introduction" title="Introduction">Introduction</a><ul class="nav">
<li class="invisable-node"><ul class="nav">
<li class=""><a href="#Due-dates" title="Due dates:">Due dates:</a></li>
<li class=""><a href="#Deliverables-for-Initial-Check-In" title="Deliverables for Initial Check-In:">Deliverables for Initial Check-In:</a></li>
<li class=""><a href="#Deliverables-for-Final-Assignment" title="Deliverables for Final Assignment:">Deliverables for Final Assignment:</a></li>
</ul>
</li>
<li class=""><a href="#Learning-Goals" title="Learning Goals">Learning Goals</a></li>
<li><a href="#Assignment-Installation" title="Assignment Installation">Assignment Installation</a><ul class="nav">
<li><a href="#Using-Containers-for-Development" title="Using Containers for Development">Using Containers for Development</a></li>
</ul>
</li>
<li><a href="#Part-1-Distributed-Data-Parallel" title="Part 1: Distributed Data Parallel">Part 1: Distributed Data Parallel</a><ul class="nav">
<li><a href="#Implement-DDP" title="Implement DDP">Implement DDP</a></li>
<li><a href="#Check-Correctness" title="Check Correctness">Check Correctness</a></li>
<li><a href="#Performance-Analysis" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-time-Memory-Usage-and-Communication-in-DDP" title="Math time: Memory Usage and Communication in DDP">Math time: Memory Usage and Communication in DDP</a></li>
<li><a href="#Deliverables-for-Mid-Project-Checkpoint-Due-on-204" title="Deliverables for Mid-Project Checkpoint Due on 2/04">Deliverables for Mid-Project Checkpoint Due on 2/04</a></li>
</ul>
</li>
<li><a href="#Part-2-Model-Parallelism" title="Part 2: Model Parallelism">Part 2: Model Parallelism</a><ul class="nav">
<li><a href="#Code-Structure-for-Model-Parallelisn" title="Code Structure for Model Parallelisn">Code Structure for Model Parallelisn</a></li>
<li><a href="#Implement-Model-Parallelism" title="Implement Model Parallelism">Implement Model Parallelism</a></li>
<li><a href="#Performance-Analysis24" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP" title="Math time: Comparison of Communication in Model Parallel vs. DDP">Math time: Comparison of Communication in Model Parallel vs. DDP</a></li>
<li><a href="#Deliverables-for-Mid-Project-Checkpoint-Due-on-20426" title="Deliverables for Mid-Project Checkpoint Due on 2/04">Deliverables for Mid-Project Checkpoint Due on 2/04</a></li>
</ul>
</li>
<li><a href="#Part-3-Reducing-the-Memory-Overhead-of-DDP" title="Part 3: Reducing the Memory Overhead of DDP">Part 3: Reducing the Memory Overhead of DDP</a><ul class="nav">
<li><a href="#Implement-FSDP" title="Implement FSDP">Implement FSDP</a></li>
<li><a href="#Check-FSDP-for-Correctness" title="Check FSDP for Correctness">Check FSDP for Correctness</a></li>
<li><a href="#Performance-Analysis30" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-Time-Memory-Overhead-of-DDP-vs-FSDP" title="Math Time: Memory Overhead of DDP vs. FSDP">Math Time: Memory Overhead of DDP vs. FSDP</a></li>
</ul>
</li>
<li><a href="#Part-4-Pipeline-Parallelism" title="Part 4: Pipeline Parallelism">Part 4: Pipeline Parallelism</a><ul class="nav">
<li><a href="#Implement-Pipeline-Parallelism" title="Implement Pipeline Parallelism">Implement Pipeline Parallelism</a></li>
<li><a href="#Performance-Analysis35" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-Time-Pipeline-Bubble-Size" title="Math Time: Pipeline Bubble Size">Math Time: Pipeline Bubble Size</a></li>
</ul>
</li>
<li><a href="#Further-References" title="Further References">Further References</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
            </ul>
        </div>
    </div>
    <div id="ui-toc-affix" class="ui-affix-toc ui-toc-dropdown unselectable hidden-print affix" data-spy="affix" style="top: 17px; left: 1076.5px;">
        <div class="toc"><ul class="nav">
<li class=""><a href="#Assignment-1-Parallelism-Techniques-" title="Assignment 1: Parallelism Techniques   ">Assignment 1: Parallelism Techniques   </a></li>
<li class=""><a href="#Introduction" title="Introduction">Introduction</a><ul class="nav">
<li class="invisable-node"><ul class="nav">
<li class=""><a href="#Due-dates" title="Due dates:">Due dates:</a></li>
<li class=""><a href="#Deliverables-for-Initial-Check-In" title="Deliverables for Initial Check-In:">Deliverables for Initial Check-In:</a></li>
<li class=""><a href="#Deliverables-for-Final-Assignment" title="Deliverables for Final Assignment:">Deliverables for Final Assignment:</a></li>
</ul>
</li>
<li class=""><a href="#Learning-Goals" title="Learning Goals">Learning Goals</a></li>
<li><a href="#Assignment-Installation" title="Assignment Installation">Assignment Installation</a><ul class="nav">
<li><a href="#Using-Containers-for-Development" title="Using Containers for Development">Using Containers for Development</a></li>
</ul>
</li>
<li><a href="#Part-1-Distributed-Data-Parallel" title="Part 1: Distributed Data Parallel">Part 1: Distributed Data Parallel</a><ul class="nav">
<li><a href="#Implement-DDP" title="Implement DDP">Implement DDP</a></li>
<li><a href="#Check-Correctness" title="Check Correctness">Check Correctness</a></li>
<li><a href="#Performance-Analysis" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-time-Memory-Usage-and-Communication-in-DDP" title="Math time: Memory Usage and Communication in DDP">Math time: Memory Usage and Communication in DDP</a></li>
<li><a href="#Deliverables-for-Mid-Project-Checkpoint-Due-on-204" title="Deliverables for Mid-Project Checkpoint Due on 2/04">Deliverables for Mid-Project Checkpoint Due on 2/04</a></li>
</ul>
</li>
<li><a href="#Part-2-Model-Parallelism" title="Part 2: Model Parallelism">Part 2: Model Parallelism</a><ul class="nav">
<li><a href="#Code-Structure-for-Model-Parallelisn" title="Code Structure for Model Parallelisn">Code Structure for Model Parallelisn</a></li>
<li><a href="#Implement-Model-Parallelism" title="Implement Model Parallelism">Implement Model Parallelism</a></li>
<li><a href="#Performance-Analysis24" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-time-Comparison-of-Communication-in-Model-Parallel-vs-DDP" title="Math time: Comparison of Communication in Model Parallel vs. DDP">Math time: Comparison of Communication in Model Parallel vs. DDP</a></li>
<li><a href="#Deliverables-for-Mid-Project-Checkpoint-Due-on-20426" title="Deliverables for Mid-Project Checkpoint Due on 2/04">Deliverables for Mid-Project Checkpoint Due on 2/04</a></li>
</ul>
</li>
<li><a href="#Part-3-Reducing-the-Memory-Overhead-of-DDP" title="Part 3: Reducing the Memory Overhead of DDP">Part 3: Reducing the Memory Overhead of DDP</a><ul class="nav">
<li><a href="#Implement-FSDP" title="Implement FSDP">Implement FSDP</a></li>
<li><a href="#Check-FSDP-for-Correctness" title="Check FSDP for Correctness">Check FSDP for Correctness</a></li>
<li><a href="#Performance-Analysis30" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-Time-Memory-Overhead-of-DDP-vs-FSDP" title="Math Time: Memory Overhead of DDP vs. FSDP">Math Time: Memory Overhead of DDP vs. FSDP</a></li>
</ul>
</li>
<li><a href="#Part-4-Pipeline-Parallelism" title="Part 4: Pipeline Parallelism">Part 4: Pipeline Parallelism</a><ul class="nav">
<li><a href="#Implement-Pipeline-Parallelism" title="Implement Pipeline Parallelism">Implement Pipeline Parallelism</a></li>
<li><a href="#Performance-Analysis35" title="Performance Analysis">Performance Analysis</a></li>
<li><a href="#Math-Time-Pipeline-Bubble-Size" title="Math Time: Pipeline Bubble Size">Math Time: Pipeline Bubble Size</a></li>
</ul>
</li>
<li><a href="#Further-References" title="Further References">Further References</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
    </div>
    <script src="project1_files/jquery.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
    <script src="project1_files/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous" defer="defer"></script>
    <script src="project1_files/gist-embed.min.js" integrity="sha256-KyF2D6xPIJUW5sUDSs93vWyZm+1RzIpKCexxElmxl8g=" crossorigin="anonymous" defer="defer"></script>
    <script>
        var markdown = $(".markdown-body");
        //smooth all hash trigger scrolling
        function smoothHashScroll() {
            var hashElements = $("a[href^='#']").toArray();
            for (var i = 0; i < hashElements.length; i++) {
                var element = hashElements[i];
                var $element = $(element);
                var hash = element.hash;
                if (hash) {
                    $element.on('click', function (e) {
                        // store hash
                        var hash = this.hash;
                        if ($(hash).length <= 0) return;
                        // prevent default anchor click behavior
                        e.preventDefault();
                        // animate
                        $('body, html').stop(true, true).animate({
                            scrollTop: $(hash).offset().top
                        }, 100, "linear", function () {
                            // when done, add hash to url
                            // (default click behaviour)
                            window.location.hash = hash;
                        });
                    });
                }
            }
        }

        smoothHashScroll();
        var toc = $('.ui-toc');
        var tocAffix = $('.ui-affix-toc');
        var tocDropdown = $('.ui-toc-dropdown');
        //toc
        tocDropdown.click(function (e) {
            e.stopPropagation();
        });

        var enoughForAffixToc = true;

        function generateScrollspy() {
            $(document.body).scrollspy({
                target: ''
            });
            $(document.body).scrollspy('refresh');
            if (enoughForAffixToc) {
                toc.hide();
                tocAffix.show();
            } else {
                tocAffix.hide();
                toc.show();
            }
            $(document.body).scroll();
        }

        function windowResize() {
            //toc right
            var paddingRight = parseFloat(markdown.css('padding-right'));
            var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight));
            toc.css('right', right + 'px');
            //affix toc left
            var newbool;
            var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2;
            //for ipad or wider device
            if (rightMargin >= 133) {
                newbool = true;
                var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2;
                var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin;
                tocAffix.css('left', left + 'px');
            } else {
                newbool = false;
            }
            if (newbool != enoughForAffixToc) {
                enoughForAffixToc = newbool;
                generateScrollspy();
            }
        }
        $(window).resize(function () {
            windowResize();
        });
        $(document).ready(function () {
            windowResize();
            generateScrollspy();
        });

        //remove hash
        function removeHash() {
            window.location.hash = '';
        }

        var backtotop = $('.back-to-top');
        var gotobottom = $('.go-to-bottom');

        backtotop.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToTop)
                scrollToTop();
            removeHash();
        });
        gotobottom.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToBottom)
                scrollToBottom();
            removeHash();
        });

        var toggle = $('.expand-toggle');
        var tocExpand = false;

        checkExpandToggle();
        toggle.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            tocExpand = !tocExpand;
            checkExpandToggle();
        })

        function checkExpandToggle () {
            var toc = $('.ui-toc-dropdown .toc');
            var toggle = $('.expand-toggle');
            if (!tocExpand) {
                toc.removeClass('expand');
                toggle.text('Expand all');
            } else {
                toc.addClass('expand');
                toggle.text('Collapse all');
            }
        }

        function scrollToTop() {
            $('body, html').stop(true, true).animate({
                scrollTop: 0
            }, 100, "linear");
        }

        function scrollToBottom() {
            $('body, html').stop(true, true).animate({
                scrollTop: $(document.body)[0].scrollHeight
            }, 100, "linear");
        }
    </script>



</body></html>
